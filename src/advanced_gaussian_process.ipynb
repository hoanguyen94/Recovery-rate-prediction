{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import statistics\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from utils import calculate_metric\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import gpytorch\n",
    "import os\n",
    "import shap\n",
    "\n",
    "# Import our Advanced GP implementation\n",
    "\n",
    "from advanced_gaussian_process import AdvancedGPWithEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11fdaf050>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_FOLDER = \"../data\"\n",
    "TRAIN_FEATURES = DATA_FOLDER + '/train_features2.xlsx'\n",
    "TRAIN_LABELS = DATA_FOLDER + \"/train_labels2.xlsx\"\n",
    "TEST_FEATURES = DATA_FOLDER + \"/test_features2.xlsx\"\n",
    "TEST_LABELS = DATA_FOLDER + \"/test_labels2.xlsx\"\n",
    "\n",
    "MODEL_PATH = '../output/AdvancedGP'\n",
    "PROJECT_NAME = \"run/AdvancedGP\"\n",
    "TRAINING_OUTPUT_FILE = '../output/train_predictions.xlsx'\n",
    "TEST_OUTPUT_FILE = '../output/test_predictions.xlsx'\n",
    "SHEET_NAME = \"AdvancedGP\"\n",
    "OUTPUT_FILE = MODEL_PATH + '/AdvancedGP.pkl'\n",
    "FEATURE_IMPORTANCE_PATH = MODEL_PATH + '/feature_importance'\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create paths\n",
    "output_dir = Path(MODEL_PATH)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coupon rate</th>\n",
       "      <th>SP500 MD</th>\n",
       "      <th>Average daily 1-year SP500 return</th>\n",
       "      <th>Ratio to MA</th>\n",
       "      <th>US Corporate Bond Yield Spread</th>\n",
       "      <th>US Corporate Bond Yield Spread(3-5 year)</th>\n",
       "      <th>US Corporate Bond Yield Spread(5-7 year)</th>\n",
       "      <th>US Corporate Bond Yield Spread(7-10 year)</th>\n",
       "      <th>US Corporate Bond Yield Spread(10+ year)</th>\n",
       "      <th>US Generic Govt 3 Month Yield</th>\n",
       "      <th>...</th>\n",
       "      <th>event_type_subcategory_sum_Missing Coupon payment only</th>\n",
       "      <th>event_type_subcategory_sum_Missing Interest payment</th>\n",
       "      <th>event_type_subcategory_sum_Missing Loan payment</th>\n",
       "      <th>event_type_subcategory_sum_Missing Principal payment</th>\n",
       "      <th>event_type_subcategory_sum_Others</th>\n",
       "      <th>event_type_subcategory_sum_Pre-Negotiated Chapter 11</th>\n",
       "      <th>event_type_subcategory_sum_Protection</th>\n",
       "      <th>event_type_subcategory_sum_Receivership</th>\n",
       "      <th>event_type_subcategory_sum_Rehabilitation</th>\n",
       "      <th>event_type_subcategory_sum_Restructuring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.500</td>\n",
       "      <td>-117.46020</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>125.407139</td>\n",
       "      <td>177.213028</td>\n",
       "      <td>134.012054</td>\n",
       "      <td>198.8153</td>\n",
       "      <td>191.364395</td>\n",
       "      <td>223.346344</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.000</td>\n",
       "      <td>166.38276</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>-4.603446</td>\n",
       "      <td>101.613617</td>\n",
       "      <td>77.032829</td>\n",
       "      <td>123.3998</td>\n",
       "      <td>105.932022</td>\n",
       "      <td>139.111115</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.000</td>\n",
       "      <td>119.85752</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>-11.950380</td>\n",
       "      <td>104.545959</td>\n",
       "      <td>77.416649</td>\n",
       "      <td>129.4317</td>\n",
       "      <td>111.818001</td>\n",
       "      <td>139.717407</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.125</td>\n",
       "      <td>653.51208</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>-2.494861</td>\n",
       "      <td>90.736633</td>\n",
       "      <td>64.654129</td>\n",
       "      <td>95.3731</td>\n",
       "      <td>92.141212</td>\n",
       "      <td>121.666237</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.250</td>\n",
       "      <td>231.89472</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>4.823413</td>\n",
       "      <td>98.533821</td>\n",
       "      <td>68.759308</td>\n",
       "      <td>93.4174</td>\n",
       "      <td>107.424469</td>\n",
       "      <td>139.741165</td>\n",
       "      <td>1.2865</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   coupon rate   SP500 MD  Average daily 1-year SP500 return  Ratio to MA  \\\n",
       "0        7.500 -117.46020                          -0.000189   125.407139   \n",
       "1        6.000  166.38276                           0.000768    -4.603446   \n",
       "2       11.000  119.85752                           0.000678   -11.950380   \n",
       "3        9.125  653.51208                           0.001638    -2.494861   \n",
       "4        9.250  231.89472                           0.000664     4.823413   \n",
       "\n",
       "   US Corporate Bond Yield Spread  US Corporate Bond Yield Spread(3-5 year)  \\\n",
       "0                      177.213028                                134.012054   \n",
       "1                      101.613617                                 77.032829   \n",
       "2                      104.545959                                 77.416649   \n",
       "3                       90.736633                                 64.654129   \n",
       "4                       98.533821                                 68.759308   \n",
       "\n",
       "   US Corporate Bond Yield Spread(5-7 year)  \\\n",
       "0                                  198.8153   \n",
       "1                                  123.3998   \n",
       "2                                  129.4317   \n",
       "3                                   95.3731   \n",
       "4                                   93.4174   \n",
       "\n",
       "   US Corporate Bond Yield Spread(7-10 year)  \\\n",
       "0                                 191.364395   \n",
       "1                                 105.932022   \n",
       "2                                 111.818001   \n",
       "3                                  92.141212   \n",
       "4                                 107.424469   \n",
       "\n",
       "   US Corporate Bond Yield Spread(10+ year)  US Generic Govt 3 Month Yield  \\\n",
       "0                                223.346344                         0.1983   \n",
       "1                                139.111115                         0.0355   \n",
       "2                                139.717407                         0.0101   \n",
       "3                                121.666237                         0.0152   \n",
       "4                                139.741165                         1.2865   \n",
       "\n",
       "   ...  event_type_subcategory_sum_Missing Coupon payment only  \\\n",
       "0  ...                                               True        \n",
       "1  ...                                              False        \n",
       "2  ...                                              False        \n",
       "3  ...                                              False        \n",
       "4  ...                                              False        \n",
       "\n",
       "   event_type_subcategory_sum_Missing Interest payment  \\\n",
       "0                                              False     \n",
       "1                                              False     \n",
       "2                                              False     \n",
       "3                                              False     \n",
       "4                                              False     \n",
       "\n",
       "   event_type_subcategory_sum_Missing Loan payment  \\\n",
       "0                                            False   \n",
       "1                                            False   \n",
       "2                                            False   \n",
       "3                                            False   \n",
       "4                                            False   \n",
       "\n",
       "   event_type_subcategory_sum_Missing Principal payment  \\\n",
       "0                                              False      \n",
       "1                                              False      \n",
       "2                                              False      \n",
       "3                                              False      \n",
       "4                                              False      \n",
       "\n",
       "   event_type_subcategory_sum_Others  \\\n",
       "0                              False   \n",
       "1                              False   \n",
       "2                              False   \n",
       "3                              False   \n",
       "4                               True   \n",
       "\n",
       "   event_type_subcategory_sum_Pre-Negotiated Chapter 11  \\\n",
       "0                                              False      \n",
       "1                                              False      \n",
       "2                                              False      \n",
       "3                                              False      \n",
       "4                                              False      \n",
       "\n",
       "   event_type_subcategory_sum_Protection  \\\n",
       "0                                  False   \n",
       "1                                  False   \n",
       "2                                  False   \n",
       "3                                  False   \n",
       "4                                  False   \n",
       "\n",
       "   event_type_subcategory_sum_Receivership  \\\n",
       "0                                    False   \n",
       "1                                    False   \n",
       "2                                    False   \n",
       "3                                    False   \n",
       "4                                    False   \n",
       "\n",
       "   event_type_subcategory_sum_Rehabilitation  \\\n",
       "0                                      False   \n",
       "1                                      False   \n",
       "2                                      False   \n",
       "3                                      False   \n",
       "4                                      False   \n",
       "\n",
       "   event_type_subcategory_sum_Restructuring  \n",
       "0                                     False  \n",
       "1                                     False  \n",
       "2                                     False  \n",
       "3                                     False  \n",
       "4                                     False  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train_features = pd.read_excel(TRAIN_FEATURES)\n",
    "train_labels = pd.read_excel(TRAIN_LABELS)\n",
    "test_features = pd.read_excel(TEST_FEATURES)\n",
    "test_labels = pd.read_excel(TEST_LABELS)\n",
    "\n",
    "# Display sample of data\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with advanced configuration (using AdvancedGPWithEnsemble without ensemble)\n",
    "# Initialize the AdvancedGPWithEnsemble class with use_ensemble=False\n",
    "# This will use a single AdvancedGaussianProcess model instead of an ensemble\n",
    "# Import the necessary class from the module\n",
    "\n",
    "# Get numerical features from the dataframe\n",
    "numerical_features = train_features.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Initialize the model with appropriate parameters\n",
    "model = AdvancedGPWithEnsemble(\n",
    "    numerical_features=numerical_features,\n",
    "    num_epochs=500,\n",
    "    learning_rate=0.01,\n",
    "    poly_degree=1,\n",
    "    n_best_features=50,\n",
    "    use_ensemble=True,\n",
    "    using_deep_feature=False,\n",
    "    using_feature_processor=False,\n",
    "    n_models=100\n",
    ")\n",
    "\n",
    "# For backward compatibility with the rest of the notebook\n",
    "# We'll extract the underlying AdvancedGaussianProcess model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coupon rate</th>\n",
       "      <th>SP500 MD</th>\n",
       "      <th>Average daily 1-year SP500 return</th>\n",
       "      <th>Ratio to MA</th>\n",
       "      <th>US Corporate Bond Yield Spread</th>\n",
       "      <th>US Corporate Bond Yield Spread(3-5 year)</th>\n",
       "      <th>US Corporate Bond Yield Spread(5-7 year)</th>\n",
       "      <th>US Corporate Bond Yield Spread(7-10 year)</th>\n",
       "      <th>US Corporate Bond Yield Spread(10+ year)</th>\n",
       "      <th>US Generic Govt 3 Month Yield</th>\n",
       "      <th>...</th>\n",
       "      <th>event_type_subcategory_sum_Missing Coupon payment only</th>\n",
       "      <th>event_type_subcategory_sum_Missing Interest payment</th>\n",
       "      <th>event_type_subcategory_sum_Missing Loan payment</th>\n",
       "      <th>event_type_subcategory_sum_Missing Principal payment</th>\n",
       "      <th>event_type_subcategory_sum_Others</th>\n",
       "      <th>event_type_subcategory_sum_Pre-Negotiated Chapter 11</th>\n",
       "      <th>event_type_subcategory_sum_Protection</th>\n",
       "      <th>event_type_subcategory_sum_Receivership</th>\n",
       "      <th>event_type_subcategory_sum_Rehabilitation</th>\n",
       "      <th>event_type_subcategory_sum_Restructuring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.500</td>\n",
       "      <td>-117.46020</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>125.407139</td>\n",
       "      <td>177.213028</td>\n",
       "      <td>134.012054</td>\n",
       "      <td>198.8153</td>\n",
       "      <td>191.364395</td>\n",
       "      <td>223.346344</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.000</td>\n",
       "      <td>166.38276</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>-4.603446</td>\n",
       "      <td>101.613617</td>\n",
       "      <td>77.032829</td>\n",
       "      <td>123.3998</td>\n",
       "      <td>105.932022</td>\n",
       "      <td>139.111115</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.000</td>\n",
       "      <td>119.85752</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>-11.950380</td>\n",
       "      <td>104.545959</td>\n",
       "      <td>77.416649</td>\n",
       "      <td>129.4317</td>\n",
       "      <td>111.818001</td>\n",
       "      <td>139.717407</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.125</td>\n",
       "      <td>653.51208</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>-2.494861</td>\n",
       "      <td>90.736633</td>\n",
       "      <td>64.654129</td>\n",
       "      <td>95.3731</td>\n",
       "      <td>92.141212</td>\n",
       "      <td>121.666237</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.250</td>\n",
       "      <td>231.89472</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>4.823413</td>\n",
       "      <td>98.533821</td>\n",
       "      <td>68.759308</td>\n",
       "      <td>93.4174</td>\n",
       "      <td>107.424469</td>\n",
       "      <td>139.741165</td>\n",
       "      <td>1.2865</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   coupon rate   SP500 MD  Average daily 1-year SP500 return  Ratio to MA  \\\n",
       "0        7.500 -117.46020                          -0.000189   125.407139   \n",
       "1        6.000  166.38276                           0.000768    -4.603446   \n",
       "2       11.000  119.85752                           0.000678   -11.950380   \n",
       "3        9.125  653.51208                           0.001638    -2.494861   \n",
       "4        9.250  231.89472                           0.000664     4.823413   \n",
       "\n",
       "   US Corporate Bond Yield Spread  US Corporate Bond Yield Spread(3-5 year)  \\\n",
       "0                      177.213028                                134.012054   \n",
       "1                      101.613617                                 77.032829   \n",
       "2                      104.545959                                 77.416649   \n",
       "3                       90.736633                                 64.654129   \n",
       "4                       98.533821                                 68.759308   \n",
       "\n",
       "   US Corporate Bond Yield Spread(5-7 year)  \\\n",
       "0                                  198.8153   \n",
       "1                                  123.3998   \n",
       "2                                  129.4317   \n",
       "3                                   95.3731   \n",
       "4                                   93.4174   \n",
       "\n",
       "   US Corporate Bond Yield Spread(7-10 year)  \\\n",
       "0                                 191.364395   \n",
       "1                                 105.932022   \n",
       "2                                 111.818001   \n",
       "3                                  92.141212   \n",
       "4                                 107.424469   \n",
       "\n",
       "   US Corporate Bond Yield Spread(10+ year)  US Generic Govt 3 Month Yield  \\\n",
       "0                                223.346344                         0.1983   \n",
       "1                                139.111115                         0.0355   \n",
       "2                                139.717407                         0.0101   \n",
       "3                                121.666237                         0.0152   \n",
       "4                                139.741165                         1.2865   \n",
       "\n",
       "   ...  event_type_subcategory_sum_Missing Coupon payment only  \\\n",
       "0  ...                                               True        \n",
       "1  ...                                              False        \n",
       "2  ...                                              False        \n",
       "3  ...                                              False        \n",
       "4  ...                                              False        \n",
       "\n",
       "   event_type_subcategory_sum_Missing Interest payment  \\\n",
       "0                                              False     \n",
       "1                                              False     \n",
       "2                                              False     \n",
       "3                                              False     \n",
       "4                                              False     \n",
       "\n",
       "   event_type_subcategory_sum_Missing Loan payment  \\\n",
       "0                                            False   \n",
       "1                                            False   \n",
       "2                                            False   \n",
       "3                                            False   \n",
       "4                                            False   \n",
       "\n",
       "   event_type_subcategory_sum_Missing Principal payment  \\\n",
       "0                                              False      \n",
       "1                                              False      \n",
       "2                                              False      \n",
       "3                                              False      \n",
       "4                                              False      \n",
       "\n",
       "   event_type_subcategory_sum_Others  \\\n",
       "0                              False   \n",
       "1                              False   \n",
       "2                              False   \n",
       "3                              False   \n",
       "4                               True   \n",
       "\n",
       "   event_type_subcategory_sum_Pre-Negotiated Chapter 11  \\\n",
       "0                                              False      \n",
       "1                                              False      \n",
       "2                                              False      \n",
       "3                                              False      \n",
       "4                                              False      \n",
       "\n",
       "   event_type_subcategory_sum_Protection  \\\n",
       "0                                  False   \n",
       "1                                  False   \n",
       "2                                  False   \n",
       "3                                  False   \n",
       "4                                  False   \n",
       "\n",
       "   event_type_subcategory_sum_Receivership  \\\n",
       "0                                    False   \n",
       "1                                    False   \n",
       "2                                    False   \n",
       "3                                    False   \n",
       "4                                    False   \n",
       "\n",
       "   event_type_subcategory_sum_Rehabilitation  \\\n",
       "0                                      False   \n",
       "1                                      False   \n",
       "2                                      False   \n",
       "3                                      False   \n",
       "4                                      False   \n",
       "\n",
       "   event_type_subcategory_sum_Restructuring  \n",
       "0                                     False  \n",
       "1                                     False  \n",
       "2                                     False  \n",
       "3                                     False  \n",
       "4                                     False  \n",
       "\n",
       "[5 rows x 317 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "Training model 1/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.160\n",
      "Epoch 101/500 - Loss: 0.983\n",
      "Epoch 151/500 - Loss: 0.882\n",
      "Epoch 201/500 - Loss: 0.862\n",
      "Epoch 251/500 - Loss: 0.752\n",
      "Epoch 301/500 - Loss: 0.777\n",
      "Epoch 351/500 - Loss: 0.581\n",
      "Epoch 401/500 - Loss: 0.657\n",
      "Epoch 451/500 - Loss: 0.638\n",
      "\n",
      "Training model 2/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.157\n",
      "Epoch 101/500 - Loss: 0.930\n",
      "Epoch 151/500 - Loss: 0.867\n",
      "Epoch 201/500 - Loss: 0.741\n",
      "Epoch 251/500 - Loss: 0.675\n",
      "Epoch 301/500 - Loss: 0.610\n",
      "Epoch 351/500 - Loss: 0.551\n",
      "Epoch 401/500 - Loss: 0.515\n",
      "Epoch 451/500 - Loss: 0.639\n",
      "\n",
      "Training model 3/100\n",
      "Epoch 1/500 - Loss: 1.508\n",
      "Epoch 51/500 - Loss: 1.115\n",
      "Epoch 101/500 - Loss: 0.904\n",
      "Epoch 151/500 - Loss: 0.904\n",
      "Epoch 201/500 - Loss: 0.783\n",
      "Epoch 251/500 - Loss: 0.782\n",
      "Epoch 301/500 - Loss: 0.779\n",
      "Epoch 351/500 - Loss: 0.686\n",
      "Epoch 401/500 - Loss: 0.628\n",
      "Epoch 451/500 - Loss: 0.687\n",
      "\n",
      "Training model 4/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.157\n",
      "Epoch 101/500 - Loss: 0.969\n",
      "Epoch 151/500 - Loss: 0.871\n",
      "Epoch 201/500 - Loss: 0.846\n",
      "Epoch 251/500 - Loss: 0.734\n",
      "Epoch 301/500 - Loss: 0.700\n",
      "Epoch 351/500 - Loss: 0.590\n",
      "Epoch 401/500 - Loss: 0.576\n",
      "Epoch 451/500 - Loss: 0.666\n",
      "\n",
      "Training model 5/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.037\n",
      "Epoch 101/500 - Loss: 0.854\n",
      "Epoch 151/500 - Loss: 0.810\n",
      "Epoch 201/500 - Loss: 0.702\n",
      "Epoch 251/500 - Loss: 0.657\n",
      "Epoch 301/500 - Loss: 0.627\n",
      "Epoch 351/500 - Loss: 0.578\n",
      "Epoch 401/500 - Loss: 0.609\n",
      "Epoch 451/500 - Loss: 0.594\n",
      "\n",
      "Training model 6/100\n",
      "Epoch 1/500 - Loss: 1.504\n",
      "Epoch 51/500 - Loss: 1.152\n",
      "Epoch 101/500 - Loss: 0.929\n",
      "Epoch 151/500 - Loss: 0.830\n",
      "Epoch 201/500 - Loss: 0.746\n",
      "Epoch 251/500 - Loss: 0.731\n",
      "Epoch 301/500 - Loss: 0.677\n",
      "Epoch 351/500 - Loss: 0.691\n",
      "Epoch 401/500 - Loss: 0.601\n",
      "Epoch 451/500 - Loss: 0.490\n",
      "\n",
      "Training model 7/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.310\n",
      "Epoch 101/500 - Loss: 1.080\n",
      "Epoch 151/500 - Loss: 0.957\n",
      "Epoch 201/500 - Loss: 0.889\n",
      "Epoch 251/500 - Loss: 0.787\n",
      "Epoch 301/500 - Loss: 0.727\n",
      "Epoch 351/500 - Loss: 0.708\n",
      "Epoch 401/500 - Loss: 0.702\n",
      "Epoch 451/500 - Loss: 0.650\n",
      "\n",
      "Training model 8/100\n",
      "Epoch 1/500 - Loss: 1.508\n",
      "Epoch 51/500 - Loss: 1.081\n",
      "Epoch 101/500 - Loss: 0.998\n",
      "Epoch 151/500 - Loss: 0.898\n",
      "Epoch 201/500 - Loss: 0.820\n",
      "Epoch 251/500 - Loss: 0.824\n",
      "Epoch 301/500 - Loss: 0.720\n",
      "Epoch 351/500 - Loss: 0.705\n",
      "Epoch 401/500 - Loss: 0.660\n",
      "Epoch 451/500 - Loss: 0.731\n",
      "\n",
      "Training model 9/100\n",
      "Epoch 1/500 - Loss: 1.506\n",
      "Epoch 51/500 - Loss: 1.124\n",
      "Epoch 101/500 - Loss: 0.986\n",
      "Epoch 151/500 - Loss: 0.895\n",
      "Epoch 201/500 - Loss: 0.805\n",
      "Epoch 251/500 - Loss: 0.732\n",
      "Epoch 301/500 - Loss: 0.698\n",
      "Epoch 351/500 - Loss: 0.677\n",
      "Epoch 401/500 - Loss: 0.702\n",
      "Epoch 451/500 - Loss: 0.619\n",
      "\n",
      "Training model 10/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.118\n",
      "Epoch 101/500 - Loss: 0.897\n",
      "Epoch 151/500 - Loss: 0.921\n",
      "Epoch 201/500 - Loss: 0.788\n",
      "Epoch 251/500 - Loss: 0.733\n",
      "Epoch 301/500 - Loss: 0.622\n",
      "Epoch 351/500 - Loss: 0.689\n",
      "Epoch 401/500 - Loss: 0.623\n",
      "Epoch 451/500 - Loss: 0.594\n",
      "\n",
      "Training model 11/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.310\n",
      "Epoch 101/500 - Loss: 1.008\n",
      "Epoch 151/500 - Loss: 0.937\n",
      "Epoch 201/500 - Loss: 0.886\n",
      "Epoch 251/500 - Loss: 0.812\n",
      "Epoch 301/500 - Loss: 0.784\n",
      "Epoch 351/500 - Loss: 0.699\n",
      "Epoch 401/500 - Loss: 0.697\n",
      "Epoch 451/500 - Loss: 0.636\n",
      "\n",
      "Training model 12/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.077\n",
      "Epoch 101/500 - Loss: 0.955\n",
      "Epoch 151/500 - Loss: 0.869\n",
      "Epoch 201/500 - Loss: 0.752\n",
      "Epoch 251/500 - Loss: 0.937\n",
      "Epoch 301/500 - Loss: 0.649\n",
      "Epoch 351/500 - Loss: 0.680\n",
      "Epoch 401/500 - Loss: 0.676\n",
      "Epoch 451/500 - Loss: 0.746\n",
      "\n",
      "Training model 13/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.111\n",
      "Epoch 101/500 - Loss: 0.933\n",
      "Epoch 151/500 - Loss: 0.845\n",
      "Epoch 201/500 - Loss: 0.727\n",
      "Epoch 251/500 - Loss: 0.754\n",
      "Epoch 301/500 - Loss: 0.625\n",
      "Epoch 351/500 - Loss: 0.646\n",
      "Epoch 401/500 - Loss: 0.651\n",
      "Epoch 451/500 - Loss: 0.582\n",
      "\n",
      "Training model 14/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.050\n",
      "Epoch 101/500 - Loss: 0.937\n",
      "Epoch 151/500 - Loss: 0.856\n",
      "Epoch 201/500 - Loss: 0.734\n",
      "Epoch 251/500 - Loss: 0.741\n",
      "Epoch 301/500 - Loss: 0.712\n",
      "Epoch 351/500 - Loss: 0.678\n",
      "Epoch 401/500 - Loss: 0.696\n",
      "Epoch 451/500 - Loss: 0.619\n",
      "\n",
      "Training model 15/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.185\n",
      "Epoch 101/500 - Loss: 1.055\n",
      "Epoch 151/500 - Loss: 0.979\n",
      "Epoch 201/500 - Loss: 0.902\n",
      "Epoch 251/500 - Loss: 0.838\n",
      "Epoch 301/500 - Loss: 0.814\n",
      "Epoch 351/500 - Loss: 0.805\n",
      "Epoch 401/500 - Loss: 0.764\n",
      "Epoch 451/500 - Loss: 0.736\n",
      "\n",
      "Training model 16/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.136\n",
      "Epoch 101/500 - Loss: 0.972\n",
      "Epoch 151/500 - Loss: 0.927\n",
      "Epoch 201/500 - Loss: 0.818\n",
      "Epoch 251/500 - Loss: 0.808\n",
      "Epoch 301/500 - Loss: 0.729\n",
      "Epoch 351/500 - Loss: 0.676\n",
      "Epoch 401/500 - Loss: 0.666\n",
      "Epoch 451/500 - Loss: 0.641\n",
      "\n",
      "Training model 17/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.143\n",
      "Epoch 101/500 - Loss: 0.960\n",
      "Epoch 151/500 - Loss: 0.887\n",
      "Epoch 201/500 - Loss: 0.779\n",
      "Epoch 251/500 - Loss: 0.747\n",
      "Epoch 301/500 - Loss: 0.691\n",
      "Epoch 351/500 - Loss: 0.645\n",
      "Epoch 401/500 - Loss: 0.631\n",
      "Epoch 451/500 - Loss: 0.638\n",
      "\n",
      "Training model 18/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.133\n",
      "Epoch 101/500 - Loss: 0.947\n",
      "Epoch 151/500 - Loss: 0.940\n",
      "Epoch 201/500 - Loss: 0.865\n",
      "Epoch 251/500 - Loss: 0.799\n",
      "Epoch 301/500 - Loss: 0.738\n",
      "Epoch 351/500 - Loss: 0.613\n",
      "Epoch 401/500 - Loss: 0.707\n",
      "Epoch 451/500 - Loss: 0.569\n",
      "\n",
      "Training model 19/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.091\n",
      "Epoch 101/500 - Loss: 1.035\n",
      "Epoch 151/500 - Loss: 0.926\n",
      "Epoch 201/500 - Loss: 1.026\n",
      "Epoch 251/500 - Loss: 0.825\n",
      "Epoch 301/500 - Loss: 0.793\n",
      "Epoch 351/500 - Loss: 0.768\n",
      "Epoch 401/500 - Loss: 0.717\n",
      "Epoch 451/500 - Loss: 0.687\n",
      "\n",
      "Training model 20/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.037\n",
      "Epoch 101/500 - Loss: 0.889\n",
      "Epoch 151/500 - Loss: 0.846\n",
      "Epoch 201/500 - Loss: 0.784\n",
      "Epoch 251/500 - Loss: 0.693\n",
      "Epoch 301/500 - Loss: 0.652\n",
      "Epoch 351/500 - Loss: 0.645\n",
      "Epoch 401/500 - Loss: 0.632\n",
      "Epoch 451/500 - Loss: 0.540\n",
      "\n",
      "Training model 21/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.089\n",
      "Epoch 101/500 - Loss: 1.024\n",
      "Epoch 151/500 - Loss: 0.911\n",
      "Epoch 201/500 - Loss: 0.834\n",
      "Epoch 251/500 - Loss: 0.887\n",
      "Epoch 301/500 - Loss: 0.688\n",
      "Epoch 351/500 - Loss: 0.824\n",
      "Epoch 401/500 - Loss: 0.668\n",
      "Epoch 451/500 - Loss: 0.768\n",
      "\n",
      "Training model 22/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.140\n",
      "Epoch 101/500 - Loss: 0.984\n",
      "Epoch 151/500 - Loss: 0.934\n",
      "Epoch 201/500 - Loss: 1.095\n",
      "Epoch 251/500 - Loss: 0.801\n",
      "Epoch 301/500 - Loss: 0.755\n",
      "Epoch 351/500 - Loss: 0.720\n",
      "Epoch 401/500 - Loss: 0.629\n",
      "Epoch 451/500 - Loss: 0.691\n",
      "\n",
      "Training model 23/100\n",
      "Epoch 1/500 - Loss: 1.508\n",
      "Epoch 51/500 - Loss: 1.167\n",
      "Epoch 101/500 - Loss: 0.935\n",
      "Epoch 151/500 - Loss: 0.848\n",
      "Epoch 201/500 - Loss: 0.821\n",
      "Epoch 251/500 - Loss: 0.742\n",
      "Epoch 301/500 - Loss: 0.637\n",
      "Epoch 351/500 - Loss: 0.679\n",
      "Epoch 401/500 - Loss: 0.557\n",
      "Epoch 451/500 - Loss: 0.541\n",
      "\n",
      "Training model 24/100\n",
      "Epoch 1/500 - Loss: 1.508\n",
      "Epoch 51/500 - Loss: 1.081\n",
      "Epoch 101/500 - Loss: 0.919\n",
      "Epoch 151/500 - Loss: 0.858\n",
      "Epoch 201/500 - Loss: 0.913\n",
      "Epoch 251/500 - Loss: 0.760\n",
      "Epoch 301/500 - Loss: 0.694\n",
      "Epoch 351/500 - Loss: 0.666\n",
      "Epoch 401/500 - Loss: 0.597\n",
      "Epoch 451/500 - Loss: 0.587\n",
      "\n",
      "Training model 25/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.143\n",
      "Epoch 101/500 - Loss: 0.981\n",
      "Epoch 151/500 - Loss: 0.852\n",
      "Epoch 201/500 - Loss: 0.840\n",
      "Epoch 251/500 - Loss: 0.800\n",
      "Epoch 301/500 - Loss: 0.704\n",
      "Epoch 351/500 - Loss: 0.759\n",
      "Epoch 401/500 - Loss: 0.698\n",
      "Epoch 451/500 - Loss: 0.641\n",
      "\n",
      "Training model 26/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.129\n",
      "Epoch 101/500 - Loss: 0.981\n",
      "Epoch 151/500 - Loss: 0.827\n",
      "Epoch 201/500 - Loss: 0.722\n",
      "Epoch 251/500 - Loss: 0.737\n",
      "Epoch 301/500 - Loss: 0.575\n",
      "Epoch 351/500 - Loss: 0.564\n",
      "Epoch 401/500 - Loss: 0.553\n",
      "Epoch 451/500 - Loss: 0.517\n",
      "\n",
      "Training model 27/100\n",
      "Epoch 1/500 - Loss: 1.505\n",
      "Epoch 51/500 - Loss: 1.137\n",
      "Epoch 101/500 - Loss: 0.952\n",
      "Epoch 151/500 - Loss: 0.893\n",
      "Epoch 201/500 - Loss: 0.745\n",
      "Epoch 251/500 - Loss: 0.639\n",
      "Epoch 301/500 - Loss: 0.693\n",
      "Epoch 351/500 - Loss: 0.591\n",
      "Epoch 401/500 - Loss: 0.592\n",
      "Epoch 451/500 - Loss: 0.549\n",
      "\n",
      "Training model 28/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.129\n",
      "Epoch 101/500 - Loss: 1.006\n",
      "Epoch 151/500 - Loss: 0.898\n",
      "Epoch 201/500 - Loss: 0.899\n",
      "Epoch 251/500 - Loss: 0.815\n",
      "Epoch 301/500 - Loss: 0.746\n",
      "Epoch 351/500 - Loss: 0.735\n",
      "Epoch 401/500 - Loss: 0.709\n",
      "Epoch 451/500 - Loss: 0.649\n",
      "\n",
      "Training model 29/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.044\n",
      "Epoch 101/500 - Loss: 1.004\n",
      "Epoch 151/500 - Loss: 0.817\n",
      "Epoch 201/500 - Loss: 0.746\n",
      "Epoch 251/500 - Loss: 0.673\n",
      "Epoch 301/500 - Loss: 0.643\n",
      "Epoch 351/500 - Loss: 0.679\n",
      "Epoch 401/500 - Loss: 0.559\n",
      "Epoch 451/500 - Loss: 0.512\n",
      "\n",
      "Training model 30/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.021\n",
      "Epoch 101/500 - Loss: 0.984\n",
      "Epoch 151/500 - Loss: 0.881\n",
      "Epoch 201/500 - Loss: 0.844\n",
      "Epoch 251/500 - Loss: 0.875\n",
      "Epoch 301/500 - Loss: 0.715\n",
      "Epoch 351/500 - Loss: 0.665\n",
      "Epoch 401/500 - Loss: 0.626\n",
      "Epoch 451/500 - Loss: 0.599\n",
      "\n",
      "Training model 31/100\n",
      "Epoch 1/500 - Loss: 1.505\n",
      "Epoch 51/500 - Loss: 1.128\n",
      "Epoch 101/500 - Loss: 0.931\n",
      "Epoch 151/500 - Loss: 0.878\n",
      "Epoch 201/500 - Loss: 0.800\n",
      "Epoch 251/500 - Loss: 0.800\n",
      "Epoch 301/500 - Loss: 0.756\n",
      "Epoch 351/500 - Loss: 0.635\n",
      "Epoch 401/500 - Loss: 0.589\n",
      "Epoch 451/500 - Loss: 0.561\n",
      "\n",
      "Training model 32/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.106\n",
      "Epoch 101/500 - Loss: 0.902\n",
      "Epoch 151/500 - Loss: 0.890\n",
      "Epoch 201/500 - Loss: 0.717\n",
      "Epoch 251/500 - Loss: 0.721\n",
      "Epoch 301/500 - Loss: 0.657\n",
      "Epoch 351/500 - Loss: 0.675\n",
      "Epoch 401/500 - Loss: 0.607\n",
      "Epoch 451/500 - Loss: 0.536\n",
      "\n",
      "Training model 33/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.159\n",
      "Epoch 101/500 - Loss: 0.989\n",
      "Epoch 151/500 - Loss: 1.077\n",
      "Epoch 201/500 - Loss: 0.851\n",
      "Epoch 251/500 - Loss: 0.874\n",
      "Epoch 301/500 - Loss: 0.719\n",
      "Epoch 351/500 - Loss: 0.712\n",
      "Epoch 401/500 - Loss: 0.604\n",
      "Epoch 451/500 - Loss: 0.588\n",
      "\n",
      "Training model 34/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.128\n",
      "Epoch 101/500 - Loss: 0.895\n",
      "Epoch 151/500 - Loss: 0.855\n",
      "Epoch 201/500 - Loss: 0.756\n",
      "Epoch 251/500 - Loss: 0.734\n",
      "Epoch 301/500 - Loss: 0.667\n",
      "Epoch 351/500 - Loss: 0.633\n",
      "Epoch 401/500 - Loss: 0.560\n",
      "Epoch 451/500 - Loss: 0.615\n",
      "\n",
      "Training model 35/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.086\n",
      "Epoch 101/500 - Loss: 0.933\n",
      "Epoch 151/500 - Loss: 0.867\n",
      "Epoch 201/500 - Loss: 1.002\n",
      "Epoch 251/500 - Loss: 0.808\n",
      "Epoch 301/500 - Loss: 0.673\n",
      "Epoch 351/500 - Loss: 0.679\n",
      "Epoch 401/500 - Loss: 0.557\n",
      "Epoch 451/500 - Loss: 0.570\n",
      "\n",
      "Training model 36/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.258\n",
      "Epoch 101/500 - Loss: 0.986\n",
      "Epoch 151/500 - Loss: 0.903\n",
      "Epoch 201/500 - Loss: 0.785\n",
      "Epoch 251/500 - Loss: 0.753\n",
      "Epoch 301/500 - Loss: 0.710\n",
      "Epoch 351/500 - Loss: 0.669\n",
      "Epoch 401/500 - Loss: 0.709\n",
      "Epoch 451/500 - Loss: 0.643\n",
      "\n",
      "Training model 37/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.025\n",
      "Epoch 101/500 - Loss: 0.906\n",
      "Epoch 151/500 - Loss: 0.865\n",
      "Epoch 201/500 - Loss: 0.846\n",
      "Epoch 251/500 - Loss: 0.705\n",
      "Epoch 301/500 - Loss: 0.675\n",
      "Epoch 351/500 - Loss: 0.667\n",
      "Epoch 401/500 - Loss: 0.598\n",
      "Epoch 451/500 - Loss: 0.588\n",
      "\n",
      "Training model 38/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.150\n",
      "Epoch 101/500 - Loss: 0.984\n",
      "Epoch 151/500 - Loss: 0.887\n",
      "Epoch 201/500 - Loss: 0.832\n",
      "Epoch 251/500 - Loss: 0.767\n",
      "Epoch 301/500 - Loss: 0.738\n",
      "Epoch 351/500 - Loss: 0.706\n",
      "Epoch 401/500 - Loss: 0.690\n",
      "Epoch 451/500 - Loss: 0.630\n",
      "\n",
      "Training model 39/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.152\n",
      "Epoch 101/500 - Loss: 1.075\n",
      "Epoch 151/500 - Loss: 0.815\n",
      "Epoch 201/500 - Loss: 0.784\n",
      "Epoch 251/500 - Loss: 0.701\n",
      "Epoch 301/500 - Loss: 0.666\n",
      "Epoch 351/500 - Loss: 0.660\n",
      "Epoch 401/500 - Loss: 0.638\n",
      "Epoch 451/500 - Loss: 0.612\n",
      "\n",
      "Training model 40/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.104\n",
      "Epoch 101/500 - Loss: 0.961\n",
      "Epoch 151/500 - Loss: 0.903\n",
      "Epoch 201/500 - Loss: 0.766\n",
      "Epoch 251/500 - Loss: 0.665\n",
      "Epoch 301/500 - Loss: 0.624\n",
      "Epoch 351/500 - Loss: 0.609\n",
      "Epoch 401/500 - Loss: 0.634\n",
      "Epoch 451/500 - Loss: 0.609\n",
      "\n",
      "Training model 41/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.050\n",
      "Epoch 101/500 - Loss: 1.007\n",
      "Epoch 151/500 - Loss: 0.961\n",
      "Epoch 201/500 - Loss: 0.814\n",
      "Epoch 251/500 - Loss: 0.762\n",
      "Epoch 301/500 - Loss: 0.696\n",
      "Epoch 351/500 - Loss: 0.786\n",
      "Epoch 401/500 - Loss: 0.762\n",
      "Epoch 451/500 - Loss: 0.567\n",
      "\n",
      "Training model 42/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.176\n",
      "Epoch 101/500 - Loss: 1.015\n",
      "Epoch 151/500 - Loss: 0.954\n",
      "Epoch 201/500 - Loss: 0.826\n",
      "Epoch 251/500 - Loss: 0.780\n",
      "Epoch 301/500 - Loss: 0.730\n",
      "Epoch 351/500 - Loss: 0.704\n",
      "Epoch 401/500 - Loss: 0.664\n",
      "Epoch 451/500 - Loss: 0.582\n",
      "\n",
      "Training model 43/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.060\n",
      "Epoch 101/500 - Loss: 0.943\n",
      "Epoch 151/500 - Loss: 0.854\n",
      "Epoch 201/500 - Loss: 0.820\n",
      "Epoch 251/500 - Loss: 0.711\n",
      "Epoch 301/500 - Loss: 0.609\n",
      "Epoch 351/500 - Loss: 0.672\n",
      "Epoch 401/500 - Loss: 0.608\n",
      "Epoch 451/500 - Loss: 0.657\n",
      "\n",
      "Training model 44/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.108\n",
      "Epoch 101/500 - Loss: 0.946\n",
      "Epoch 151/500 - Loss: 0.875\n",
      "Epoch 201/500 - Loss: 0.887\n",
      "Epoch 251/500 - Loss: 0.727\n",
      "Epoch 301/500 - Loss: 0.704\n",
      "Epoch 351/500 - Loss: 0.635\n",
      "Epoch 401/500 - Loss: 0.664\n",
      "Epoch 451/500 - Loss: 0.596\n",
      "\n",
      "Training model 45/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.078\n",
      "Epoch 101/500 - Loss: 0.935\n",
      "Epoch 151/500 - Loss: 0.974\n",
      "Epoch 201/500 - Loss: 0.770\n",
      "Epoch 251/500 - Loss: 0.825\n",
      "Epoch 301/500 - Loss: 0.722\n",
      "Epoch 351/500 - Loss: 0.639\n",
      "Epoch 401/500 - Loss: 0.559\n",
      "Epoch 451/500 - Loss: 0.619\n",
      "\n",
      "Training model 46/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.168\n",
      "Epoch 101/500 - Loss: 1.012\n",
      "Epoch 151/500 - Loss: 1.694\n",
      "Epoch 201/500 - Loss: 0.874\n",
      "Epoch 251/500 - Loss: 0.761\n",
      "Epoch 301/500 - Loss: 0.698\n",
      "Epoch 351/500 - Loss: 0.648\n",
      "Epoch 401/500 - Loss: 0.614\n",
      "Epoch 451/500 - Loss: 0.663\n",
      "\n",
      "Training model 47/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.205\n",
      "Epoch 101/500 - Loss: 1.130\n",
      "Epoch 151/500 - Loss: 0.955\n",
      "Epoch 201/500 - Loss: 0.797\n",
      "Epoch 251/500 - Loss: 0.786\n",
      "Epoch 301/500 - Loss: 0.711\n",
      "Epoch 351/500 - Loss: 0.721\n",
      "Epoch 401/500 - Loss: 0.713\n",
      "Epoch 451/500 - Loss: 0.575\n",
      "\n",
      "Training model 48/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.121\n",
      "Epoch 101/500 - Loss: 0.935\n",
      "Epoch 151/500 - Loss: 0.893\n",
      "Epoch 201/500 - Loss: 0.767\n",
      "Epoch 251/500 - Loss: 0.746\n",
      "Epoch 301/500 - Loss: 0.699\n",
      "Epoch 351/500 - Loss: 0.668\n",
      "Epoch 401/500 - Loss: 0.629\n",
      "Epoch 451/500 - Loss: 0.579\n",
      "\n",
      "Training model 49/100\n",
      "Epoch 1/500 - Loss: 1.506\n",
      "Epoch 51/500 - Loss: 1.079\n",
      "Epoch 101/500 - Loss: 0.952\n",
      "Epoch 151/500 - Loss: 0.772\n",
      "Epoch 201/500 - Loss: 0.683\n",
      "Epoch 251/500 - Loss: 0.699\n",
      "Epoch 301/500 - Loss: 0.629\n",
      "Epoch 351/500 - Loss: 0.607\n",
      "Epoch 401/500 - Loss: 0.531\n",
      "Epoch 451/500 - Loss: 0.501\n",
      "\n",
      "Training model 50/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.087\n",
      "Epoch 101/500 - Loss: 0.904\n",
      "Epoch 151/500 - Loss: 0.919\n",
      "Epoch 201/500 - Loss: 0.798\n",
      "Epoch 251/500 - Loss: 0.685\n",
      "Epoch 301/500 - Loss: 0.760\n",
      "Epoch 351/500 - Loss: 0.769\n",
      "Epoch 401/500 - Loss: 0.705\n",
      "Epoch 451/500 - Loss: 0.746\n",
      "\n",
      "Training model 51/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.103\n",
      "Epoch 101/500 - Loss: 0.951\n",
      "Epoch 151/500 - Loss: 0.760\n",
      "Epoch 201/500 - Loss: 0.757\n",
      "Epoch 251/500 - Loss: 0.743\n",
      "Epoch 301/500 - Loss: 0.747\n",
      "Epoch 351/500 - Loss: 0.648\n",
      "Epoch 401/500 - Loss: 0.584\n",
      "Epoch 451/500 - Loss: 0.613\n",
      "\n",
      "Training model 52/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.131\n",
      "Epoch 101/500 - Loss: 1.112\n",
      "Epoch 151/500 - Loss: 0.940\n",
      "Epoch 201/500 - Loss: 0.868\n",
      "Epoch 251/500 - Loss: 0.872\n",
      "Epoch 301/500 - Loss: 0.805\n",
      "Epoch 351/500 - Loss: 0.805\n",
      "Epoch 401/500 - Loss: 0.736\n",
      "Epoch 451/500 - Loss: 0.730\n",
      "\n",
      "Training model 53/100\n",
      "Epoch 1/500 - Loss: 1.506\n",
      "Epoch 51/500 - Loss: 1.045\n",
      "Epoch 101/500 - Loss: 0.971\n",
      "Epoch 151/500 - Loss: 0.959\n",
      "Epoch 201/500 - Loss: 0.900\n",
      "Epoch 251/500 - Loss: 0.939\n",
      "Epoch 301/500 - Loss: 0.765\n",
      "Epoch 351/500 - Loss: 0.760\n",
      "Epoch 401/500 - Loss: 0.643\n",
      "Epoch 451/500 - Loss: 0.665\n",
      "\n",
      "Training model 54/100\n",
      "Epoch 1/500 - Loss: 1.508\n",
      "Epoch 51/500 - Loss: 1.107\n",
      "Epoch 101/500 - Loss: 1.054\n",
      "Epoch 151/500 - Loss: 0.876\n",
      "Epoch 201/500 - Loss: 0.803\n",
      "Epoch 251/500 - Loss: 0.782\n",
      "Epoch 301/500 - Loss: 0.711\n",
      "Epoch 351/500 - Loss: 0.701\n",
      "Epoch 401/500 - Loss: 0.678\n",
      "Epoch 451/500 - Loss: 0.627\n",
      "\n",
      "Training model 55/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.064\n",
      "Epoch 101/500 - Loss: 0.902\n",
      "Epoch 151/500 - Loss: 0.857\n",
      "Epoch 201/500 - Loss: 0.784\n",
      "Epoch 251/500 - Loss: 0.784\n",
      "Epoch 301/500 - Loss: 0.671\n",
      "Epoch 351/500 - Loss: 0.663\n",
      "Epoch 401/500 - Loss: 0.588\n",
      "Epoch 451/500 - Loss: 0.578\n",
      "\n",
      "Training model 56/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.068\n",
      "Epoch 101/500 - Loss: 0.906\n",
      "Epoch 151/500 - Loss: 0.841\n",
      "Epoch 201/500 - Loss: 0.738\n",
      "Epoch 251/500 - Loss: 0.645\n",
      "Epoch 301/500 - Loss: 0.645\n",
      "Epoch 351/500 - Loss: 0.572\n",
      "Epoch 401/500 - Loss: 0.557\n",
      "Epoch 451/500 - Loss: 0.480\n",
      "\n",
      "Training model 57/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.080\n",
      "Epoch 101/500 - Loss: 1.037\n",
      "Epoch 151/500 - Loss: 0.884\n",
      "Epoch 201/500 - Loss: 0.982\n",
      "Epoch 251/500 - Loss: 0.760\n",
      "Epoch 301/500 - Loss: 0.781\n",
      "Epoch 351/500 - Loss: 0.701\n",
      "Epoch 401/500 - Loss: 0.659\n",
      "Epoch 451/500 - Loss: 0.648\n",
      "\n",
      "Training model 58/100\n",
      "Epoch 1/500 - Loss: 1.506\n",
      "Epoch 51/500 - Loss: 1.220\n",
      "Epoch 101/500 - Loss: 1.005\n",
      "Epoch 151/500 - Loss: 0.856\n",
      "Epoch 201/500 - Loss: 0.814\n",
      "Epoch 251/500 - Loss: 0.793\n",
      "Epoch 301/500 - Loss: 0.724\n",
      "Epoch 351/500 - Loss: 0.746\n",
      "Epoch 401/500 - Loss: 0.706\n",
      "Epoch 451/500 - Loss: 0.607\n",
      "\n",
      "Training model 59/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.067\n",
      "Epoch 101/500 - Loss: 0.974\n",
      "Epoch 151/500 - Loss: 1.099\n",
      "Epoch 201/500 - Loss: 0.683\n",
      "Epoch 251/500 - Loss: 0.686\n",
      "Epoch 301/500 - Loss: 0.670\n",
      "Epoch 351/500 - Loss: 0.676\n",
      "Epoch 401/500 - Loss: 0.582\n",
      "Epoch 451/500 - Loss: 0.590\n",
      "\n",
      "Training model 60/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.171\n",
      "Epoch 101/500 - Loss: 1.045\n",
      "Epoch 151/500 - Loss: 0.948\n",
      "Epoch 201/500 - Loss: 0.832\n",
      "Epoch 251/500 - Loss: 0.799\n",
      "Epoch 301/500 - Loss: 0.706\n",
      "Epoch 351/500 - Loss: 0.698\n",
      "Epoch 401/500 - Loss: 0.675\n",
      "Epoch 451/500 - Loss: 0.725\n",
      "\n",
      "Training model 61/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.130\n",
      "Epoch 101/500 - Loss: 1.057\n",
      "Epoch 151/500 - Loss: 0.887\n",
      "Epoch 201/500 - Loss: 0.864\n",
      "Epoch 251/500 - Loss: 0.744\n",
      "Epoch 301/500 - Loss: 0.660\n",
      "Epoch 351/500 - Loss: 0.659\n",
      "Epoch 401/500 - Loss: 0.592\n",
      "Epoch 451/500 - Loss: 0.534\n",
      "\n",
      "Training model 62/100\n",
      "Epoch 1/500 - Loss: 1.501\n",
      "Epoch 51/500 - Loss: 1.151\n",
      "Epoch 101/500 - Loss: 1.015\n",
      "Epoch 151/500 - Loss: 0.842\n",
      "Epoch 201/500 - Loss: 0.729\n",
      "Epoch 251/500 - Loss: 0.687\n",
      "Epoch 301/500 - Loss: 0.742\n",
      "Epoch 351/500 - Loss: 0.729\n",
      "Epoch 401/500 - Loss: 0.698\n",
      "Epoch 451/500 - Loss: 0.626\n",
      "\n",
      "Training model 63/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.121\n",
      "Epoch 101/500 - Loss: 1.208\n",
      "Epoch 151/500 - Loss: 0.919\n",
      "Epoch 201/500 - Loss: 0.862\n",
      "Epoch 251/500 - Loss: 0.841\n",
      "Epoch 301/500 - Loss: 0.833\n",
      "Epoch 351/500 - Loss: 0.736\n",
      "Epoch 401/500 - Loss: 0.778\n",
      "Epoch 451/500 - Loss: 0.699\n",
      "\n",
      "Training model 64/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.107\n",
      "Epoch 101/500 - Loss: 0.919\n",
      "Epoch 151/500 - Loss: 0.800\n",
      "Epoch 201/500 - Loss: 0.736\n",
      "Epoch 251/500 - Loss: 0.703\n",
      "Epoch 301/500 - Loss: 0.682\n",
      "Epoch 351/500 - Loss: 0.645\n",
      "Epoch 401/500 - Loss: 0.601\n",
      "Epoch 451/500 - Loss: 0.562\n",
      "\n",
      "Training model 65/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.094\n",
      "Epoch 101/500 - Loss: 0.959\n",
      "Epoch 151/500 - Loss: 0.820\n",
      "Epoch 201/500 - Loss: 0.709\n",
      "Epoch 251/500 - Loss: 0.748\n",
      "Epoch 301/500 - Loss: 0.605\n",
      "Epoch 351/500 - Loss: 0.590\n",
      "Epoch 401/500 - Loss: 0.588\n",
      "Epoch 451/500 - Loss: 0.479\n",
      "\n",
      "Training model 66/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.118\n",
      "Epoch 101/500 - Loss: 0.989\n",
      "Epoch 151/500 - Loss: 0.900\n",
      "Epoch 201/500 - Loss: 0.814\n",
      "Epoch 251/500 - Loss: 0.803\n",
      "Epoch 301/500 - Loss: 0.670\n",
      "Epoch 351/500 - Loss: 0.688\n",
      "Epoch 401/500 - Loss: 0.604\n",
      "Epoch 451/500 - Loss: 0.650\n",
      "\n",
      "Training model 67/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.073\n",
      "Epoch 101/500 - Loss: 1.043\n",
      "Epoch 151/500 - Loss: 1.146\n",
      "Epoch 201/500 - Loss: 0.930\n",
      "Epoch 251/500 - Loss: 0.763\n",
      "Epoch 301/500 - Loss: 0.739\n",
      "Epoch 351/500 - Loss: 0.651\n",
      "Epoch 401/500 - Loss: 0.706\n",
      "Epoch 451/500 - Loss: 0.601\n",
      "\n",
      "Training model 68/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.077\n",
      "Epoch 101/500 - Loss: 0.933\n",
      "Epoch 151/500 - Loss: 0.842\n",
      "Epoch 201/500 - Loss: 0.760\n",
      "Epoch 251/500 - Loss: 0.677\n",
      "Epoch 301/500 - Loss: 0.700\n",
      "Epoch 351/500 - Loss: 0.632\n",
      "Epoch 401/500 - Loss: 0.627\n",
      "Epoch 451/500 - Loss: 0.577\n",
      "\n",
      "Training model 69/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.151\n",
      "Epoch 101/500 - Loss: 0.980\n",
      "Epoch 151/500 - Loss: 0.859\n",
      "Epoch 201/500 - Loss: 0.782\n",
      "Epoch 251/500 - Loss: 0.731\n",
      "Epoch 301/500 - Loss: 0.677\n",
      "Epoch 351/500 - Loss: 0.664\n",
      "Epoch 401/500 - Loss: 0.653\n",
      "Epoch 451/500 - Loss: 0.673\n",
      "\n",
      "Training model 70/100\n",
      "Epoch 1/500 - Loss: 1.506\n",
      "Epoch 51/500 - Loss: 1.094\n",
      "Epoch 101/500 - Loss: 0.907\n",
      "Epoch 151/500 - Loss: 0.938\n",
      "Epoch 201/500 - Loss: 0.712\n",
      "Epoch 251/500 - Loss: 0.614\n",
      "Epoch 301/500 - Loss: 0.577\n",
      "Epoch 351/500 - Loss: 0.510\n",
      "Epoch 401/500 - Loss: 0.531\n",
      "Epoch 451/500 - Loss: 0.401\n",
      "\n",
      "Training model 71/100\n",
      "Epoch 1/500 - Loss: 1.505\n",
      "Epoch 51/500 - Loss: 1.194\n",
      "Epoch 101/500 - Loss: 0.928\n",
      "Epoch 151/500 - Loss: 0.867\n",
      "Epoch 201/500 - Loss: 0.776\n",
      "Epoch 251/500 - Loss: 0.758\n",
      "Epoch 301/500 - Loss: 0.720\n",
      "Epoch 351/500 - Loss: 0.725\n",
      "Epoch 401/500 - Loss: 0.704\n",
      "Epoch 451/500 - Loss: 0.593\n",
      "\n",
      "Training model 72/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.165\n",
      "Epoch 101/500 - Loss: 0.938\n",
      "Epoch 151/500 - Loss: 0.980\n",
      "Epoch 201/500 - Loss: 0.826\n",
      "Epoch 251/500 - Loss: 0.697\n",
      "Epoch 301/500 - Loss: 0.820\n",
      "Epoch 351/500 - Loss: 0.750\n",
      "Epoch 401/500 - Loss: 0.656\n",
      "Epoch 451/500 - Loss: 0.587\n",
      "\n",
      "Training model 73/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.064\n",
      "Epoch 101/500 - Loss: 0.957\n",
      "Epoch 151/500 - Loss: 0.831\n",
      "Epoch 201/500 - Loss: 0.819\n",
      "Epoch 251/500 - Loss: 0.745\n",
      "Epoch 301/500 - Loss: 0.638\n",
      "Epoch 351/500 - Loss: 0.655\n",
      "Epoch 401/500 - Loss: 0.575\n",
      "Epoch 451/500 - Loss: 0.585\n",
      "\n",
      "Training model 74/100\n",
      "Epoch 1/500 - Loss: 1.506\n",
      "Epoch 51/500 - Loss: 1.115\n",
      "Epoch 101/500 - Loss: 1.089\n",
      "Epoch 151/500 - Loss: 0.985\n",
      "Epoch 201/500 - Loss: 0.934\n",
      "Epoch 251/500 - Loss: 0.864\n",
      "Epoch 301/500 - Loss: 0.867\n",
      "Epoch 351/500 - Loss: 0.849\n",
      "Epoch 401/500 - Loss: 0.908\n",
      "Epoch 451/500 - Loss: 0.828\n",
      "\n",
      "Training model 75/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.120\n",
      "Epoch 101/500 - Loss: 0.913\n",
      "Epoch 151/500 - Loss: 0.858\n",
      "Epoch 201/500 - Loss: 0.787\n",
      "Epoch 251/500 - Loss: 0.701\n",
      "Epoch 301/500 - Loss: 0.630\n",
      "Epoch 351/500 - Loss: 0.662\n",
      "Epoch 401/500 - Loss: 0.569\n",
      "Epoch 451/500 - Loss: 0.610\n",
      "\n",
      "Training model 76/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.070\n",
      "Epoch 101/500 - Loss: 1.009\n",
      "Epoch 151/500 - Loss: 0.865\n",
      "Epoch 201/500 - Loss: 0.806\n",
      "Epoch 251/500 - Loss: 0.689\n",
      "Epoch 301/500 - Loss: 0.648\n",
      "Epoch 351/500 - Loss: 0.568\n",
      "Epoch 401/500 - Loss: 0.612\n",
      "Epoch 451/500 - Loss: 0.576\n",
      "\n",
      "Training model 77/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.100\n",
      "Epoch 101/500 - Loss: 0.899\n",
      "Epoch 151/500 - Loss: 0.863\n",
      "Epoch 201/500 - Loss: 0.815\n",
      "Epoch 251/500 - Loss: 0.695\n",
      "Epoch 301/500 - Loss: 0.637\n",
      "Epoch 351/500 - Loss: 0.626\n",
      "Epoch 401/500 - Loss: 0.637\n",
      "Epoch 451/500 - Loss: 0.572\n",
      "\n",
      "Training model 78/100\n",
      "Epoch 1/500 - Loss: 1.507\n",
      "Epoch 51/500 - Loss: 1.075\n",
      "Epoch 101/500 - Loss: 0.952\n",
      "Epoch 151/500 - Loss: 0.894\n",
      "Epoch 201/500 - Loss: 0.834\n",
      "Epoch 251/500 - Loss: 0.767\n",
      "Epoch 301/500 - Loss: 0.714\n",
      "Epoch 351/500 - Loss: 0.671\n",
      "Epoch 401/500 - Loss: 0.577\n",
      "Epoch 451/500 - Loss: 0.582\n",
      "\n",
      "Training model 79/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.093\n",
      "Epoch 101/500 - Loss: 0.954\n",
      "Epoch 151/500 - Loss: 0.857\n",
      "Epoch 201/500 - Loss: 0.744\n",
      "Epoch 251/500 - Loss: 0.697\n",
      "Epoch 301/500 - Loss: 0.613\n",
      "Epoch 351/500 - Loss: 0.668\n",
      "Epoch 401/500 - Loss: 0.591\n",
      "Epoch 451/500 - Loss: 0.530\n",
      "\n",
      "Training model 80/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.170\n",
      "Epoch 101/500 - Loss: 1.220\n",
      "Epoch 151/500 - Loss: 1.088\n",
      "Epoch 201/500 - Loss: 0.864\n",
      "Epoch 251/500 - Loss: 0.757\n",
      "Epoch 301/500 - Loss: 0.723\n",
      "Epoch 351/500 - Loss: 0.699\n",
      "Epoch 401/500 - Loss: 0.646\n",
      "Epoch 451/500 - Loss: 0.567\n",
      "\n",
      "Training model 81/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.078\n",
      "Epoch 101/500 - Loss: 0.989\n",
      "Epoch 151/500 - Loss: 0.835\n",
      "Epoch 201/500 - Loss: 0.856\n",
      "Epoch 251/500 - Loss: 0.737\n",
      "Epoch 301/500 - Loss: 0.686\n",
      "Epoch 351/500 - Loss: 0.674\n",
      "Epoch 401/500 - Loss: 0.653\n",
      "Epoch 451/500 - Loss: 0.615\n",
      "\n",
      "Training model 82/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.129\n",
      "Epoch 101/500 - Loss: 0.919\n",
      "Epoch 151/500 - Loss: 0.848\n",
      "Epoch 201/500 - Loss: 0.773\n",
      "Epoch 251/500 - Loss: 0.788\n",
      "Epoch 301/500 - Loss: 0.798\n",
      "Epoch 351/500 - Loss: 0.629\n",
      "Epoch 401/500 - Loss: 0.637\n",
      "Epoch 451/500 - Loss: 0.584\n",
      "\n",
      "Training model 83/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.251\n",
      "Epoch 101/500 - Loss: 0.946\n",
      "Epoch 151/500 - Loss: 0.860\n",
      "Epoch 201/500 - Loss: 0.772\n",
      "Epoch 251/500 - Loss: 1.013\n",
      "Epoch 301/500 - Loss: 0.668\n",
      "Epoch 351/500 - Loss: 0.676\n",
      "Epoch 401/500 - Loss: 0.621\n",
      "Epoch 451/500 - Loss: 0.595\n",
      "\n",
      "Training model 84/100\n",
      "Epoch 1/500 - Loss: 1.508\n",
      "Epoch 51/500 - Loss: 1.171\n",
      "Epoch 101/500 - Loss: 0.873\n",
      "Epoch 151/500 - Loss: 0.869\n",
      "Epoch 201/500 - Loss: 0.763\n",
      "Epoch 251/500 - Loss: 0.707\n",
      "Epoch 301/500 - Loss: 0.759\n",
      "Epoch 351/500 - Loss: 0.693\n",
      "Epoch 401/500 - Loss: 0.735\n",
      "Epoch 451/500 - Loss: 0.612\n",
      "\n",
      "Training model 85/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.080\n",
      "Epoch 101/500 - Loss: 0.997\n",
      "Epoch 151/500 - Loss: 0.849\n",
      "Epoch 201/500 - Loss: 0.781\n",
      "Epoch 251/500 - Loss: 0.733\n",
      "Epoch 301/500 - Loss: 0.715\n",
      "Epoch 351/500 - Loss: 0.654\n",
      "Epoch 401/500 - Loss: 0.717\n",
      "Epoch 451/500 - Loss: 0.616\n",
      "\n",
      "Training model 86/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.165\n",
      "Epoch 101/500 - Loss: 0.952\n",
      "Epoch 151/500 - Loss: 0.855\n",
      "Epoch 201/500 - Loss: 0.820\n",
      "Epoch 251/500 - Loss: 0.911\n",
      "Epoch 301/500 - Loss: 0.715\n",
      "Epoch 351/500 - Loss: 0.697\n",
      "Epoch 401/500 - Loss: 0.687\n",
      "Epoch 451/500 - Loss: 0.643\n",
      "\n",
      "Training model 87/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.074\n",
      "Epoch 101/500 - Loss: 0.953\n",
      "Epoch 151/500 - Loss: 0.872\n",
      "Epoch 201/500 - Loss: 0.772\n",
      "Epoch 251/500 - Loss: 0.751\n",
      "Epoch 301/500 - Loss: 0.657\n",
      "Epoch 351/500 - Loss: 0.604\n",
      "Epoch 401/500 - Loss: 0.631\n",
      "Epoch 451/500 - Loss: 0.654\n",
      "\n",
      "Training model 88/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.139\n",
      "Epoch 101/500 - Loss: 0.958\n",
      "Epoch 151/500 - Loss: 0.899\n",
      "Epoch 201/500 - Loss: 0.983\n",
      "Epoch 251/500 - Loss: 0.736\n",
      "Epoch 301/500 - Loss: 0.669\n",
      "Epoch 351/500 - Loss: 0.621\n",
      "Epoch 401/500 - Loss: 0.624\n",
      "Epoch 451/500 - Loss: 0.588\n",
      "\n",
      "Training model 89/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.152\n",
      "Epoch 101/500 - Loss: 0.941\n",
      "Epoch 151/500 - Loss: 0.856\n",
      "Epoch 201/500 - Loss: 0.904\n",
      "Epoch 251/500 - Loss: 0.718\n",
      "Epoch 301/500 - Loss: 0.662\n",
      "Epoch 351/500 - Loss: 0.700\n",
      "Epoch 401/500 - Loss: 0.723\n",
      "Epoch 451/500 - Loss: 0.552\n",
      "\n",
      "Training model 90/100\n",
      "Epoch 1/500 - Loss: 1.506\n",
      "Epoch 51/500 - Loss: 1.152\n",
      "Epoch 101/500 - Loss: 0.956\n",
      "Epoch 151/500 - Loss: 0.849\n",
      "Epoch 201/500 - Loss: 0.805\n",
      "Epoch 251/500 - Loss: 0.824\n",
      "Epoch 301/500 - Loss: 0.736\n",
      "Epoch 351/500 - Loss: 0.744\n",
      "Epoch 401/500 - Loss: 0.726\n",
      "Epoch 451/500 - Loss: 0.615\n",
      "\n",
      "Training model 91/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.091\n",
      "Epoch 101/500 - Loss: 0.988\n",
      "Epoch 151/500 - Loss: 0.843\n",
      "Epoch 201/500 - Loss: 0.777\n",
      "Epoch 251/500 - Loss: 0.721\n",
      "Epoch 301/500 - Loss: 0.700\n",
      "Epoch 351/500 - Loss: 0.710\n",
      "Epoch 401/500 - Loss: 0.684\n",
      "Epoch 451/500 - Loss: 0.570\n",
      "\n",
      "Training model 92/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.084\n",
      "Epoch 101/500 - Loss: 1.018\n",
      "Epoch 151/500 - Loss: 0.891\n",
      "Epoch 201/500 - Loss: 0.769\n",
      "Epoch 251/500 - Loss: 0.718\n",
      "Epoch 301/500 - Loss: 0.683\n",
      "Epoch 351/500 - Loss: 0.657\n",
      "Epoch 401/500 - Loss: 0.606\n",
      "Epoch 451/500 - Loss: 0.699\n",
      "\n",
      "Training model 93/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.102\n",
      "Epoch 101/500 - Loss: 0.918\n",
      "Epoch 151/500 - Loss: 0.875\n",
      "Epoch 201/500 - Loss: 0.985\n",
      "Epoch 251/500 - Loss: 0.689\n",
      "Epoch 301/500 - Loss: 0.726\n",
      "Epoch 351/500 - Loss: 0.662\n",
      "Epoch 401/500 - Loss: 0.603\n",
      "Epoch 451/500 - Loss: 0.610\n",
      "\n",
      "Training model 94/100\n",
      "Epoch 1/500 - Loss: 1.511\n",
      "Epoch 51/500 - Loss: 1.154\n",
      "Epoch 101/500 - Loss: 1.110\n",
      "Epoch 151/500 - Loss: 0.929\n",
      "Epoch 201/500 - Loss: 0.824\n",
      "Epoch 251/500 - Loss: 0.745\n",
      "Epoch 301/500 - Loss: 0.819\n",
      "Epoch 351/500 - Loss: 0.647\n",
      "Epoch 401/500 - Loss: 0.625\n",
      "Epoch 451/500 - Loss: 0.662\n",
      "\n",
      "Training model 95/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.122\n",
      "Epoch 101/500 - Loss: 0.925\n",
      "Epoch 151/500 - Loss: 0.802\n",
      "Epoch 201/500 - Loss: 0.788\n",
      "Epoch 251/500 - Loss: 0.623\n",
      "Epoch 301/500 - Loss: 0.684\n",
      "Epoch 351/500 - Loss: 0.592\n",
      "Epoch 401/500 - Loss: 0.556\n",
      "Epoch 451/500 - Loss: 0.463\n",
      "\n",
      "Training model 96/100\n",
      "Epoch 1/500 - Loss: 1.510\n",
      "Epoch 51/500 - Loss: 1.104\n",
      "Epoch 101/500 - Loss: 1.108\n",
      "Epoch 151/500 - Loss: 0.913\n",
      "Epoch 201/500 - Loss: 0.845\n",
      "Epoch 251/500 - Loss: 0.798\n",
      "Epoch 301/500 - Loss: 0.709\n",
      "Epoch 351/500 - Loss: 0.671\n",
      "Epoch 401/500 - Loss: 0.714\n",
      "Epoch 451/500 - Loss: 0.649\n",
      "\n",
      "Training model 97/100\n",
      "Epoch 1/500 - Loss: 1.509\n",
      "Epoch 51/500 - Loss: 1.067\n",
      "Epoch 101/500 - Loss: 0.998\n",
      "Epoch 151/500 - Loss: 0.855\n",
      "Epoch 201/500 - Loss: 0.777\n",
      "Epoch 251/500 - Loss: 0.706\n",
      "Epoch 301/500 - Loss: 0.693\n",
      "Epoch 351/500 - Loss: 0.537\n",
      "Epoch 401/500 - Loss: 0.683\n",
      "Epoch 451/500 - Loss: 0.672\n",
      "\n",
      "Training model 98/100\n",
      "Epoch 1/500 - Loss: 1.513\n",
      "Epoch 51/500 - Loss: 1.133\n",
      "Epoch 101/500 - Loss: 1.002\n",
      "Epoch 151/500 - Loss: 0.926\n",
      "Epoch 201/500 - Loss: 0.819\n",
      "Epoch 251/500 - Loss: 0.892\n",
      "Epoch 301/500 - Loss: 0.631\n",
      "Epoch 351/500 - Loss: 0.652\n",
      "Epoch 401/500 - Loss: 0.591\n",
      "Epoch 451/500 - Loss: 0.627\n",
      "\n",
      "Training model 99/100\n",
      "Epoch 1/500 - Loss: 1.512\n",
      "Epoch 51/500 - Loss: 1.202\n",
      "Epoch 101/500 - Loss: 0.949\n",
      "Epoch 151/500 - Loss: 0.906\n",
      "Epoch 201/500 - Loss: 0.799\n",
      "Epoch 251/500 - Loss: 0.737\n",
      "Epoch 301/500 - Loss: 0.746\n",
      "Epoch 351/500 - Loss: 0.677\n",
      "Epoch 401/500 - Loss: 0.656\n",
      "Epoch 451/500 - Loss: 0.634\n",
      "\n",
      "Training model 100/100\n",
      "Epoch 1/500 - Loss: 1.514\n",
      "Epoch 51/500 - Loss: 1.100\n",
      "Epoch 101/500 - Loss: 1.016\n",
      "Epoch 151/500 - Loss: 0.879\n",
      "Epoch 201/500 - Loss: 0.845\n",
      "Epoch 251/500 - Loss: 0.803\n",
      "Epoch 301/500 - Loss: 0.772\n",
      "Epoch 351/500 - Loss: 0.733\n",
      "Epoch 401/500 - Loss: 0.722\n",
      "Epoch 451/500 - Loss: 0.646\n",
      "Training completed in 3238.72 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Training model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(train_features, train_labels['rr1_30'].values)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Training Metrics:\n",
      "Train average mean absolute error: 0.07167906134169158\n",
      "Train average mean absolute percentage error: 19.009193745176045\n",
      "Train average root mean squared error: 0.10661564330970903\n",
      "Train average R2: 0.8514694491621588\n",
      "\n",
      "Test Metrics:\n",
      "Val average mean absolute error: 0.15039265648806513\n",
      "Val average mean absolute percentage error: 39.94953426288143\n",
      "Val average root mean squared error: 0.22211521208058846\n",
      "Val average R2: 0.23387584643692105\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "print(\"Making predictions...\")\n",
    "train_pred, train_std = model.predict(train_features, return_std=True)\n",
    "test_pred, test_std = model.predict(test_features, return_std=True)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Training Metrics:\")\n",
    "\n",
    "mae, mape, rmse, rsqr = calculate_metric(train_labels.values.ravel(), train_pred.ravel())\n",
    "print(f\"Train average mean absolute error: {mae}\")\n",
    "print(f\"Train average mean absolute percentage error: {mape}\")\n",
    "print(f\"Train average root mean squared error: {rmse}\")\n",
    "print(f\"Train average R2: {rsqr}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "mae, mape, rmse, rsqr = calculate_metric(test_labels.values.ravel(), test_pred.ravel())\n",
    "print(f\"Val average mean absolute error: {mae}\")\n",
    "print(f\"Val average mean absolute percentage error: {mape}\")\n",
    "print(f\"Val average root mean squared error: {rmse}\")\n",
    "print(f\"Val average R2: {rsqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "train_df = pd.DataFrame({\n",
    "    'Actual': train_labels['rr1_30'],\n",
    "    'Predicted': train_pred,\n",
    "    'Std': train_std\n",
    "})\n",
    "train_df.to_excel(TRAINING_OUTPUT_FILE, sheet_name=SHEET_NAME, index=False)\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'Actual': test_labels['rr1_30'],\n",
    "    'Predicted': test_pred,\n",
    "    'Std': test_std\n",
    "})\n",
    "test_df.to_excel(TEST_OUTPUT_FILE, sheet_name=SHEET_NAME, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze and plot feature importance\n",
    "feature_names = train_features.columns.tolist()\n",
    "importance_df = model.plot_feature_importances(\n",
    "    feature_names=feature_names,\n",
    "    top_k=20,\n",
    "    save_path=FEATURE_IMPORTANCE_PATH\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df[['Feature', 'Combined_Importance']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted values with uncertainty\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training data\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.errorbar(train_labels['rr1_30'], train_pred, \n",
    "            yerr=2*train_std, fmt='o', alpha=0.5, \n",
    "            markersize=2, label='95% CI')\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Perfect Prediction')\n",
    "plt.xlabel('Actual Recovery Rate')\n",
    "plt.ylabel('Predicted Recovery Rate')\n",
    "plt.title('Training Set Predictions')\n",
    "plt.legend()\n",
    "\n",
    "# Test data\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.errorbar(test_labels['rr1_30'], test_pred, \n",
    "            yerr=2*test_std, fmt='o', alpha=0.5, \n",
    "            markersize=2, label='95% CI')\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Perfect Prediction')\n",
    "plt.xlabel('Actual Recovery Rate')\n",
    "plt.ylabel('Predicted Recovery Rate')\n",
    "plt.title('Test Set Predictions')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{MODEL_PATH}/predictions_with_uncertainty.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze uncertainty distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training uncertainty\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_std, bins=50, alpha=0.7)\n",
    "plt.xlabel('Standard Deviation')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Training Set Uncertainty Distribution')\n",
    "\n",
    "# Test uncertainty\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(test_std, bins=50, alpha=0.7)\n",
    "plt.xlabel('Standard Deviation')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Test Set Uncertainty Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{MODEL_PATH}/uncertainty_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print uncertainty statistics\n",
    "print(\"\\nUncertainty Statistics:\")\n",
    "print(f\"Training Set - Mean Std: {np.mean(train_std):.4f}, Median Std: {np.median(train_std):.4f}\")\n",
    "print(f\"Test Set - Mean Std: {np.mean(test_std):.4f}, Median Std: {np.median(test_std):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
