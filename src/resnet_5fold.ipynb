{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from optuna.trial import TrialState\n",
    "import statistics\n",
    "import time\n",
    "from utils import calculate_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data\"\n",
    "TRAIN_FEATURES = DATA_FOLDER + '/train_features2.xlsx'\n",
    "TRAIN_LABELS = DATA_FOLDER + \"/train_labels2.xlsx\"\n",
    "TEST_FEATURES = DATA_FOLDER + \"/test_features2.xlsx\"\n",
    "TEST_LABELS = DATA_FOLDER + \"/test_labels2.xlsx\"\n",
    "\n",
    "OUTPUT_PATH = '../output/resnet'\n",
    "TRAINING_OUTPUT_FILE = '../output/train_predictions.xlsx'\n",
    "TEST_OUTPUT_FILE = '../output/test_predictions.xlsx'\n",
    "OOF_PREDICTIONS_FILE = '../output/oof_predictions.xlsx'\n",
    "SHEET_NAME = \"resnet\"\n",
    "\n",
    "MODEL_PATH = OUTPUT_PATH + '/best_resnet_5fold__model.pth'\n",
    "BATCH_SIZE = 64\n",
    "BATCH_NORM = True\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE_LIST = [0, 1, 3]\n",
    "\n",
    "EPOCH = 500\n",
    "\n",
    "Path(OUTPUT_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df = pd.read_excel(TRAIN_FEATURES)\n",
    "train_label_df = pd.read_excel(TRAIN_LABELS)\n",
    "test_feature_df = pd.read_excel(TEST_FEATURES)\n",
    "test_label_df = pd.read_excel(TEST_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1293, 317)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "feature_list = train_feature_df.columns\n",
    "category_feature_key = ['currency', 'seniorioty_adj', 'domicile_country',\t'exchange_country',\t'Industry_sector',\t'Industry_group',\t'Industry_subgroup', 'event_type',\n",
    "                        'event_type_subcategory_sum']\n",
    "category_features = [i for i in feature_list if any(sub in i for sub in category_feature_key)]\n",
    "non_category_features = [i for i in feature_list if i not in category_features]\n",
    "\n",
    "print(len(category_features))\n",
    "print(len(non_category_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "# Prepare the ColumnTransformer\n",
    "scaler = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), non_category_features)   # StandardScaler()\n",
    "    ],\n",
    "    remainder='passthrough'  # Leave categorical features untouched\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(feature, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TUNING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNetBlock\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, dropout=0.5, batch_norm = True, activation_name='ReLU', negative_slope=0.01):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        if batch_norm:\n",
    "            self.batch_norm = nn.BatchNorm1d(in_features)\n",
    "        else:\n",
    "            self.batch_norm = nn.Identity()\n",
    "\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.relu = getattr(nn, activation_name)()\n",
    "        \n",
    "        if self.relu == nn.LeakyReLU():\n",
    "            self.relu = self.relu(negative_slope)\n",
    "            \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(out_features, in_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        resisual = x\n",
    "        out = self.batch_norm(resisual)\n",
    "        out = self.linear(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.dropout(out)\n",
    "        out += resisual # Add the input tensor to the output\n",
    "        return out\n",
    "\n",
    "# Define the Prediction layer\n",
    "class Prediction(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, batchNorm = True):\n",
    "        super(Prediction, self).__init__()\n",
    "        if batchNorm:\n",
    "            self.batch_norm = nn.BatchNorm1d(in_features)\n",
    "        else:\n",
    "            self.batch_norm = nn.Identity()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Define the ResNet model\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_dim: int, dropout: float, num_blocks: int, out_features_list: List[int], batch_norm = True, activation_name='ReLU', negative_slope=0.01):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # First linear layer to convert input_dim to the first out_features\n",
    "        self.layers.append(nn.Linear(input_dim, out_features_list[0]))\n",
    "        \n",
    "        # Add the ResNet blocks\n",
    "        for i in range(num_blocks):\n",
    "            if i > 0:\n",
    "                self.layers.append(ResNetBlock(out_features_list[0], out_features_list[i], dropout, batch_norm = batch_norm, activation_name=activation_name, negative_slope=negative_slope))\n",
    "        \n",
    "        # Add the prediction layer\n",
    "        self.prediction = Prediction(out_features_list[0], 1, batchNorm = batch_norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.prediction(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # Generate the model.\n",
    "    num_blocks = trial.suggest_int('num_blocks', 1, 5)\n",
    "    \n",
    "    out_features_list = []\n",
    "    for i in range(num_blocks):\n",
    "        out_features = trial.suggest_int(f'out_features_{i}', 10, 128)\n",
    "        out_features_list.append(out_features)\n",
    "\n",
    "    p = trial.suggest_float(\"dropout\", 0, 0.5)\n",
    "    # activation_name = trial.suggest_categorical(f'activation_{i}', ['ReLU', 'Tanh', 'LeakyReLU'])\n",
    "    # negative_slope = 0.01\n",
    "    # if activation_name == 'LeakyReLU':\n",
    "    #     negative_slope = trial.suggest_float(f\"negative_slope_{i}\", 0.01, 1)\n",
    "        \n",
    "\n",
    "    # model = ResNet(input_dim=train_features.shape[1], num_blocks=num_blocks, dropout=p, out_features_list=out_features_list, batch_norm=BATCH_NORM).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-9, 1e-1, log=True)\n",
    "\n",
    "\n",
    "    # Define cross-validation setup\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_losses = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(train_feature_df):\n",
    "        # Create training and validation datasets for the current fold\n",
    "        X_train_fold, X_val_fold = train_feature_df.iloc[train_idx], train_feature_df.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = train_label_df.iloc[train_idx], train_label_df.iloc[val_idx]\n",
    "        \n",
    "        # scaling features\n",
    "        X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold = scaler.transform(X_val_fold)\n",
    "            \n",
    "        # Initialize the model for this fold\n",
    "        model = ResNet(input_dim=X_train_fold.shape[1], num_blocks=num_blocks, dropout=p, out_features_list=out_features_list, batch_norm=BATCH_NORM) #activation_name=activation_name, negative_slope=negative_slope)\n",
    "        model = nn.DataParallel(model, device_ids = DEVICE_LIST)\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "        # define optimizer\n",
    "        if optimizer_name == \"Adam\":\n",
    "         optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        else:\n",
    "            momentum = trial.suggest_float(\"momentum\", 1e-9, 0.95, log=True)\n",
    "            optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "        \n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Prepare DataLoader for training\n",
    "        train_dataset = CustomDataset(X_train_fold, y_train_fold.to_numpy())\n",
    "        val_dataset = CustomDataset(X_val_fold, y_val_fold.to_numpy())\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "            \n",
    "        # Training of the model.\n",
    "        model.train()\n",
    "        for epoch in range(EPOCH):\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                # print(\"shape\", output.shape, target.shape)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_loader):\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                val_loss = criterion(output, target).item()\n",
    "                val_losses.append(val_loss**0.5) #rmse\n",
    "\n",
    "        trial.report(val_loss, epoch)\n",
    "\n",
    "    # Return the average validation loss across all folds\n",
    "    return np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty cache first\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-28 03:31:44,496] A new study created in memory with name: no-name-0d2789c6-e021-47f9-bb47-0bdfc994af09\n",
      "/home/nguyenhoa/miniconda3/envs/.henv/lib/python3.12/site-packages/torch/nn/modules/linear.py:116: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return F.linear(input, self.weight, self.bias)\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f59011510a0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nguyenhoa/miniconda3/envs/.henv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, timeout=600)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_blocks': 3,\n",
       " 'out_features_0': 24,\n",
       " 'out_features_1': 91,\n",
       " 'out_features_2': 54,\n",
       " 'dropout': 0.4049073766569241,\n",
       " 'optimizer': 'RMSprop',\n",
       " 'lr': 0.0002714543459380886,\n",
       " 'weight_decay': 7.006491903330438e-08,\n",
       " 'momentum': 8.011034123049581e-05}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG = {\"out_features_list\": [], \"dropout\": 0, \"optimizer\": {}, \"num_blocks\": 0}\n",
    "\n",
    "for key, value in best_params.items():\n",
    "    if \"out_features\" in key:\n",
    "        MODEL_CONFIG[\"out_features_list\"].append(value)\n",
    "    elif \"dropout\" in key:\n",
    "        MODEL_CONFIG[\"dropout\"] = value\n",
    "    elif \"negative_slope\" in key:\n",
    "        MODEL_CONFIG[\"negative_slope\"] = value\n",
    "    elif \"activation\" in key:\n",
    "        MODEL_CONFIG[\"activation_name\"] = value\n",
    "    elif \"num_blocks\" in key:\n",
    "        MODEL_CONFIG[\"num_blocks\"] = value\n",
    "    elif \"batch_size\" in key:\n",
    "        BATCH_SIZE = int(value)\n",
    "    else:\n",
    "        MODEL_CONFIG[\"optimizer\"][key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out_features_list': [24, 91, 54],\n",
       " 'dropout': 0.4049073766569241,\n",
       " 'optimizer': {'optimizer': 'RMSprop',\n",
       "  'lr': 0.0002714543459380886,\n",
       "  'weight_decay': 7.006491903330438e-08,\n",
       "  'momentum': 8.011034123049581e-05},\n",
       " 'num_blocks': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUNNING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data\n",
    "train_features = scaler.fit_transform(train_feature_df)\n",
    "test_features = scaler.transform(test_feature_df)\n",
    "\n",
    "new_feature_list = non_category_features + category_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset instances\n",
    "train_dataset = CustomDataset(train_features, train_label_df.to_numpy())\n",
    "test_dataset = CustomDataset(test_features, test_label_df.to_numpy())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_feature_df.shape[0], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=317, out_features=24, bias=True)\n",
       "    (1): ResNetBlock(\n",
       "      (batch_norm): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (linear): Linear(in_features=24, out_features=91, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.4049073766569241, inplace=False)\n",
       "      (linear2): Linear(in_features=91, out_features=24, bias=True)\n",
       "    )\n",
       "    (2): ResNetBlock(\n",
       "      (batch_norm): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (linear): Linear(in_features=24, out_features=54, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.4049073766569241, inplace=False)\n",
       "      (linear2): Linear(in_features=54, out_features=24, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (prediction): Prediction(\n",
       "    (batch_norm): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (linear): Linear(in_features=24, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config = deepcopy(MODEL_CONFIG)\n",
    "del m_config[\"optimizer\"]\n",
    "model = ResNet(input_dim=train_features.shape[1], batch_norm=BATCH_NORM, **m_config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty cache first\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=317, out_features=24, bias=True)\n",
       "      (1): ResNetBlock(\n",
       "        (batch_norm): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (linear): Linear(in_features=24, out_features=91, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dropout): Dropout(p=0.4049073766569241, inplace=False)\n",
       "        (linear2): Linear(in_features=91, out_features=24, bias=True)\n",
       "      )\n",
       "      (2): ResNetBlock(\n",
       "        (batch_norm): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (linear): Linear(in_features=24, out_features=54, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dropout): Dropout(p=0.4049073766569241, inplace=False)\n",
       "        (linear2): Linear(in_features=54, out_features=24, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (prediction): Prediction(\n",
       "      (batch_norm): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (linear): Linear(in_features=24, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.DataParallel(model, device_ids = DEVICE_LIST)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSprop (\n",
       "Parameter Group 0\n",
       "    alpha: 0.99\n",
       "    centered: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    lr: 0.0002714543459380886\n",
       "    maximize: False\n",
       "    momentum: 8.011034123049581e-05\n",
       "    weight_decay: 7.006491903330438e-08\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define optimizer\n",
    "optim_config = deepcopy(MODEL_CONFIG[\"optimizer\"])\n",
    "del optim_config[\"optimizer\"]\n",
    "\n",
    "optimizer = getattr(optim, MODEL_CONFIG[\"optimizer\"][\"optimizer\"])(model.parameters(), **optim_config)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:57<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500], Train Loss: 0.0180\n",
      "Training time: 118.053 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 500\n",
    "criterion = nn.MSELoss()\n",
    "start_time = time.time()\n",
    "\n",
    "for ep in tqdm(range(EPOCH)):\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        # print(inputs.shape, labels.shape)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print(f'[{ep + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "\n",
    "train_loss = running_loss  / len(train_loader.dataset)\n",
    "print(f'Epoch [{ep+1}], Train Loss: {train_loss:.4f}')\n",
    "\n",
    "# print out training time\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Training time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training average mean absolute error: 0.07803716510534286\n",
      "Training average mean absolute percentage error: 298.17864894866943\n",
      "Training average root mean squared error: 0.12046847110869388\n",
      "Training average R2: 0.8662272691726685\n"
     ]
    }
   ],
   "source": [
    "# Testing phase\n",
    "model.eval()\n",
    "# Lists to store predictions and targets\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        # inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        if isinstance(model, nn.DataParallel):\n",
    "            model = model.module  # Unwrap from DataParallel\n",
    "        model = model.to('cpu')\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        # Collect predictions and targets\n",
    "        all_predictions.extend(outputs.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_pred = np.array(all_predictions)\n",
    "y_true = np.array(all_targets)\n",
    "\n",
    "# save metrics\n",
    "mae, mape, rmse, rsqr = calculate_metric(y_pred, y_true)\n",
    "print(f\"Training average mean absolute error: {mae}\")\n",
    "print(f\"Training average mean absolute percentage error: {mape}\")\n",
    "print(f\"Training average root mean squared error: {rmse}\")\n",
    "print(f\"Training average R2: {rsqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test average mean absolute error: 0.16242802143096924\n",
      "Test average mean absolute percentage error: 259.7667455673218\n",
      "Test average root mean squared error: 0.24180740863491207\n",
      "Test average R2: 0.4895339012145996\n"
     ]
    }
   ],
   "source": [
    "# Testing phase\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        if isinstance(model, nn.DataParallel):\n",
    "            model = model.module  # Unwrap from DataParallel\n",
    "        model = model.to('cpu')\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        # Collect predictions and targets\n",
    "        all_predictions.extend(outputs.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_test_pred = np.array(all_predictions)\n",
    "y_test_true = np.array(all_targets)\n",
    "\n",
    "# save metrics\n",
    "mae, mape, rmse, rsqr = calculate_metric(y_test_pred, y_test_true)\n",
    "print(f\"Test average mean absolute error: {mae}\")\n",
    "print(f\"Test average mean absolute percentage error: {mape}\")\n",
    "print(f\"Test average root mean squared error: {rmse}\")\n",
    "print(f\"Test average R2: {rsqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train predictions\n",
    "train_predictions_df = pd.DataFrame({\"predictions\": y_pred.ravel()})\n",
    "with pd.ExcelWriter(TRAINING_OUTPUT_FILE, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "    # Write the new DataFrame to a new sheet\n",
    "    train_predictions_df.to_excel(writer, sheet_name=SHEET_NAME, index=False)\n",
    "    \n",
    "# save test predictions\n",
    "test_predictions_df = pd.DataFrame({\"predictions\": y_test_pred.ravel()})\n",
    "with pd.ExcelWriter(TEST_OUTPUT_FILE, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "    # Write the new DataFrame to a new sheet\n",
    "    test_predictions_df.to_excel(writer, sheet_name=SHEET_NAME, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coupon rate</th>\n",
       "      <th>SP500 MD</th>\n",
       "      <th>Average daily 1-year SP500 return</th>\n",
       "      <th>Ratio to MA</th>\n",
       "      <th>US Corporate Bond Yield Spread</th>\n",
       "      <th>US Corporate Bond Yield Spread(3-5 year)</th>\n",
       "      <th>US Corporate Bond Yield Spread(5-7 year)</th>\n",
       "      <th>US Corporate Bond Yield Spread(7-10 year)</th>\n",
       "      <th>US Corporate Bond Yield Spread(10+ year)</th>\n",
       "      <th>US Generic Govt 3 Month Yield</th>\n",
       "      <th>...</th>\n",
       "      <th>event_type_subcategory_sum_Missing Coupon payment only</th>\n",
       "      <th>event_type_subcategory_sum_Missing Interest payment</th>\n",
       "      <th>event_type_subcategory_sum_Missing Loan payment</th>\n",
       "      <th>event_type_subcategory_sum_Missing Principal payment</th>\n",
       "      <th>event_type_subcategory_sum_Others</th>\n",
       "      <th>event_type_subcategory_sum_Pre-Negotiated Chapter 11</th>\n",
       "      <th>event_type_subcategory_sum_Protection</th>\n",
       "      <th>event_type_subcategory_sum_Receivership</th>\n",
       "      <th>event_type_subcategory_sum_Rehabilitation</th>\n",
       "      <th>event_type_subcategory_sum_Restructuring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.500</td>\n",
       "      <td>-117.46020</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>125.407139</td>\n",
       "      <td>177.213028</td>\n",
       "      <td>134.012054</td>\n",
       "      <td>198.8153</td>\n",
       "      <td>191.364395</td>\n",
       "      <td>223.346344</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.000</td>\n",
       "      <td>166.38276</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>-4.603446</td>\n",
       "      <td>101.613617</td>\n",
       "      <td>77.032829</td>\n",
       "      <td>123.3998</td>\n",
       "      <td>105.932022</td>\n",
       "      <td>139.111115</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.000</td>\n",
       "      <td>119.85752</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>-11.950380</td>\n",
       "      <td>104.545959</td>\n",
       "      <td>77.416649</td>\n",
       "      <td>129.4317</td>\n",
       "      <td>111.818001</td>\n",
       "      <td>139.717407</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.125</td>\n",
       "      <td>653.51208</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>-2.494861</td>\n",
       "      <td>90.736633</td>\n",
       "      <td>64.654129</td>\n",
       "      <td>95.3731</td>\n",
       "      <td>92.141212</td>\n",
       "      <td>121.666237</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.250</td>\n",
       "      <td>231.89472</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>4.823413</td>\n",
       "      <td>98.533821</td>\n",
       "      <td>68.759308</td>\n",
       "      <td>93.4174</td>\n",
       "      <td>107.424469</td>\n",
       "      <td>139.741165</td>\n",
       "      <td>1.2865</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>3.250</td>\n",
       "      <td>147.33344</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>3.538252</td>\n",
       "      <td>128.976395</td>\n",
       "      <td>95.360374</td>\n",
       "      <td>138.8445</td>\n",
       "      <td>138.946106</td>\n",
       "      <td>172.733887</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>10.000</td>\n",
       "      <td>175.31656</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>-4.067337</td>\n",
       "      <td>121.170998</td>\n",
       "      <td>92.879501</td>\n",
       "      <td>123.2500</td>\n",
       "      <td>131.104904</td>\n",
       "      <td>162.916901</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>7.450</td>\n",
       "      <td>315.81748</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>8.604100</td>\n",
       "      <td>126.786606</td>\n",
       "      <td>89.018188</td>\n",
       "      <td>114.9728</td>\n",
       "      <td>131.522430</td>\n",
       "      <td>171.701096</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>0.500</td>\n",
       "      <td>31.75120</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-4.373852</td>\n",
       "      <td>126.595230</td>\n",
       "      <td>105.460007</td>\n",
       "      <td>121.6212</td>\n",
       "      <td>147.382416</td>\n",
       "      <td>163.772141</td>\n",
       "      <td>4.8375</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>12.000</td>\n",
       "      <td>-19.05864</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>31.582513</td>\n",
       "      <td>175.199493</td>\n",
       "      <td>142.421204</td>\n",
       "      <td>183.6181</td>\n",
       "      <td>182.215195</td>\n",
       "      <td>222.939301</td>\n",
       "      <td>0.3307</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1725 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coupon rate   SP500 MD  Average daily 1-year SP500 return  Ratio to MA  \\\n",
       "0           7.500 -117.46020                          -0.000189   125.407139   \n",
       "1           6.000  166.38276                           0.000768    -4.603446   \n",
       "2          11.000  119.85752                           0.000678   -11.950380   \n",
       "3           9.125  653.51208                           0.001638    -2.494861   \n",
       "4           9.250  231.89472                           0.000664     4.823413   \n",
       "...           ...        ...                                ...          ...   \n",
       "1720        3.250  147.33344                           0.000556     3.538252   \n",
       "1721       10.000  175.31656                           0.000554    -4.067337   \n",
       "1722        7.450  315.81748                           0.000747     8.604100   \n",
       "1723        0.500   31.75120                          -0.000157    -4.373852   \n",
       "1724       12.000  -19.05864                          -0.000058    31.582513   \n",
       "\n",
       "      US Corporate Bond Yield Spread  \\\n",
       "0                         177.213028   \n",
       "1                         101.613617   \n",
       "2                         104.545959   \n",
       "3                          90.736633   \n",
       "4                          98.533821   \n",
       "...                              ...   \n",
       "1720                      128.976395   \n",
       "1721                      121.170998   \n",
       "1722                      126.786606   \n",
       "1723                      126.595230   \n",
       "1724                      175.199493   \n",
       "\n",
       "      US Corporate Bond Yield Spread(3-5 year)  \\\n",
       "0                                   134.012054   \n",
       "1                                    77.032829   \n",
       "2                                    77.416649   \n",
       "3                                    64.654129   \n",
       "4                                    68.759308   \n",
       "...                                        ...   \n",
       "1720                                 95.360374   \n",
       "1721                                 92.879501   \n",
       "1722                                 89.018188   \n",
       "1723                                105.460007   \n",
       "1724                                142.421204   \n",
       "\n",
       "      US Corporate Bond Yield Spread(5-7 year)  \\\n",
       "0                                     198.8153   \n",
       "1                                     123.3998   \n",
       "2                                     129.4317   \n",
       "3                                      95.3731   \n",
       "4                                      93.4174   \n",
       "...                                        ...   \n",
       "1720                                  138.8445   \n",
       "1721                                  123.2500   \n",
       "1722                                  114.9728   \n",
       "1723                                  121.6212   \n",
       "1724                                  183.6181   \n",
       "\n",
       "      US Corporate Bond Yield Spread(7-10 year)  \\\n",
       "0                                    191.364395   \n",
       "1                                    105.932022   \n",
       "2                                    111.818001   \n",
       "3                                     92.141212   \n",
       "4                                    107.424469   \n",
       "...                                         ...   \n",
       "1720                                 138.946106   \n",
       "1721                                 131.104904   \n",
       "1722                                 131.522430   \n",
       "1723                                 147.382416   \n",
       "1724                                 182.215195   \n",
       "\n",
       "      US Corporate Bond Yield Spread(10+ year)  US Generic Govt 3 Month Yield  \\\n",
       "0                                   223.346344                         0.1983   \n",
       "1                                   139.111115                         0.0355   \n",
       "2                                   139.717407                         0.0101   \n",
       "3                                   121.666237                         0.0152   \n",
       "4                                   139.741165                         1.2865   \n",
       "...                                        ...                            ...   \n",
       "1720                                172.733887                         0.0000   \n",
       "1721                                162.916901                         0.7516   \n",
       "1722                                171.701096                         0.0864   \n",
       "1723                                163.772141                         4.8375   \n",
       "1724                                222.939301                         0.3307   \n",
       "\n",
       "      ...  event_type_subcategory_sum_Missing Coupon payment only  \\\n",
       "0     ...                                               True        \n",
       "1     ...                                              False        \n",
       "2     ...                                              False        \n",
       "3     ...                                              False        \n",
       "4     ...                                              False        \n",
       "...   ...                                                ...        \n",
       "1720  ...                                              False        \n",
       "1721  ...                                              False        \n",
       "1722  ...                                              False        \n",
       "1723  ...                                              False        \n",
       "1724  ...                                              False        \n",
       "\n",
       "      event_type_subcategory_sum_Missing Interest payment  \\\n",
       "0                                                 False     \n",
       "1                                                 False     \n",
       "2                                                 False     \n",
       "3                                                 False     \n",
       "4                                                 False     \n",
       "...                                                 ...     \n",
       "1720                                              False     \n",
       "1721                                               True     \n",
       "1722                                              False     \n",
       "1723                                              False     \n",
       "1724                                              False     \n",
       "\n",
       "      event_type_subcategory_sum_Missing Loan payment  \\\n",
       "0                                               False   \n",
       "1                                               False   \n",
       "2                                               False   \n",
       "3                                               False   \n",
       "4                                               False   \n",
       "...                                               ...   \n",
       "1720                                            False   \n",
       "1721                                            False   \n",
       "1722                                            False   \n",
       "1723                                            False   \n",
       "1724                                            False   \n",
       "\n",
       "      event_type_subcategory_sum_Missing Principal payment  \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "1720                                              False      \n",
       "1721                                              False      \n",
       "1722                                              False      \n",
       "1723                                              False      \n",
       "1724                                              False      \n",
       "\n",
       "      event_type_subcategory_sum_Others  \\\n",
       "0                                 False   \n",
       "1                                 False   \n",
       "2                                 False   \n",
       "3                                 False   \n",
       "4                                  True   \n",
       "...                                 ...   \n",
       "1720                              False   \n",
       "1721                              False   \n",
       "1722                              False   \n",
       "1723                              False   \n",
       "1724                              False   \n",
       "\n",
       "      event_type_subcategory_sum_Pre-Negotiated Chapter 11  \\\n",
       "0                                                 False      \n",
       "1                                                 False      \n",
       "2                                                 False      \n",
       "3                                                 False      \n",
       "4                                                 False      \n",
       "...                                                 ...      \n",
       "1720                                              False      \n",
       "1721                                              False      \n",
       "1722                                              False      \n",
       "1723                                              False      \n",
       "1724                                              False      \n",
       "\n",
       "      event_type_subcategory_sum_Protection  \\\n",
       "0                                     False   \n",
       "1                                     False   \n",
       "2                                     False   \n",
       "3                                     False   \n",
       "4                                     False   \n",
       "...                                     ...   \n",
       "1720                                  False   \n",
       "1721                                  False   \n",
       "1722                                  False   \n",
       "1723                                  False   \n",
       "1724                                  False   \n",
       "\n",
       "      event_type_subcategory_sum_Receivership  \\\n",
       "0                                       False   \n",
       "1                                       False   \n",
       "2                                       False   \n",
       "3                                       False   \n",
       "4                                       False   \n",
       "...                                       ...   \n",
       "1720                                    False   \n",
       "1721                                    False   \n",
       "1722                                    False   \n",
       "1723                                    False   \n",
       "1724                                    False   \n",
       "\n",
       "      event_type_subcategory_sum_Rehabilitation  \\\n",
       "0                                         False   \n",
       "1                                         False   \n",
       "2                                         False   \n",
       "3                                         False   \n",
       "4                                         False   \n",
       "...                                         ...   \n",
       "1720                                      False   \n",
       "1721                                      False   \n",
       "1722                                      False   \n",
       "1723                                      False   \n",
       "1724                                      False   \n",
       "\n",
       "      event_type_subcategory_sum_Restructuring  \n",
       "0                                        False  \n",
       "1                                        False  \n",
       "2                                        False  \n",
       "3                                        False  \n",
       "4                                        False  \n",
       "...                                        ...  \n",
       "1720                                     False  \n",
       "1721                                     False  \n",
       "1722                                     False  \n",
       "1723                                     False  \n",
       "1724                                     False  \n",
       "\n",
       "[1725 rows x 317 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.concat([train_feature_df, test_feature_df], axis=0, ignore_index=True)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rr1_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.082481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.378845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.836149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.987208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.021458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>0.471411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>0.823750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>0.241612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>0.762054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>0.199981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1725 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rr1_30\n",
       "0     0.082481\n",
       "1     0.378845\n",
       "2     0.836149\n",
       "3     0.987208\n",
       "4     1.021458\n",
       "...        ...\n",
       "1720  0.471411\n",
       "1721  0.823750\n",
       "1722  0.241612\n",
       "1723  0.762054\n",
       "1724  0.199981\n",
       "\n",
       "[1725 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.concat([train_label_df, test_label_df], axis=0, ignore_index=True)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "EPOCHS = 500\n",
    "val_mae = []\n",
    "val_mape = []\n",
    "val_rmse = []\n",
    "val_rsqr = []\n",
    "oof_predictions = np.zeros(labels.shape[0])\n",
    "\n",
    "\n",
    "for train_idx, val_idx in kf.split(train_feature_df):\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    # Create training and validation datasets for the current fold\n",
    "    X_train_fold, X_val_fold = features.iloc[train_idx], features.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = labels.iloc[train_idx], labels.iloc[val_idx]\n",
    "    \n",
    "    # scaling features\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "        \n",
    "    # Initialize the model for this fold\n",
    "    model = ResNet(input_dim=X_train_fold.shape[1], batch_norm=BATCH_NORM, **m_config)\n",
    "    model = nn.DataParallel(model, device_ids = DEVICE_LIST)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # define optimizer\n",
    "    optimizer = getattr(optim, MODEL_CONFIG[\"optimizer\"][\"optimizer\"])(model.parameters(), **optim_config)\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Prepare DataLoader for training\n",
    "    train_dataset = CustomDataset(X_train_fold, y_train_fold.to_numpy())\n",
    "    val_dataset = CustomDataset(X_val_fold, y_val_fold.to_numpy())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=val_dataset.features.shape[0], shuffle=True)\n",
    "        \n",
    "    # Training of the model.\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(f'Epoch [{ep+1}], Train Loss: {train_loss:.4f}')\n",
    "\n",
    "    # Validation of the model.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            # data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            if isinstance(model, nn.DataParallel):\n",
    "                model = model.module  # Unwrap from DataParallel\n",
    "            model = model.to('cpu')\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Collect predictions and targets\n",
    "        all_predictions.extend(outputs.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    y_test_pred = np.array(all_predictions).ravel()\n",
    "    y_test_true = np.array(all_targets).ravel()\n",
    "    oof_predictions[val_idx] = y_test_pred\n",
    "\n",
    "    # save metrics\n",
    "    mae, mape, rmse, rsqr = calculate_metric(y_test_pred, y_test_true)\n",
    "    val_mae.append(mae)\n",
    "    val_mape.append(mape)\n",
    "    val_rmse.append(rmse)\n",
    "    val_rsqr.append(rsqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test average mean absolute error: 0.15643084049224854\n",
      "Test average mean absolute percentage error: 4577.370375394821\n",
      "Test average root mean squared error: 0.24134598316855008\n",
      "Test average R2: 0.4652834296226501\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test average mean absolute error: {statistics.mean(val_mae)}\")\n",
    "print(f\"Test average mean absolute percentage error: {statistics.mean(val_mape)}\")\n",
    "print(f\"Test average root mean squared error: {statistics.mean(val_rmse)}\")\n",
    "print(f\"Test average R2: {statistics.mean(val_rsqr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING OUT-OF-PREDICTION RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "EPOCHS = 500\n",
    "val_mae = []\n",
    "val_mape = []\n",
    "val_rmse = []\n",
    "val_rsqr = []\n",
    "oof_predictions = np.zeros(train_label_df.shape[0])\n",
    "\n",
    "\n",
    "for train_idx, val_idx in kf.split(train_feature_df):\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    # Create training and validation datasets for the current fold\n",
    "    X_train_fold, X_val_fold = train_feature_df.iloc[train_idx], train_feature_df.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = train_label_df.iloc[train_idx], train_label_df.iloc[val_idx]\n",
    "    \n",
    "    # scaling features\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "        \n",
    "    # Initialize the model for this fold\n",
    "    model = ResNet(input_dim=X_train_fold.shape[1], batch_norm=BATCH_NORM, **m_config)\n",
    "    model = nn.DataParallel(model, device_ids = DEVICE_LIST)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # define optimizer\n",
    "    optimizer = getattr(optim, MODEL_CONFIG[\"optimizer\"][\"optimizer\"])(model.parameters(), **optim_config)\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Prepare DataLoader for training\n",
    "    train_dataset = CustomDataset(X_train_fold, y_train_fold.to_numpy())\n",
    "    val_dataset = CustomDataset(X_val_fold, y_val_fold.to_numpy())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=val_dataset.features.shape[0], shuffle=False)\n",
    "        \n",
    "    # Training of the model.\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(f'Epoch [{ep+1}], Train Loss: {train_loss:.4f}')\n",
    "\n",
    "    # Validation of the model.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            # data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            if isinstance(model, nn.DataParallel):\n",
    "                model = model.module  # Unwrap from DataParallel\n",
    "            model = model.to('cpu')\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Collect predictions and targets\n",
    "        all_predictions.extend(outputs.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    y_test_pred = np.array(all_predictions).ravel()\n",
    "    y_test_true = np.array(all_targets).ravel()\n",
    "    oof_predictions[val_idx] = y_test_pred\n",
    "\n",
    "    # save metrics\n",
    "    mae, mape, rmse, rsqr = calculate_metric(y_test_pred, y_test_true)\n",
    "    val_mae.append(mae)\n",
    "    val_mape.append(mape)\n",
    "    val_rmse.append(rmse)\n",
    "    val_rsqr.append(rsqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_predictions_df = pd.DataFrame({\"predictions\": oof_predictions.ravel()})\n",
    "with pd.ExcelWriter(OOF_PREDICTIONS_FILE, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "    # Write the new DataFrame to a new sheet\n",
    "    oof_predictions_df.to_excel(writer, sheet_name=SHEET_NAME, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".henv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
