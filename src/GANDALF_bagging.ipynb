{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import joblib\n",
    "\n",
    "import statistics\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from utils import calculate_metric\n",
    "\n",
    "from pytorch_tabular.models import GANDALFConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    "    ExperimentConfig\n",
    ")\n",
    "from pytorch_tabular import TabularModel\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12f640050>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"../data/data_removing_na.xlsx\"\n",
    "MODEL_PATH = '../output/GANDALF_bagging'\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PROJECT_NAME = \"run/GANDALF_bagging\"\n",
    "TRAINING_OUTPUT_FILE = '../output/train_predictions.xlsx'\n",
    "TEST_OUTPUT_FILE = '../output/test_predictions.xlsx'\n",
    "SHEET_NAME = \"GANDALF_bagging\"\n",
    "OUTPUT_FILE = MODEL_PATH + '/GANDALF_bagging.pkl'\n",
    "\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rr1_30</th>\n",
       "      <th>currency</th>\n",
       "      <th>seniorioty_adj</th>\n",
       "      <th>coupon rate</th>\n",
       "      <th>domicile_country</th>\n",
       "      <th>exchange_country</th>\n",
       "      <th>Industry_sector</th>\n",
       "      <th>Industry_group</th>\n",
       "      <th>Industry_subgroup</th>\n",
       "      <th>event_type</th>\n",
       "      <th>...</th>\n",
       "      <th>PD_55_pd</th>\n",
       "      <th>PD_56_pd</th>\n",
       "      <th>PD_57_pd</th>\n",
       "      <th>PD_58_pd</th>\n",
       "      <th>PD_59_pd</th>\n",
       "      <th>PD_60_pd</th>\n",
       "      <th>DTD</th>\n",
       "      <th>NI_Over_TA</th>\n",
       "      <th>Size</th>\n",
       "      <th>defaulted_in_last_6_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259908</td>\n",
       "      <td>USD</td>\n",
       "      <td>Senior Subordinated Unsecured</td>\n",
       "      <td>9.000</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Retail &amp; Whsle - Discretionary</td>\n",
       "      <td>E-Commerce Discretionary</td>\n",
       "      <td>Bankruptcy Filing</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396731</td>\n",
       "      <td>0.397453</td>\n",
       "      <td>0.398148</td>\n",
       "      <td>0.398819</td>\n",
       "      <td>0.399467</td>\n",
       "      <td>0.400092</td>\n",
       "      <td>-0.732815</td>\n",
       "      <td>-0.007137</td>\n",
       "      <td>-0.852484</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032729</td>\n",
       "      <td>USD</td>\n",
       "      <td>Senior Subordinated Unsecured</td>\n",
       "      <td>5.750</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Facilities &amp; Svcs</td>\n",
       "      <td>Default Corp Action</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957454</td>\n",
       "      <td>0.957467</td>\n",
       "      <td>0.957480</td>\n",
       "      <td>0.957492</td>\n",
       "      <td>0.957503</td>\n",
       "      <td>0.957514</td>\n",
       "      <td>-1.666262</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-1.186347</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972400</td>\n",
       "      <td>USD</td>\n",
       "      <td>Unsecured</td>\n",
       "      <td>5.675</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Retail &amp; Whsle - Discretionary</td>\n",
       "      <td>Wholesale - Discretionary</td>\n",
       "      <td>Default Corp Action</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568169</td>\n",
       "      <td>0.568693</td>\n",
       "      <td>0.569197</td>\n",
       "      <td>0.569682</td>\n",
       "      <td>0.570150</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>-1.853366</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1.053677</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.047416</td>\n",
       "      <td>CHF</td>\n",
       "      <td>Unsecured</td>\n",
       "      <td>0.125</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Retail &amp; Whsle - Discretionary</td>\n",
       "      <td>Wholesale - Discretionary</td>\n",
       "      <td>Default Corp Action</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568169</td>\n",
       "      <td>0.568693</td>\n",
       "      <td>0.569197</td>\n",
       "      <td>0.569682</td>\n",
       "      <td>0.570150</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>-1.853366</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1.053677</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.848872</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Unsecured</td>\n",
       "      <td>1.750</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Products</td>\n",
       "      <td>Electrical Equipment</td>\n",
       "      <td>Bankruptcy Filing</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130285</td>\n",
       "      <td>0.130688</td>\n",
       "      <td>0.131081</td>\n",
       "      <td>0.131465</td>\n",
       "      <td>0.131840</td>\n",
       "      <td>0.132206</td>\n",
       "      <td>-0.768857</td>\n",
       "      <td>-0.028058</td>\n",
       "      <td>-1.946507</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rr1_30 currency                 seniorioty_adj  coupon rate  \\\n",
       "0  0.259908      USD  Senior Subordinated Unsecured        9.000   \n",
       "1  0.032729      USD  Senior Subordinated Unsecured        5.750   \n",
       "2  0.972400      USD                      Unsecured        5.675   \n",
       "3  1.047416      CHF                      Unsecured        0.125   \n",
       "4  0.848872      JPY                      Unsecured        1.750   \n",
       "\n",
       "  domicile_country exchange_country         Industry_sector  \\\n",
       "0    United States    United States  Consumer Discretionary   \n",
       "1    United States    United States             Health Care   \n",
       "2      South Korea      South Korea  Consumer Discretionary   \n",
       "3      South Korea      South Korea  Consumer Discretionary   \n",
       "4            Japan            Japan             Industrials   \n",
       "\n",
       "                   Industry_group              Industry_subgroup  \\\n",
       "0  Retail & Whsle - Discretionary       E-Commerce Discretionary   \n",
       "1                     Health Care  Health Care Facilities & Svcs   \n",
       "2  Retail & Whsle - Discretionary      Wholesale - Discretionary   \n",
       "3  Retail & Whsle - Discretionary      Wholesale - Discretionary   \n",
       "4             Industrial Products           Electrical Equipment   \n",
       "\n",
       "            event_type  ...  PD_55_pd  PD_56_pd  PD_57_pd  PD_58_pd  PD_59_pd  \\\n",
       "0    Bankruptcy Filing  ...  0.396731  0.397453  0.398148  0.398819  0.399467   \n",
       "1  Default Corp Action  ...  0.957454  0.957467  0.957480  0.957492  0.957503   \n",
       "2  Default Corp Action  ...  0.568169  0.568693  0.569197  0.569682  0.570150   \n",
       "3  Default Corp Action  ...  0.568169  0.568693  0.569197  0.569682  0.570150   \n",
       "4    Bankruptcy Filing  ...  0.130285  0.130688  0.131081  0.131465  0.131840   \n",
       "\n",
       "   PD_60_pd       DTD  NI_Over_TA      Size  defaulted_in_last_6_months  \n",
       "0  0.400092 -0.732815   -0.007137 -0.852484                       False  \n",
       "1  0.957514 -1.666262   -0.000286 -1.186347                       False  \n",
       "2  0.570600 -1.853366    0.000191  1.053677                       False  \n",
       "3  0.570600 -1.853366    0.000191  1.053677                       False  \n",
       "4  0.132206 -0.768857   -0.028058 -1.946507                       False  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1725, 165)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = df.columns\n",
    "feature_list = feature_list.drop('rr1_30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['currency', 'seniorioty_adj', 'coupon rate', 'domicile_country',\n",
       "       'exchange_country', 'Industry_sector', 'Industry_group',\n",
       "       'Industry_subgroup', 'event_type', 'event_type_subcategory_sum',\n",
       "       ...\n",
       "       'PD_55_pd', 'PD_56_pd', 'PD_57_pd', 'PD_58_pd', 'PD_59_pd', 'PD_60_pd',\n",
       "       'DTD', 'NI_Over_TA', 'Size', 'defaulted_in_last_6_months'],\n",
       "      dtype='object', length=164)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_features = list(df.select_dtypes(include=['object', 'bool']).columns)\n",
    "non_category_features = [i for i in feature_list if i not in category_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(non_category_features))\n",
    "print(len(category_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['currency',\n",
       " 'seniorioty_adj',\n",
       " 'domicile_country',\n",
       " 'exchange_country',\n",
       " 'Industry_sector',\n",
       " 'Industry_group',\n",
       " 'Industry_subgroup',\n",
       " 'event_type',\n",
       " 'event_type_subcategory_sum',\n",
       " 'defaulted_in_last_5_years',\n",
       " 'defaulted_in_last_6_months']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test set\n",
    "test_size = 0.25\n",
    "train, test = train_test_split(df, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rr1_30</th>\n",
       "      <th>currency</th>\n",
       "      <th>seniorioty_adj</th>\n",
       "      <th>coupon rate</th>\n",
       "      <th>domicile_country</th>\n",
       "      <th>exchange_country</th>\n",
       "      <th>Industry_sector</th>\n",
       "      <th>Industry_group</th>\n",
       "      <th>Industry_subgroup</th>\n",
       "      <th>event_type</th>\n",
       "      <th>...</th>\n",
       "      <th>PD_55_pd</th>\n",
       "      <th>PD_56_pd</th>\n",
       "      <th>PD_57_pd</th>\n",
       "      <th>PD_58_pd</th>\n",
       "      <th>PD_59_pd</th>\n",
       "      <th>PD_60_pd</th>\n",
       "      <th>DTD</th>\n",
       "      <th>NI_Over_TA</th>\n",
       "      <th>Size</th>\n",
       "      <th>defaulted_in_last_6_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0.082481</td>\n",
       "      <td>USD</td>\n",
       "      <td>Senior Unsecured</td>\n",
       "      <td>7.500</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Oil &amp; Gas</td>\n",
       "      <td>Oil &amp; Gas Producers</td>\n",
       "      <td>Default Corp Action</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691011</td>\n",
       "      <td>0.691382</td>\n",
       "      <td>0.691738</td>\n",
       "      <td>0.692080</td>\n",
       "      <td>0.692408</td>\n",
       "      <td>0.692725</td>\n",
       "      <td>-1.084433</td>\n",
       "      <td>-0.052027</td>\n",
       "      <td>-2.074964</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0.378845</td>\n",
       "      <td>USD</td>\n",
       "      <td>Unsecured</td>\n",
       "      <td>6.000</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Metals &amp; Mining</td>\n",
       "      <td>Default Corp Action</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183801</td>\n",
       "      <td>0.184996</td>\n",
       "      <td>0.186167</td>\n",
       "      <td>0.187313</td>\n",
       "      <td>0.188437</td>\n",
       "      <td>0.189539</td>\n",
       "      <td>-0.540409</td>\n",
       "      <td>0.017209</td>\n",
       "      <td>0.864692</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>0.836149</td>\n",
       "      <td>USD</td>\n",
       "      <td>Senior Secured</td>\n",
       "      <td>11.000</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Metals &amp; Mining</td>\n",
       "      <td>Default Corp Action</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278774</td>\n",
       "      <td>0.280216</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.284290</td>\n",
       "      <td>0.285571</td>\n",
       "      <td>0.754647</td>\n",
       "      <td>-0.010395</td>\n",
       "      <td>-0.342209</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>0.987208</td>\n",
       "      <td>USD</td>\n",
       "      <td>Senior Secured</td>\n",
       "      <td>9.125</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Oil &amp; Gas</td>\n",
       "      <td>Oil &amp; Gas Services &amp; Equip</td>\n",
       "      <td>Default Corp Action</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190375</td>\n",
       "      <td>0.191471</td>\n",
       "      <td>0.192544</td>\n",
       "      <td>0.193594</td>\n",
       "      <td>0.194622</td>\n",
       "      <td>0.195628</td>\n",
       "      <td>-0.242080</td>\n",
       "      <td>-0.022618</td>\n",
       "      <td>-2.808528</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>1.021458</td>\n",
       "      <td>USD</td>\n",
       "      <td>Senior Secured</td>\n",
       "      <td>9.250</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Oil &amp; Gas</td>\n",
       "      <td>Oil &amp; Gas Producers</td>\n",
       "      <td>Default Corp Action</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149501</td>\n",
       "      <td>0.150930</td>\n",
       "      <td>0.152327</td>\n",
       "      <td>0.153692</td>\n",
       "      <td>0.155027</td>\n",
       "      <td>0.156332</td>\n",
       "      <td>1.138686</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.085154</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rr1_30 currency    seniorioty_adj  coupon rate domicile_country  \\\n",
       "755   0.082481      USD  Senior Unsecured        7.500    United States   \n",
       "588   0.378845      USD         Unsecured        6.000        Indonesia   \n",
       "585   0.836149      USD    Senior Secured       11.000    United States   \n",
       "1329  0.987208      USD    Senior Secured        9.125    United States   \n",
       "973   1.021458      USD    Senior Secured        9.250    United States   \n",
       "\n",
       "     exchange_country Industry_sector Industry_group  \\\n",
       "755     United States          Energy      Oil & Gas   \n",
       "588         Indonesia       Materials      Materials   \n",
       "585     United States       Materials      Materials   \n",
       "1329    United States          Energy      Oil & Gas   \n",
       "973     United States          Energy      Oil & Gas   \n",
       "\n",
       "               Industry_subgroup           event_type  ...  PD_55_pd  \\\n",
       "755          Oil & Gas Producers  Default Corp Action  ...  0.691011   \n",
       "588              Metals & Mining  Default Corp Action  ...  0.183801   \n",
       "585              Metals & Mining  Default Corp Action  ...  0.278774   \n",
       "1329  Oil & Gas Services & Equip  Default Corp Action  ...  0.190375   \n",
       "973          Oil & Gas Producers  Default Corp Action  ...  0.149501   \n",
       "\n",
       "      PD_56_pd  PD_57_pd  PD_58_pd  PD_59_pd  PD_60_pd       DTD  NI_Over_TA  \\\n",
       "755   0.691382  0.691738  0.692080  0.692408  0.692725 -1.084433   -0.052027   \n",
       "588   0.184996  0.186167  0.187313  0.188437  0.189539 -0.540409    0.017209   \n",
       "585   0.280216  0.281615  0.282972  0.284290  0.285571  0.754647   -0.010395   \n",
       "1329  0.191471  0.192544  0.193594  0.194622  0.195628 -0.242080   -0.022618   \n",
       "973   0.150930  0.152327  0.153692  0.155027  0.156332  1.138686    0.000033   \n",
       "\n",
       "          Size  defaulted_in_last_6_months  \n",
       "755  -2.074964                       False  \n",
       "588   0.864692                       False  \n",
       "585  -0.342209                       False  \n",
       "1329 -2.808528                       False  \n",
       "973  -0.085154                       False  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TUNING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "target_col = 'rr1_30'\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=[\n",
    "        target_col\n",
    "    ],  # target should always be a list\n",
    "    continuous_cols=non_category_features,\n",
    "    categorical_cols=category_features,\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "experiment_config = ExperimentConfig(project_name=PROJECT_NAME,exp_watch=\"all\",log_target=\"tensorboard\")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_epochs=EPOCHS,\n",
    "    early_stopping=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    #Number of layers in the feature abstraction\n",
    "    gflu_stages = trial.suggest_int(\"gflu_stages\", 1, 10, log=True)\n",
    "    \n",
    "    #initial percentage of features to be selected in each GFLU stage.\n",
    "    gflu_feature_init_sparsity = trial.suggest_float(\"gflu_feature_init_sparsity\", 0.1, 1, log=True)\n",
    "    gflu_dropout = trial.suggest_float(\"gflu_dropout\", 0, 0.5)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    \n",
    "    model_config = GANDALFConfig(\n",
    "            task=\"regression\",\n",
    "            gflu_stages=gflu_stages,    #Number of layers in the feature abstraction\n",
    "            gflu_feature_init_sparsity=gflu_feature_init_sparsity, #initial percentage of features to be selected in each GFLU stage.\n",
    "            gflu_dropout=gflu_dropout,\n",
    "            learning_rate=lr,\n",
    "        )\n",
    "    # Initialize the model\n",
    "    tabular_model = TabularModel(\n",
    "            data_config=data_config,\n",
    "            model_config=model_config,\n",
    "            optimizer_config=optimizer_config,\n",
    "            trainer_config=trainer_config,\n",
    "            experiment_config=experiment_config,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    # training with 5-fold CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = []\n",
    "\n",
    "    for index, (train_idx, val_idx) in enumerate(kf.split(train)):\n",
    "        # Create training and validation datasets for the current fold\n",
    "        train_fold, val_fold = train.iloc[train_idx], train.iloc[val_idx]\n",
    "            \n",
    "        # Train the model\n",
    "        bagged_pred_df = tabular_model.bagging_predict(\n",
    "            cv=5, train=train_fold, test=val_fold, aggregate=\"mean\"\n",
    "        )\n",
    "        mae, mape, rmse, rsqr = calculate_metric(bagged_pred_df.to_numpy().squeeze(), val_fold[target_col].to_numpy())\n",
    "        mse_scores.append(rmse)\n",
    "\n",
    "        trial.report(rmse, index)\n",
    "\n",
    "    # Return the average validation loss across all folds\n",
    "    return np.mean(mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 09:53:43,886] A new study created in memory with name: no-name-1e4fc111-27de-41a4-a67f-8c8c4aa523d3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:53:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">924</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:53:43\u001b[0m,\u001b[1;36m924\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:53:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">926</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:53:43\u001b[0m,\u001b[1;36m926\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:53:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">930</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:53:43\u001b[0m,\u001b[1;36m930\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:53:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">972</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:53:43\u001b[0m,\u001b[1;36m972\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:53:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">050</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:53:44\u001b[0m,\u001b[1;36m050\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:53:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">065</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:53:44\u001b[0m,\u001b[1;36m065\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:53:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">077</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:53:44\u001b[0m,\u001b[1;36m077\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    240 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    240 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b90fbbb88fc4baba0089bed9668869d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">030</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:56:00\u001b[0m,\u001b[1;36m030\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">032</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:56:00\u001b[0m,\u001b[1;36m032\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">174</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:56:00\u001b[0m,\u001b[1;36m174\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">191</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:56:00\u001b[0m,\u001b[1;36m191\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">195</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:56:00\u001b[0m,\u001b[1;36m195\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:56:00\u001b[0m,\u001b[1;36m202\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">294</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:56:00\u001b[0m,\u001b[1;36m294\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">448</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:56:00\u001b[0m,\u001b[1;36m448\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">468</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:56:00\u001b[0m,\u001b[1;36m468\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:56:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">529</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:56:00\u001b[0m,\u001b[1;36m529\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    239 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    239 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69283a666b5547de87de0c73f7ed4507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:58:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">412</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:58:13\u001b[0m,\u001b[1;36m412\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:58:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">413</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:58:13\u001b[0m,\u001b[1;36m413\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:58:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">491</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:58:13\u001b[0m,\u001b[1;36m491\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:58:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">514</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:58:13\u001b[0m,\u001b[1;36m514\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:58:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">518</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:58:13\u001b[0m,\u001b[1;36m518\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:58:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">527</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:58:13\u001b[0m,\u001b[1;36m527\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:58:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">595</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:58:13\u001b[0m,\u001b[1;36m595\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:58:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">743</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:58:13\u001b[0m,\u001b[1;36m743\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:58:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">764</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:58:13\u001b[0m,\u001b[1;36m764\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">09:58:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">836</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m09:58:13\u001b[0m,\u001b[1;36m836\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    239 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    239 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556c842367cb4f3a80343e17d3b276db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">816</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:00:13\u001b[0m,\u001b[1;36m816\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">819</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:00:13\u001b[0m,\u001b[1;36m819\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">954</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:00:13\u001b[0m,\u001b[1;36m954\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">973</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:00:13\u001b[0m,\u001b[1;36m973\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">978</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:00:13\u001b[0m,\u001b[1;36m978\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">985</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:00:13\u001b[0m,\u001b[1;36m985\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">064</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:00:14\u001b[0m,\u001b[1;36m064\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">201</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:00:14\u001b[0m,\u001b[1;36m201\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">222</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:00:14\u001b[0m,\u001b[1;36m222\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:00:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">296</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:00:14\u001b[0m,\u001b[1;36m296\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    239 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    239 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b9e1a9588944a8b1dce717644208e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:02:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">489</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:02:45\u001b[0m,\u001b[1;36m489\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:02:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">491</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:02:45\u001b[0m,\u001b[1;36m491\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:02:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">590</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:02:45\u001b[0m,\u001b[1;36m590\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:02:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">610</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:02:45\u001b[0m,\u001b[1;36m610\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:02:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">616</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:02:45\u001b[0m,\u001b[1;36m616\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:02:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">629</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:02:45\u001b[0m,\u001b[1;36m629\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:02:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">699</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:02:45\u001b[0m,\u001b[1;36m699\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:02:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">931</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:02:45\u001b[0m,\u001b[1;36m931\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:02:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">953</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:02:45\u001b[0m,\u001b[1;36m953\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:02:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">056</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:02:46\u001b[0m,\u001b[1;36m056\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    239 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    239 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408b230ec5b1420d876aa42597f0768d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:04:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">013</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:04:49\u001b[0m,\u001b[1;36m013\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:04:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">015</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:04:49\u001b[0m,\u001b[1;36m015\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:04:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">205</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:04:49\u001b[0m,\u001b[1;36m205\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:04:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">229</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:04:49\u001b[0m,\u001b[1;36m229\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:04:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">232</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:04:49\u001b[0m,\u001b[1;36m232\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:04:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">245</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:04:49\u001b[0m,\u001b[1;36m245\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:04:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">320</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:04:49\u001b[0m,\u001b[1;36m320\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:04:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">459</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:04:49\u001b[0m,\u001b[1;36m459\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:04:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">717</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:04:49\u001b[0m,\u001b[1;36m717\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:04:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">784</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:04:49\u001b[0m,\u001b[1;36m784\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fe95867bf44cd3a94411b04bcbda4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:06:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">517</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:06:53\u001b[0m,\u001b[1;36m517\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:06:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">519</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:06:53\u001b[0m,\u001b[1;36m519\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:06:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">631</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:06:53\u001b[0m,\u001b[1;36m631\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:06:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">650</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:06:53\u001b[0m,\u001b[1;36m650\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:06:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:06:53\u001b[0m,\u001b[1;36m652\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:06:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">660</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:06:53\u001b[0m,\u001b[1;36m660\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:06:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">738</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:06:53\u001b[0m,\u001b[1;36m738\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:06:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">881</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:06:53\u001b[0m,\u001b[1;36m881\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:06:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">902</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:06:53\u001b[0m,\u001b[1;36m902\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:06:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">977</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:06:53\u001b[0m,\u001b[1;36m977\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    241 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    241 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61401eaf80dc4e398812febf1e817703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:08:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">751</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:08:55\u001b[0m,\u001b[1;36m751\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:08:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">753</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:08:55\u001b[0m,\u001b[1;36m753\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:08:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">028</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:08:56\u001b[0m,\u001b[1;36m028\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:08:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">048</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:08:56\u001b[0m,\u001b[1;36m048\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:08:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">052</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:08:56\u001b[0m,\u001b[1;36m052\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:08:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">067</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:08:56\u001b[0m,\u001b[1;36m067\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:08:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">139</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:08:56\u001b[0m,\u001b[1;36m139\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:08:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">283</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:08:56\u001b[0m,\u001b[1;36m283\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:08:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">303</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:08:56\u001b[0m,\u001b[1;36m303\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:08:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">374</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:08:56\u001b[0m,\u001b[1;36m374\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    241 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    241 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4be58eec1fd41bcb9c1426ca6c82741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:11:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">876</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:11:21\u001b[0m,\u001b[1;36m876\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:11:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">879</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:11:21\u001b[0m,\u001b[1;36m879\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:11:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:11:22\u001b[0m,\u001b[1;36m122\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:11:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">158</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:11:22\u001b[0m,\u001b[1;36m158\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:11:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">166</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:11:22\u001b[0m,\u001b[1;36m166\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:11:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">176</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:11:22\u001b[0m,\u001b[1;36m176\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:11:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">306</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:11:22\u001b[0m,\u001b[1;36m306\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:11:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">460</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:11:22\u001b[0m,\u001b[1;36m460\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:11:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">483</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:11:22\u001b[0m,\u001b[1;36m483\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:11:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">582</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:11:22\u001b[0m,\u001b[1;36m582\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e02892fc6804f8a9301b1c60793266d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:14:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">690</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:14:15\u001b[0m,\u001b[1;36m690\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:14:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">692</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:14:15\u001b[0m,\u001b[1;36m692\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:14:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">074</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:14:16\u001b[0m,\u001b[1;36m074\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:14:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">096</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:14:16\u001b[0m,\u001b[1;36m096\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:14:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:14:16\u001b[0m,\u001b[1;36m102\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:14:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:14:16\u001b[0m,\u001b[1;36m112\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:14:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">241</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:14:16\u001b[0m,\u001b[1;36m241\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:14:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">408</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:14:16\u001b[0m,\u001b[1;36m408\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:14:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">431</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:14:16\u001b[0m,\u001b[1;36m431\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:14:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">511</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:14:16\u001b[0m,\u001b[1;36m511\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0075b86fabf4b088abd60288e3a919e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:17:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:17:13\u001b[0m,\u001b[1;36m524\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:17:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">526</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:17:13\u001b[0m,\u001b[1;36m526\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:17:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">648</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:17:13\u001b[0m,\u001b[1;36m648\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:17:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">675</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:17:13\u001b[0m,\u001b[1;36m675\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:17:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">679</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:17:13\u001b[0m,\u001b[1;36m679\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:17:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">698</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:17:13\u001b[0m,\u001b[1;36m698\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:17:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">999</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:17:13\u001b[0m,\u001b[1;36m999\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:17:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">170</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:17:14\u001b[0m,\u001b[1;36m170\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:17:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">190</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:17:14\u001b[0m,\u001b[1;36m190\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:17:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">267</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:17:14\u001b[0m,\u001b[1;36m267\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1bb8556041b4f39adf63125c27db780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:19:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">703</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:19:19\u001b[0m,\u001b[1;36m703\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:19:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">705</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:19:19\u001b[0m,\u001b[1;36m705\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:19:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">796</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:19:19\u001b[0m,\u001b[1;36m796\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:19:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">815</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:19:19\u001b[0m,\u001b[1;36m815\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:19:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">818</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:19:19\u001b[0m,\u001b[1;36m818\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:19:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">825</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:19:19\u001b[0m,\u001b[1;36m825\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:19:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">893</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:19:19\u001b[0m,\u001b[1;36m893\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:19:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">039</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:19:20\u001b[0m,\u001b[1;36m039\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:19:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">060</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:19:20\u001b[0m,\u001b[1;36m060\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:19:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">132</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:19:20\u001b[0m,\u001b[1;36m132\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    240 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    240 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aba35b3f8b1490fabe96731aac6fa40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:21:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">872</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:21:24\u001b[0m,\u001b[1;36m872\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:21:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">874</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:21:24\u001b[0m,\u001b[1;36m874\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:21:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">024</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:21:25\u001b[0m,\u001b[1;36m024\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:21:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">046</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:21:25\u001b[0m,\u001b[1;36m046\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:21:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">051</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:21:25\u001b[0m,\u001b[1;36m051\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:21:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">062</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:21:25\u001b[0m,\u001b[1;36m062\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:21:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">168</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:21:25\u001b[0m,\u001b[1;36m168\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:21:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:21:25\u001b[0m,\u001b[1;36m314\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:21:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">335</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:21:25\u001b[0m,\u001b[1;36m335\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:21:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">413</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:21:25\u001b[0m,\u001b[1;36m413\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    242 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    242 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777ea7ed129e4285bcaa7758f5f82c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:23:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:23:56\u001b[0m,\u001b[1;36m905\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:23:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">907</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:23:56\u001b[0m,\u001b[1;36m907\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:23:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">001</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:23:57\u001b[0m,\u001b[1;36m001\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:23:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">020</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:23:57\u001b[0m,\u001b[1;36m020\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:23:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">024</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:23:57\u001b[0m,\u001b[1;36m024\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:23:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">032</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:23:57\u001b[0m,\u001b[1;36m032\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:23:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:23:57\u001b[0m,\u001b[1;36m105\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:23:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">245</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:23:57\u001b[0m,\u001b[1;36m245\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:23:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">268</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:23:57\u001b[0m,\u001b[1;36m268\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:23:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">341</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:23:57\u001b[0m,\u001b[1;36m341\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    242 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    242 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aac6750f3984b0ebdfeaa3b04a848d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:25:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">697</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:25:46\u001b[0m,\u001b[1;36m697\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:25:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">699</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:25:46\u001b[0m,\u001b[1;36m699\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:25:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">800</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:25:46\u001b[0m,\u001b[1;36m800\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:25:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">818</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:25:46\u001b[0m,\u001b[1;36m818\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:25:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">821</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:25:46\u001b[0m,\u001b[1;36m821\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:25:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">828</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:25:46\u001b[0m,\u001b[1;36m828\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:25:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">899</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:25:46\u001b[0m,\u001b[1;36m899\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:25:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">034</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:25:47\u001b[0m,\u001b[1;36m034\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:25:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">058</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:25:47\u001b[0m,\u001b[1;36m058\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:25:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">131</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:25:47\u001b[0m,\u001b[1;36m131\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    242 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    242 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0399fa994234ba1ae62f54d54d8b775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:27:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">990</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:27:35\u001b[0m,\u001b[1;36m990\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:27:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">992</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:27:35\u001b[0m,\u001b[1;36m992\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:27:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">078</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:27:36\u001b[0m,\u001b[1;36m078\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:27:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:27:36\u001b[0m,\u001b[1;36m100\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:27:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">103</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:27:36\u001b[0m,\u001b[1;36m103\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:27:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:27:36\u001b[0m,\u001b[1;36m112\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:27:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">188</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:27:36\u001b[0m,\u001b[1;36m188\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:27:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">323</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:27:36\u001b[0m,\u001b[1;36m323\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:27:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">343</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:27:36\u001b[0m,\u001b[1;36m343\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:27:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">420</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:27:36\u001b[0m,\u001b[1;36m420\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdeacd65a6242609e0ab966750ff985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:29:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">927</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:29:24\u001b[0m,\u001b[1;36m927\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:29:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">928</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:29:24\u001b[0m,\u001b[1;36m928\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:29:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">013</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:29:25\u001b[0m,\u001b[1;36m013\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:29:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">032</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:29:25\u001b[0m,\u001b[1;36m032\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:29:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">035</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:29:25\u001b[0m,\u001b[1;36m035\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:29:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">043</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:29:25\u001b[0m,\u001b[1;36m043\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:29:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:29:25\u001b[0m,\u001b[1;36m113\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:29:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">258</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:29:25\u001b[0m,\u001b[1;36m258\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:29:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">282</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:29:25\u001b[0m,\u001b[1;36m282\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:29:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">354</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:29:25\u001b[0m,\u001b[1;36m354\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    239 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    239 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd763b38fd24d669907e176590f8c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:31:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">004</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:31:19\u001b[0m,\u001b[1;36m004\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:31:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">005</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:31:19\u001b[0m,\u001b[1;36m005\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:31:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">099</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:31:19\u001b[0m,\u001b[1;36m099\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:31:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:31:19\u001b[0m,\u001b[1;36m119\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:31:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:31:19\u001b[0m,\u001b[1;36m122\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:31:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">129</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:31:19\u001b[0m,\u001b[1;36m129\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:31:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">196</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:31:19\u001b[0m,\u001b[1;36m196\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:31:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">336</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:31:19\u001b[0m,\u001b[1;36m336\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:31:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">357</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:31:19\u001b[0m,\u001b[1;36m357\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:31:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">427</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:31:19\u001b[0m,\u001b[1;36m427\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    241 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    241 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02971cc4ec2426aac4ea9acd33b09fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:33:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">111</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:33:07\u001b[0m,\u001b[1;36m111\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:33:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:33:07\u001b[0m,\u001b[1;36m113\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:33:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">217</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:33:07\u001b[0m,\u001b[1;36m217\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:33:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">239</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:33:07\u001b[0m,\u001b[1;36m239\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:33:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:33:07\u001b[0m,\u001b[1;36m242\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:33:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:33:07\u001b[0m,\u001b[1;36m257\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:33:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">471</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:33:07\u001b[0m,\u001b[1;36m471\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:33:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">615</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:33:07\u001b[0m,\u001b[1;36m615\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:33:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">637</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:33:07\u001b[0m,\u001b[1;36m637\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:33:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">722</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:33:07\u001b[0m,\u001b[1;36m722\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7797542ec5430bb164f85b539201dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:35:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">408</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:35:01\u001b[0m,\u001b[1;36m408\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:35:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">410</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:35:01\u001b[0m,\u001b[1;36m410\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:35:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">555</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:35:01\u001b[0m,\u001b[1;36m555\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:35:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">573</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:35:01\u001b[0m,\u001b[1;36m573\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:35:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">577</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:35:01\u001b[0m,\u001b[1;36m577\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:35:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">585</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:35:01\u001b[0m,\u001b[1;36m585\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:35:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">666</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:35:01\u001b[0m,\u001b[1;36m666\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:35:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">799</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:35:01\u001b[0m,\u001b[1;36m799\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:35:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">821</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:35:01\u001b[0m,\u001b[1;36m821\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:35:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">890</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:35:01\u001b[0m,\u001b[1;36m890\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    242 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    242 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d04aa7c0264ecf87c54ded106c9f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:36:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">061</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:36:51\u001b[0m,\u001b[1;36m061\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:36:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">062</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:36:51\u001b[0m,\u001b[1;36m062\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:36:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">174</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:36:51\u001b[0m,\u001b[1;36m174\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:36:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:36:51\u001b[0m,\u001b[1;36m200\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:36:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">203</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:36:51\u001b[0m,\u001b[1;36m203\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:36:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">214</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:36:51\u001b[0m,\u001b[1;36m214\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:36:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">289</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:36:51\u001b[0m,\u001b[1;36m289\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:36:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">430</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:36:51\u001b[0m,\u001b[1;36m430\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:36:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">458</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:36:51\u001b[0m,\u001b[1;36m458\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:36:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">575</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:36:51\u001b[0m,\u001b[1;36m575\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d820e1dfb34753884239a5cfc73103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:38:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">995</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:38:44\u001b[0m,\u001b[1;36m995\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:38:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">997</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:38:44\u001b[0m,\u001b[1;36m997\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:38:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:38:45\u001b[0m,\u001b[1;36m114\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:38:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">131</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:38:45\u001b[0m,\u001b[1;36m131\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:38:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">134</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:38:45\u001b[0m,\u001b[1;36m134\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:38:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">144</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:38:45\u001b[0m,\u001b[1;36m144\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:38:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">226</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:38:45\u001b[0m,\u001b[1;36m226\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:38:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">372</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:38:45\u001b[0m,\u001b[1;36m372\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:38:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">394</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:38:45\u001b[0m,\u001b[1;36m394\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:38:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">464</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:38:45\u001b[0m,\u001b[1;36m464\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    240 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    240 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dd1caeb98e446fb31050c3b1a64c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:40:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">357</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:40:39\u001b[0m,\u001b[1;36m357\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:40:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">359</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:40:39\u001b[0m,\u001b[1;36m359\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:40:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:40:39\u001b[0m,\u001b[1;36m450\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:40:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">470</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:40:39\u001b[0m,\u001b[1;36m470\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:40:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">473</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:40:39\u001b[0m,\u001b[1;36m473\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:40:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">481</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:40:39\u001b[0m,\u001b[1;36m481\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:40:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">562</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:40:39\u001b[0m,\u001b[1;36m562\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:40:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">708</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:40:39\u001b[0m,\u001b[1;36m708\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:40:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">729</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:40:39\u001b[0m,\u001b[1;36m729\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:40:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">810</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:40:39\u001b[0m,\u001b[1;36m810\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    241 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    241 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfa3a0505e14aeba8d4226a38939eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:42:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">933</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:42:43\u001b[0m,\u001b[1;36m933\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:42:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">934</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:42:43\u001b[0m,\u001b[1;36m934\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:42:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">066</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:42:44\u001b[0m,\u001b[1;36m066\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:42:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">084</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:42:44\u001b[0m,\u001b[1;36m084\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:42:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">087</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:42:44\u001b[0m,\u001b[1;36m087\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:42:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">096</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:42:44\u001b[0m,\u001b[1;36m096\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:42:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">170</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:42:44\u001b[0m,\u001b[1;36m170\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:42:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">313</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:42:44\u001b[0m,\u001b[1;36m313\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:42:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">336</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:42:44\u001b[0m,\u001b[1;36m336\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:42:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">409</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:42:44\u001b[0m,\u001b[1;36m409\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    242 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    242 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e986ec31a5904b75add48c13f1b5df30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:44:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">892</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:44:42\u001b[0m,\u001b[1;36m892\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:44:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">894</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:44:42\u001b[0m,\u001b[1;36m894\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:44:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">976</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:44:42\u001b[0m,\u001b[1;36m976\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:44:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">995</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:44:42\u001b[0m,\u001b[1;36m995\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:44:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">998</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:44:42\u001b[0m,\u001b[1;36m998\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:44:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">005</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:44:43\u001b[0m,\u001b[1;36m005\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:44:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:44:43\u001b[0m,\u001b[1;36m105\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:44:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">263</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:44:43\u001b[0m,\u001b[1;36m263\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:44:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">285</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:44:43\u001b[0m,\u001b[1;36m285\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:44:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">360</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:44:43\u001b[0m,\u001b[1;36m360\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bc0d22663446b2b51cc39ed0323875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:46:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">544</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:46:57\u001b[0m,\u001b[1;36m544\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:46:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">546</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:46:57\u001b[0m,\u001b[1;36m546\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:46:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">667</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:46:57\u001b[0m,\u001b[1;36m667\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 10:46:57,691] Trial 0 finished with value: 0.33944122524476467 and parameters: {'gflu_stages': 7, 'gflu_feature_init_sparsity': 0.3229093069406744, 'gflu_dropout': 0.08586469259275054, 'learning_rate': 0.017914503521860834}. Best is trial 0 with value: 0.33944122524476467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  0.33944122524476467\n",
      "  Params: \n",
      "    gflu_stages: 7\n",
      "    gflu_feature_init_sparsity: 0.3229093069406744\n",
      "    gflu_dropout: 0.08586469259275054\n",
      "    learning_rate: 0.017914503521860834\n"
     ]
    }
   ],
   "source": [
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gflu_stages': 7,\n",
       " 'gflu_feature_init_sparsity': 0.3229093069406744,\n",
       " 'gflu_dropout': 0.08586469259275054,\n",
       " 'learning_rate': 0.017914503521860834}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUNNING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty cache first\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "target_col = 'rr1_30'\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=[\n",
    "        target_col\n",
    "    ],  # target should always be a list\n",
    "    continuous_cols=non_category_features,\n",
    "    categorical_cols=category_features,\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "experiment_config = ExperimentConfig(project_name=PROJECT_NAME,exp_watch=\"all\",log_target=\"tensorboard\")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_epochs=EPOCHS,\n",
    "    early_stopping=None\n",
    ")\n",
    "\n",
    "# best_params = {'gflu_stages': 9,\n",
    "#  'gflu_feature_init_sparsity': 0.1950409583306746,\n",
    "#  'gflu_dropout': 0.030707294595931856,\n",
    "#  'learning_rate': 0.015269936277354889}\n",
    "\n",
    "best_params = trial.params\n",
    "\n",
    "\n",
    "model_config = GANDALFConfig(\n",
    "    task=\"regression\",\n",
    "    metrics=[\"mean_absolute_error\", \"mean_absolute_percentage_error\", \"mean_squared_error\", \"r2_score\"],\n",
    "    **best_params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    experiment_config=experiment_config,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">069</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:22:38\u001b[0m,\u001b[1;36m069\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">074</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:22:38\u001b[0m,\u001b[1;36m074\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">081</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:22:38\u001b[0m,\u001b[1;36m081\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:22:38\u001b[0m,\u001b[1;36m127\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:22:38\u001b[0m,\u001b[1;36m202\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">221</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:22:38\u001b[0m,\u001b[1;36m221\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:22:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">263</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:22:38\u001b[0m,\u001b[1;36m263\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    244 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.5 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    244 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dbd0d5ecb04a9fbadd7b5d9de2e621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:27:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">324</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:27:55\u001b[0m,\u001b[1;36m324\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:27:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">325</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:27:55\u001b[0m,\u001b[1;36m325\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:27:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">480</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:27:55\u001b[0m,\u001b[1;36m480\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:27:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">498</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:27:55\u001b[0m,\u001b[1;36m498\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:27:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:27:55\u001b[0m,\u001b[1;36m502\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:27:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">510</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:27:55\u001b[0m,\u001b[1;36m510\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:27:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">577</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:27:55\u001b[0m,\u001b[1;36m577\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:27:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">713</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:27:55\u001b[0m,\u001b[1;36m713\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:27:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">738</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:27:55\u001b[0m,\u001b[1;36m738\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:27:55</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">817</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:27:55\u001b[0m,\u001b[1;36m817\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    241 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    241 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26049993601f44078ca08cdec9e169a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:34:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">636</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:34:15\u001b[0m,\u001b[1;36m636\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:34:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">640</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:34:15\u001b[0m,\u001b[1;36m640\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:34:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">856</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:34:15\u001b[0m,\u001b[1;36m856\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:34:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">876</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:34:15\u001b[0m,\u001b[1;36m876\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:34:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">881</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:34:15\u001b[0m,\u001b[1;36m881\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:34:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">891</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:34:15\u001b[0m,\u001b[1;36m891\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:34:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">967</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:34:15\u001b[0m,\u001b[1;36m967\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:34:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">098</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:34:16\u001b[0m,\u001b[1;36m098\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:34:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">126</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:34:16\u001b[0m,\u001b[1;36m126\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:34:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">205</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:34:16\u001b[0m,\u001b[1;36m205\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b99e8f4a3ab49c7a2ba23568d8a72b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:39:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">021</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:39:16\u001b[0m,\u001b[1;36m021\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:39:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">023</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:39:16\u001b[0m,\u001b[1;36m023\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:39:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">405</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:39:16\u001b[0m,\u001b[1;36m405\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:39:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">416</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:39:16\u001b[0m,\u001b[1;36m416\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:39:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">420</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:39:16\u001b[0m,\u001b[1;36m420\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:39:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">425</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:39:16\u001b[0m,\u001b[1;36m425\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:39:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">465</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:39:16\u001b[0m,\u001b[1;36m465\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:39:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">537</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:39:16\u001b[0m,\u001b[1;36m537\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:39:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">553</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:39:16\u001b[0m,\u001b[1;36m553\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:39:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">615</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:39:16\u001b[0m,\u001b[1;36m615\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b145d8ed2c14062888e27e259283997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:43:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">580</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:43:28\u001b[0m,\u001b[1;36m580\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:43:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">581</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:43:28\u001b[0m,\u001b[1;36m581\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:43:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:43:28\u001b[0m,\u001b[1;36m689\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:43:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">701</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:43:28\u001b[0m,\u001b[1;36m701\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:43:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">703</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:43:28\u001b[0m,\u001b[1;36m703\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:43:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">710</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:43:28\u001b[0m,\u001b[1;36m710\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:43:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">761</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:43:28\u001b[0m,\u001b[1;36m761\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:43:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">831</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:43:28\u001b[0m,\u001b[1;36m831\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:43:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">846</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:43:28\u001b[0m,\u001b[1;36m846\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:43:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">906</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:43:28\u001b[0m,\u001b[1;36m906\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40faa9196c404769902d2357bc34c503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:47:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">258</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:47:24\u001b[0m,\u001b[1;36m258\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:47:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">259</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:47:24\u001b[0m,\u001b[1;36m259\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11:47:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">350</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m11:47:24\u001b[0m,\u001b[1;36m350\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    bagged_pred_df = tabular_model.bagging_predict(\n",
    "        cv=5, train=train, test=test, aggregate=\"mean\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test average mean absolute error: 0.17270184262468233\n",
      "Test average mean absolute percentage error: 324.85607810783057\n",
      "Test average root mean squared error: 0.2321947271898611\n",
      "Test average R2: 0.5293127995331639\n"
     ]
    }
   ],
   "source": [
    " # save metrics\n",
    "mae, mape, rmse, rsqr = calculate_metric(bagged_pred_df.to_numpy().squeeze(), test[target_col].to_numpy())\n",
    "print(f\"Test average mean absolute error: {mae}\")\n",
    "print(f\"Test average mean absolute percentage error: {mape}\")\n",
    "print(f\"Test average root mean squared error: {rmse}\")\n",
    "print(f\"Test average R2: {rsqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../output/GANDALF_bagging/GANDALF_bagging.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save train predictions\n",
    "# with pd.ExcelWriter(TRAINING_OUTPUT_FILE, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "#     # Write the new DataFrame to a new sheet\n",
    "#     train_predictions.to_excel(writer, sheet_name=SHEET_NAME, index=False)\n",
    "    \n",
    "# save test predictions\n",
    "with pd.ExcelWriter(TEST_OUTPUT_FILE, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "    # Write the new DataFrame to a new sheet\n",
    "    bagged_pred_df.to_excel(writer, sheet_name=SHEET_NAME, index=False)\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(tabular_model, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>PD_1_median_exch</td>\n",
       "      <td>1.999998e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>PD_21_pd</td>\n",
       "      <td>1.999997e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>dtd_median_exch</td>\n",
       "      <td>1.480471e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Long-term_ratio</td>\n",
       "      <td>5.195277e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Industry_subgroup</td>\n",
       "      <td>3.846152e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>US Generic Govt 5 Year Yield</td>\n",
       "      <td>3.085345e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>PD_12_median_exch</td>\n",
       "      <td>3.079759e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>PD_27_pd</td>\n",
       "      <td>3.023301e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PD_1_domicile_subsec</td>\n",
       "      <td>3.011441e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>US Generic Govt 10 Year Yield</td>\n",
       "      <td>2.847408e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Features    importance\n",
       "86                PD_1_median_exch  1.999998e+00\n",
       "121                       PD_21_pd  1.999997e+00\n",
       "85                 dtd_median_exch  1.480471e+00\n",
       "79                 Long-term_ratio  5.195277e-01\n",
       "6                Industry_subgroup  3.846152e-02\n",
       "..                             ...           ...\n",
       "25    US Generic Govt 5 Year Yield  3.085345e-08\n",
       "88               PD_12_median_exch  3.079759e-08\n",
       "127                       PD_27_pd  3.023301e-08\n",
       "35            PD_1_domicile_subsec  3.011441e-08\n",
       "27   US Generic Govt 10 Year Yield  2.847408e-08\n",
       "\n",
       "[164 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_ft_importance = tabular_model.feature_importance().sort_values(\"importance\", ascending=False)\n",
    "native_ft_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWwAAAJOCAYAAAAjyk6bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeXhM1//A8c8kSGwJIZEgktiiWrtKo3Yh9rW2traWflFF1VpLbEV1o62iLUJVKVpV1Jbaaykpqi2tNbbYJRGEJJ/fH57cXyYLkkwmE3m/nicPc+65Z7lz5869n3vmXJOqqgAAAAAAAAAAspxdVjcAAAAAAAAAAPAQAVsAAAAAAAAAsBEEbAEAAAAAAADARhCwBQAAAAAAAAAbQcAWAAAAAAAAAGwEAVsAAAAAAAAAsBEEbAEAAAAAAADARhCwBQAAAAAAAAAbQcAWAAAAAAAAAGwEAVsAAADYHG9vb/H29s7qZgAAAABWR8AWAADkKCaTKU1/WaFXr17patO3334rtWrVkvz580vhwoWlVatWEhoamqa6vb29xWQyiaurq0RFRaWYx9HRMcPB1IQ+njlzJkPlWMPj3o8hQ4ZYpR0NGjTIsn0yIxLaHR4entVNyTTcYAAAAJaUK6sbAAAAYE1BQUHJ0mbOnCkREREpLstKgwcPlkKFCj1R3vfee0/Gjh0rXl5e0q9fP4mKipJly5ZJ7dq1JSQkRF588cU01X3t2jWZMWOGTJ48OR0tz7iQkJAsqfdRXn/9dSlZsmSy9BdeeCELWgMAAICnFQFbAACQo0yYMCFZWnBwsERERKS4LCsNGTLkiUbt/ffffzJhwgQpX7687N+/X5ydnUVEZMCAAfLCCy9I37595ejRo2Jn92Q/rsqdO7d4eHjIJ598Im+++aa4u7tnpBvpUqZMGavX+Th9+vQhOAsAAIBMx5QIAAAAqbh27ZoMGTJEfHx8xMHBQdzc3KRz585y9OjRZHkTfjZ/6tQpmTFjhpQrV04cHR3Fx8dHJk2aJA8ePMi0di5cuFBiY2NlzJgxRrBWRKRq1arSrVs3+eeff2TXrl1PXJ6dnZ1MnDhRoqOjZeLEiU+0zsWLFyUoKEheeOEFcXNzEwcHB/H29pYBAwbIlStXzPJ6e3vLokWLRETEx8fHmFqgQYMGZnkSB6snT54sJpNJFi9enGL9P/zwg5hMJhkzZoxZ+unTp6VPnz5SqlQpcXBwEA8PD+nVq5ecPXv2ifqVVvfv35ePP/5YqlevLvnz55eCBQtK3bp1Zc2aNcny/vvvvzJixAipXr26FClSRBwdHaV8+fIyatQouX37tllek8kk27dvN/6f8NerVy8REdm2bZuYTKYUbzqcOXPGLG+ChG1869YtGThwoHh6ekquXLkkODjYyHPkyBHp2rWreHh4SJ48ecTLy0veeustuX79eoa2U+L2/vbbb9KwYUMpWLCguLq6yoABA+Tu3bsiIrJu3Trx9/eX/PnzS7FixWTEiBESGxtrVlZwcLCYTCYJDg6Wn376SWrVqiX58uUTV1dXee211+Ty5csptmH37t3SsmVLcXFxEUdHR6lQoYIEBQXJnTt3kuVN2D8vXLggPXr0EHd3d7GzszPqPnv2rJw9e9bsvUl4L+7fvy+fffaZBAYGiqenp3Es6dChg/zxxx/J6krcn02bNknt2rUlX758UqRIEenZs2eq2/7w4cPyyiuvSMmSJY19vVmzZvLzzz8ny/vTTz9J48aNpXDhwuLo6CjPPfecfPjhhxIXF/fI9w0AAFgHI2wBAABScPXqVfH395eTJ09KgwYNpGvXrnL69GlZuXKlrFu3TjZu3Ch16tRJtt6QIUNk9+7d0rlzZylQoID8/PPPEhQUJEeOHJGVK1emqQ1r166VqKgocXBwkGeeeUYaN24sefLkSZZv27ZtIiLStGnTZMsCAwMlODhYtm/fLvXq1Xviunv06CEfffSRfP311/L2229L+fLlH5l/x44d8tFHH0njxo3Fz89PcufOLX/88YfMmTNHNm7cKKGhoUYweciQIRIcHCyHDx82m/bhUaOJX331VQkKCpIlS5ZIjx49ki3/5ptvRESke/fuRtq+ffskMDBQoqOjpVWrVlKuXDk5c+aMfPvtt/LLL7/Inj17pHTp0k+8TR4nJiZGmjVrJtu2bZOqVavK66+/Lg8ePJB169ZJ27Zt5bPPPpOBAwca+X/44QeZP3++NGzYUBo0aCDx8fGyd+9eef/992X79u2yY8cOyZ07t4g8nMojODhYzp49azZ1R9WqVTPc5kaNGsnt27elTZs2kitXLilWrJiIiKxZs0Y6d+4sdnZ20rZtW/H09JS///5bPv/8c9m4caPs27dPChcunKH69+3bJ++//74EBgbK//73P9m6davMmTNHIiMjpXXr1tKrVy9p27at+Pv7y7p16+SDDz6QAgUKyPjx45OVtWrVKtm4caO89NJLEhAQIHv37pWFCxfKzp07Zf/+/WZtXbFihXTr1k0cHBykS5cu4ubmJps2bZJJkybJxo0bZdu2beLo6GhW/vXr18Xf319cXFyka9eucu/ePalcubIEBQXJzJkzRUTM5jNOuAFx48YNGTJkiNStW1datGghhQsXllOnTsmaNWvkl19+kR07dsjzzz+frD9r1qyRdevWSevWraV27dqyY8cOWbx4sZw8eTLZDZhVq1bJyy+/LKoqrVu3Fl9fX7ly5Yrs27dP5s+fL61btzbyjh49WqZPny4lSpSQDh06iLOzs+zcuVOGDx8u+/btkxUrVqT1bQQAAJamAAAAOZyXl5cmPS3q3bu3ioiOHj3aLH3dunUqIlq2bFmNi4sz0nv27Kkioq6urnru3DkjPSYmRuvVq6cioitXrnyi9iSUlfTPw8NDN2zYkCx/0aJFtUCBAimWdeDAARUR7d69+xPV7eXlpQ4ODqqqunbtWhUR7dixo1keBwcH9fLyMku7fPmyRkVFJStv0aJFKiI6ZcqUFPt4+vTpVNuRtI46deqovb29Xrx40Sz9+vXrmidPHq1Zs6aRdv/+ffX29taCBQtqaGioWf6dO3eqvb29tmrVKsW6k0po6+uvv65BQUFmf9OmTTPyvfvuuyoiOm7cOI2PjzfSIyMjtWbNmponTx69cOGCkX7+/HmNiYlJVt/EiRNVRHTJkiVm6fXr10+2nybYunWriogGBQUlW3b69GkVEe3Zs6dZesJ+HxgYqHfu3DFbdu3aNXVyctISJUromTNnzJZ99913KiI6cODAFNuSVEK7L126lKy9IqKrV6820u/fv6+VK1dWk8mkRYsW1f379xvLIiMj1c3NTV1cXPT+/ftG+sKFC42ykn4+Ro0alaytERER6uzsrA4ODnr48GEjPS4uTrt06aIiopMmTTIrJ6H83r17a2xsbLI+prS/Jrh3756eP38+WfrRo0e1QIECGhAQYJae0J9cuXLprl27jPTY2Fht0KCBioju2bPHSA8PD9f8+fNr/vz5k+3rqmp2PNq0aZPxnt++fdtIj4+P1379+qXpOAUAADIPAVsAAJDjJQ3YxsTEqKOjoxYpUkSjo6OT5W/SpImKiO7YscNISwjqJQ1Mqj4MEIrIEwcI58+fr99//72GhYXp3bt39b///tNJkyZp3rx5NU+ePPr777+b5c+dO7eWKFEixbL+/fdfFRFt06bNE9WdOGCrqkawed++fUZaSgHb1MTHx6uTk5M2aNDALD09Adt58+apiOhHH31klv7FF1+oiOjMmTONtB9++CHFwFuCDh06qJ2dnUZERDy2D6kF0EVEnZ2dVfVhsK9w4cJapkwZs2BtgjVr1qiI6GefffbY+q5fv64ior169TJLz6yAbeKgZYKPP/5YRUQXL16cYn3Vq1fXokWLPrYvidudUsC2YcOGyfJPmjTJCI4m9dprr6mI6KlTp4y0hABn0sCnqmpUVJQWKlRInZycjBssixcvVhHR/v37J8t/9uxZzZUrl5YuXdosXUQ0T548evXq1RT7+KiA7aO0bt1a8+TJk2IAukePHsnyJyz79NNPjbT3339fRUTHjx//2PratGmjIqJnz55NtuzWrVtqMpmS3aABAADWx5QIAAAASRw7dkzu3bsnDRs2lHz58iVb3rBhQ9m8ebMcOnRI6tata7Ys6WsREX9/f8mVK1eK81Wm5LXXXjN7XbZsWRk3bpyUKFFCXn/9dZk0aVKKc6JmhhkzZsgLL7wgI0eOlK1btz4y7w8//CDz5s2T0NBQuXnzptl8mBcvXsxwWzp37iyDBg2Sb775RoYOHWqkL1myRHLlyiXdunUz0vbu3SsiIsePH09xXtfw8HCJj4+Xf//9V2rWrPlE9e/ZsyfVh44dP35cbt68KcWLF09x3t+rV6+KyMN9K4GqysKFCyU4OFiOHj0qEREREh8fbyy3xDZ7HEdHR6lUqVKy9ITtt2/fPjl58mSy5ffu3ZNr167JtWvXpGjRoumuP6UpHTw8PB677OLFi+Lj42O2LKXPXoECBaRq1aqybds2OXXqlJQtW9b4HCaeMzlBqVKlpHTp0vLvv/9KVFSUFCxY0Fjm4+OT7r4eOnRIZsyYIbt27ZLw8PBkc1pfu3bN6FuCGjVqJCunZMmSIiJy69YtI23//v0ikvKUKEnt3btX8ufPLwsWLEhxed68ec32UQAAkDUI2AIAACQRGRkpImLM5ZlUQmAlIV9iKa1jb28vRYoUkYiIiAy1q2fPnvLmm2/K7t27zdKdnZ1TLTuhjYkfRpYWfn5+0qFDB/nhhx9k/fr10qJFixTzffTRRzJs2DBxdXWVpk2bSsmSJSVv3rwiIjJz5kyJiYlJV/2JFSpUSFq1aiWrVq2Sv//+WypWrCgnT56U3377TVq0aCFubm5G3hs3boiIyLfffvvIMqOjozPcrsT1/fXXX/LXX389UX2DBg2Szz//XDw9PaVNmzbi4eEhDg4OIiIyceJEi2yzx3FzcxOTyZQsPaE/s2fPfuT60dHRGQrYOjk5JUvLlSvXY5el9BC/1D6vCekJn5En+Xz/+++/EhkZaRawTS3/4/z222/SqFEjEXkYVC1XrpwUKFBATCaTrF69Wg4fPpzie/2o/ie+GZLQrxIlSjy2LTdu3JDY2NhHPkzQUp8JAACQfgRsAQAAkkgIlKT2dPnw8HCzfIldvnxZfH19zdLi4uLk+vXr6Q74JLC3t5dChQrJzZs3zdLLlSsne/bskfDwcHF3dzdb9t9//xl50mvq1KmyZs0aGTVqlDRr1izZ8tjYWJk8ebJ4eHjIoUOHzAKnqiozZsxId91Jde/eXVatWiXffPONTJs2TZYsWWKkJ5bw3vz888/SqlUri9WfmoT6Onbs+EQPl7ty5YrMnj1bKleuLHv27DEbyR0eHv7IgFpK7OzsROThe5HUo24UpBSsFfn//vz555/y3HPPpaktWSW1z2tCesJNi/R+vlPbVo/z3nvvSUxMjOzcuTPZgwr37t0rhw8fTle5CRIe2nfhwoVHPrhP5GGfTCaTXLt2LUN1AgCAzGWX1Q0AAACwNRUqVBBHR0f5/fff5c6dO8mWb9u2TURS/sn2zp07k6Xt2bNHYmNjpVq1ahlqV1hYmISHhycLytSvX19ERDZt2pRsnY0bN5rlSQ9fX195/fXX5c8//5Rvvvkm2fJr165JRESE+Pv7mwVrRUQOHDggd+/eTbaOvb29iJiPFHwSLVq0kCJFisjSpUslPj5evv32WylYsKC0bdvWLJ+fn5+IPNz21vDMM8+Ik5OTHDhwIMXRn0mdOnVKVFUCAgKSTbuR0j4k8uhtVrhwYRF5GLRL6kmn4kjM2tvPElLabrdv35ZDhw6Jk5OTlC5dWkTE+BwmfI4TO3funJw8eVJKly5tNrr2cezt7VPdl0+ePCkuLi7JgrV37tyR0NDQJ64jNbVq1RKRlD//Sfn5+cn169eNGzkAAMA2EbAFAABIIk+ePNKtWze5du2aTJs2zWzZhg0bZOPGjVK2bFl58cUXk607a9YsOX/+vPH6/v37MmbMGBER6dWr12PrDg8PTzHoduvWLWP9l19+2WxZ7969JVeuXPLee++ZjaY8dOiQfPfdd/LMM88kCxal1YQJEyRfvnwyfvx4s3lWRR7+rD5v3rwSGhpqFuC+efOmvPXWWymW5+LiIiIPA2RpkTt3bunSpYuEhYXJjBkz5L///pOOHTsa0y8kaNu2rZQqVUo+/vhj2bFjR7JyHjx4ILt27UpT3Y+SK1cu6d+/v5w9e1aGDRuWYtD26NGjcuXKFRER8fLyEpGHP5dPvD3Pnz8vo0ePTrGOR20zX19fKViwoKxZs8aYzkDk4SjSKVOmpLk/vXv3loIFC8qYMWNSnOLhzp07xjy3tmLLli3GDYoE7733nty6dUt69OhhjEJu27atODs7y8KFC836pqoycuRIiY2NfaLPamIuLi5y7do1uXfvXrJlXl5ecvPmTbO64uLiZNiwYcbcxhnRs2dPKVCggHz00Udy6NChZMsTH08GDRokIg/nyb5+/XqyvOHh4fLPP/9kuE0AACBjmBIBAAAgBe+//75s375dpkyZIr/99pv4+fnJmTNnZMWKFZIvXz5ZuHChEQBK7IUXXpAqVapIly5dJH/+/PLzzz/L8ePHpUOHDtKxY8fH1nvs2DFp0qSJ1K5dW8qVKyeurq5y7tw52bBhg1y/fl0aNWokI0aMMFunfPnyMmHCBBk7dqxUqVJFOnbsKFFRUbJs2TIREfnqq69SbGtauLu7y9tvvy3vvfdesmV2dnYyYMAA+eijj6RKlSrSunVriYyMlF9++UW8vLykePHiydZp1KiRfPjhh/LGG29Ix44dJX/+/OLl5ZVsaoOUdO/eXb744gsZP3688TopBwcHWblypTRv3lzq168vjRo1kkqVKonJZJKzZ8/Kzp07pUiRIhZ9wNLEiRMlNDRUPv30U1m3bp3Uq1dP3Nzc5MKFC/Lnn3/K4cOHZc+ePeLm5iYeHh7SsWNHWbVqldSsWVMaN24sly9flrVr10rjxo1TfNBXo0aNZOXKldKxY0dp3ry5ODo6Gts7T5488tZbb8nUqVOlevXq0rZtW4mKipKff/5Z6tevn2J5j+Lq6irfffeddOrUSapUqSLNmjWTChUqSExMjJw5c0a2b98utWvXlg0bNlhq82VYq1atpHXr1vLSSy+Jt7e37N27V7Zu3SplypSRSZMmGfmcnJzkq6++km7duomfn5906dJFXF1dZcuWLXLw4EGpVauWDB8+PE11N2rUSA4cOCDNmzeXunXrSp48eaRevXpSr149eeutt2TTpk1Sp04d6dy5szg6Osq2bdvkwoUL0qBBgxRH+qaFm5ubLF68WLp27Sq1atWSNm3aiK+vr1y7dk327dsn3t7esnr1ahERadasmYwbN04mT54sZcuWlWbNmomXl5dcv35dTpw4ITt37pQpU6bIM888k6E2AQCADFIAAIAczsvLS1M6Lbp69aoOGjRIvby8NHfu3Fq0aFF96aWX9M8//0yWt2fPnioievLkSZ0+fbqWLVtW8+TJo15eXjphwgSNiYl5oraEhYVpnz59tEqVKlqkSBHNlSuXFipUSOvVq6dz587V2NjYVNddsmSJ1qxZU/PmzavOzs7aokULPXjw4JNvCH24LRwcHFJcFhERoUWLFlURUS8vL7Nl9+/f1/fee0/LlSunDg4OWqpUKX3nnXc0KipKvby8kuVXVZ0xY4aWK1dOc+fOrSKi9evXN2tHSuskKFeunIqIlixZUuPi4lLNd/78eR08eLDRLicnJ33mmWe0T58+GhIS8qhNYUh4b/fs2fPYvLGxsTpv3jx98cUX1cnJydgWzZo10zlz5ujt27eNvFFRUfrOO++ot7e3Ojg4aLly5XTy5Ml6//79ZNtDVfXBgwc6YsQILVWqlObKlUtFRHv27Gksj4uL0wkTJqinp6fmyZNHy5cvr7NmzdJTp04ly6v6+G2sqnrs2DF9/fXX1cvLS/PkyaOFCxfWSpUq6aBBg3T//v2P3R6qqvXr11cR0UuXLhlpW7duVRHRoKCgZPkXLlyoIqILFy5MtiwoKEhFRLdu3Zpi/tWrV+vzzz+vefPm1SJFimivXr3M6k1sx44d2rx5cy1UqJCxvcaNG2f2HiVI6f1ILCoqSvv27aseHh5qb2+frG8rV67U6tWra758+bRo0aLauXNnPXnypLFvnT59+on6/6jt9scff2jnzp21WLFimjt3bvXw8NDmzZvr2rVrk+XdvHmztm7dWl1dXTV37tzq7u6u/v7+OnnyZA0LC0u1nwAAwDpMqqpWjhEDAAA8dXr16iWLFi2S06dPP/bBPwAsJzg4WHr37i0LFy5M81QGAAAAtog5bAEAAAAAAADARhCwBQAAAAAAAAAbQcAWAAAAAAAAAGwEc9gCAAAAAAAAgI1ghC0AAAAAAAAA2AgCtgAAAAAAAABgI3JldQOQXHx8vFy8eFEKFiwoJpMpq5sDAAAAAAAAIANUVaKioqR48eJiZ/foMbQEbG3QxYsXxdPTM6ubAQAAAAAAAMCCzp07JyVLlnxkHgK2NqhgwYIi8vANdHJyyuLWAAAAAAAAAMiIyMhI8fT0NOJ+j0LA1gYlTIPg5OREwBYAAAAAAAB4SjzJ9Kc8dAwAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBGELAFAAAAAAAAABtBwBYAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBGELAFAAAAAAAAABtBwBYAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBG5NiA7bRp0+T555+XggULipubm7Rr106OHz/+2PVWrFghFSpUEEdHR6lUqZKsX7/ebLmqyvjx48XDw0Py5s0rAQEB8t9//2VWNwAAAAAAAAA8RXJswHb79u3y5ptvyt69e2Xz5s3y4MEDadq0qURHR6e6zm+//SbdunWT119/Xf744w9p166dtGvXTo4ePWrkmTFjhnz66acyd+5c2bdvn+TPn18CAwPl3r171ugWAAAAAAAAgGzMpKqa1Y2wBVevXhU3NzfZvn271KtXL8U8Xbp0kejoaFm7dq2R9sILL0jVqlVl7ty5oqpSvHhxeeedd2TYsGEiIhIRESHFihWT4OBg6dq16xO1JTIyUpydnSUiIkKcnJwy3jkAAAAAAAAAWSYt8b4cO8I2qYiICBERcXFxSTXPnj17JCAgwCwtMDBQ9uzZIyIip0+flvDwcLM8zs7O4ufnZ+RJSUxMjERGRpr9AQAAAAAAAMh5cmV1A2xBfHy8DBkyRF588UV57rnnUs0XHh4uxYoVM0srVqyYhIeHG8sT0lLLk5Jp06bJxIkTn6it3qPWPVG+xM5Mb5nmddJaT3rqAAAAAAAAAGCOEbYi8uabb8rRo0dl2bJlWVL/6NGjJSIiwvg7d+5clrQDAAAAAAAAQNbK8SNsBw4cKGvXrpUdO3ZIyZIlH5nX3d1dLl++bJZ2+fJlcXd3N5YnpHl4eJjlqVq1aqrlOjg4iIODQzp7AAAAAAAAAOBpkWNH2KqqDBw4UH788Uf59ddfxcfH57Hr+Pv7S0hIiFna5s2bxd/fX0REfHx8xN3d3SxPZGSk7Nu3z8gDAAAAAAAAAKnJsSNs33zzTVm6dKn89NNPUrBgQWOOWWdnZ8mbN6+IiPTo0UNKlCgh06ZNExGRwYMHS/369eWjjz6Sli1byrJly+TAgQPy5ZdfioiIyWSSIUOGyJQpU6RcuXLi4+Mj48aNk+LFi0u7du2ypJ8AAAAAAAAAso8cG7CdM2eOiIg0aNDALH3hwoXSq1cvEREJCwsTO7v/H4Rcu3ZtWbp0qYwdO1beffddKVeunKxevdrsQWUjRoyQ6OhoeeONN+TWrVtSp04d2bBhgzg6OmZ6nwAAAAAAAABkbyZV1axuBMxFRkaKs7OzREREiJOTk9ky71Hr0lzemekt07xOWutJTx0AAAAAAABATvCoeF9SOXYOWwAAAAAAAACwNQRsAQAAAAAAAMBGELAFAAAAAAAAABtBwBYAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBGELAFAAAAAAAAABtBwBYAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBGELAFAAAAAAAAABtBwBYAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBGELAFAAAAAAAAABtBwBYAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBGELAFAAAAAAAAABtBwBYAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBGELAFAAAAAAAAABtBwBYAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBGELAFAAAAAAAAABtBwBYAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBGELAFAAAAAAAAABtBwBYAAAAAAAAAbAQBWwAAAAAAAACwEQRsAQAAAAAAAMBG5OiA7Y4dO6R169ZSvHhxMZlMsnr16kfm79Wrl5hMpmR/zz77rJFnwoQJyZZXqFAhk3sCAAAAAAAA4GmQowO20dHRUqVKFZk9e/YT5Z81a5ZcunTJ+Dt37py4uLhIp06dzPI9++yzZvl27dqVGc0HAAAAAAAA8JTJldUNyErNmzeX5s2bP3F+Z2dncXZ2Nl6vXr1abt68Kb179zbLlytXLnF3d7dYOwEAAAAAAADkDDl6hG1GzZ8/XwICAsTLy8ss/b///pPixYtL6dKl5ZVXXpGwsLBHlhMTEyORkZFmfwAAAAAAAAByHgK26XTx4kX55ZdfpE+fPmbpfn5+EhwcLBs2bJA5c+bI6dOnpW7duhIVFZVqWdOmTTNG7zo7O4unp2dmNx8AAAAAAACADSJgm06LFi2SQoUKSbt27czSmzdvLp06dZLKlStLYGCgrF+/Xm7duiXff/99qmWNHj1aIiIijL9z585lcusBAAAAAAAA2KIcPYdteqmqLFiwQLp37y558uR5ZN5ChQpJ+fLl5cSJE6nmcXBwEAcHB0s3EwAAAAAAAEA2wwjbdNi+fbucOHFCXn/99cfmvX37tpw8eVI8PDys0DIAAAAAAAAA2VmODtjevn1bDh06JIcOHRIRkdOnT8uhQ4eMh4SNHj1aevTokWy9+fPni5+fnzz33HPJlg0bNky2b98uZ86ckd9++03at28v9vb20q1bt0ztCwAAAAAAAIDsL0dPiXDgwAFp2LCh8Xro0KEiItKzZ08JDg6WS5cuGcHbBBEREbJq1SqZNWtWimWeP39eunXrJtevXxdXV1epU6eO7N27V1xdXTOvIwAAAAAAAACeCjk6YNugQQNR1VSXBwcHJ0tzdnaWO3fupLrOsmXLLNE0AAAAAAAAADlQjp4SAQAAAAAAAABsCQFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsRI4O2O7YsUNat24txYsXF5PJJKtXr35k/m3btonJZEr2Fx4ebpZv9uzZ4u3tLY6OjuLn5yf79+/PxF4AAAAAAAAAeFrk6IBtdHS0VKlSRWbPnp2m9Y4fPy6XLl0y/tzc3Ixly5cvl6FDh0pQUJCEhoZKlSpVJDAwUK5cuWLp5gMAAAAAAAB4yuTK6gZkpebNm0vz5s3TvJ6bm5sUKlQoxWUff/yx9O3bV3r37i0iInPnzpV169bJggULZNSoURlpLgAAAAAAAICnXI4eYZteVatWFQ8PD2nSpIns3r3bSL9//74cPHhQAgICjDQ7OzsJCAiQPXv2ZEVTAQAAAAAAAGQjBGzTwMPDQ+bOnSurVq2SVatWiaenpzRo0EBCQ0NFROTatWsSFxcnxYoVM1uvWLFiyea5TSwmJkYiIyPN/gAAAAAAAADkPNluSoRLly7JlStXpGzZspI/f36r1u3r6yu+vr7G69q1a8vJkyflk08+kW+++Sbd5U6bNk0mTpxoiSYCAAAAAAAAyMayzQjbn376SSpUqCAlS5aU6tWry759+0Tk4ajWatWqyerVq7OkXbVq1ZITJ06IiEjRokXF3t5eLl++bJbn8uXL4u7unmoZo0ePloiICOPv3LlzmdpmAAAAAAAAALYpWwRsf/75Z+nQoYMULVpUgoKCRFWNZUWLFpUSJUrIwoULs6Rthw4dEg8PDxERyZMnj9SoUUNCQkKM5fHx8RISEiL+/v6pluHg4CBOTk5mfwAAAAAAAABynmwxJcKkSZOkXr16snXrVrl+/bpMmDDBbLm/v7/MmzcvzeXevn3bGB0rInL69Gk5dOiQuLi4SKlSpWT06NFy4cIFWbx4sYiIzJw5U3x8fOTZZ5+Ve/fuyddffy2//vqrbNq0yShj6NCh0rNnT6lZs6bUqlVLZs6cKdHR0dK7d+/0df4p5j1qXZrXOTO9ZSa0BAAAAAAAALAN2SJge/ToUfn4449TXV6sWDG5cuVKmss9cOCANGzY0Hg9dOhQERHp2bOnBAcHy6VLlyQsLMxYfv/+fXnnnXfkwoULki9fPqlcubJs2bLFrIwuXbrI1atXZfz48RIeHi5Vq1aVDRs2JHsQGQAAAAAAAAAklS0Ctvny5ZPo6OhUl586dUqKFCmS5nIbNGhgNr1CUsHBwWavR4wYISNGjHhsuQMHDpSBAwemuT0AAAAAAAAAcrZsMYdtw4YNZdGiRRIbG5tsWXh4uHz11VfStGnTLGgZAAAAAAAAAFhOtgjYvvfee3L+/Hl5/vnnZd68eWIymWTjxo0yduxYqVSpkqiqBAUFZXUzAQAAAAAAACBDskXA1tfXV3bt2iVFihSRcePGiarKBx98IFOnTpVKlSrJzp07xdvbO6ubCQAAAAAAAAAZki3msBURefbZZ2XLli1y8+ZNOXHihMTHx0vp0qXF1dU1q5sGAAAAAAAAABaRbQK2CQoXLizPP/98VjcDAAAAAAAAACwuW0yJ8Omnn0pgYGCqy5s3by5z5syxYosAAAAAAAAAwPKyRcB2/vz5UrFixVSXV6xYUb788ksrtggAAAAAAAAALC9bBGxPnjwpzzzzTKrLK1SoICdPnrRiiwAAAAAAAADA8rJFwDZPnjwSHh6e6vJLly6JnV226AoAAAAAAAAApCpbRDlfeOEFCQ4OlqioqGTLIiIiZOHChfLCCy9kQcsAAAAAAAAAwHJyZXUDnkRQUJDUr19fqlatKkOGDJFnn31WRESOHj0qM2fOlEuXLsnSpUuzuJUAAAAAAAAAkDHZImDr5+cnP//8s/zvf/+TwYMHi8lkEhERVRUfHx9Zs2aN+Pv7Z3ErAQAAAAAAACBjskXAVkSkSZMmcuLECfnjjz+MB4yVKVNGqlevbgRwAQAAAAAAACA7yzYBWxEROzs7qVGjhtSoUSOrmwIAAAAAAAAAFpetArZ///23nDp1Sm7evCmqmmx5jx49sqBVAAAAAAAAAGAZ2SJge/LkSXn11Vdl//79KQZqRURMJhMBWwAAAAAAAADZWrYI2P7vf/+TP//8U2bOnCl169aVwoULZ3WTAAAAAAAAAMDiskXAdvfu3fLuu+/KW2+9ldVNAQAAAAAAAIBMY5fVDXgSRYsWFWdn56xuBgAAAAAAAABkqmwRsO3Xr58sWbJE4uLisropAAAAAAAAAJBpssWUCOXLl5e4uDipUqWKvPbaa+Lp6Sn29vbJ8nXo0CELWgcAAAAAAAAAlpEtArZdunQx/j9s2LAU85hMJkbgAgAAAAAAAMjWskXAduvWrVndBAAAAAAAAADIdNkiYFu/fv2sbgIAAAAAAAAAZLps8dAxAAAAAAAAAMgJssUIWxGR8PBwmT9/voSGhkpERITEx8ebLTeZTBISEpJFrQMAAAAAAACAjMsWAdsjR45IgwYN5O7du+Lr6yt//vmnVKxYUW7duiUXLlyQMmXKiKenZ1Y3EwAAAAAAAAAyJFtMiTBq1CgpUKCAHD9+XLZs2SKqKrNmzZJz587J8uXL5ebNmzJ9+vSsbiYAAAAAAAAAZEi2CNju3r1b/ve//0mpUqXEzu5hkxOmROjUqZO88sorMnz48KxsIgAAAAAAAABkWLYI2MbHx0uxYsVERKRQoUJib28vN27cMJZXqlRJDh48mFXNAwAAAAAAAACLyBYBWx8fHzl9+rSIiNjZ2YmPj49s2bLFWP7bb79JoUKFsqh1AAAAAAAAAGAZ2SJg27RpU1mxYoXxun///vL1119LQECANG7cWBYtWiQvv/xyFrYQAAAAAAAAADIuV1Y34EmMGTNGunXrJg8ePJDcuXPLkCFDJDo6WlatWiX29vYybtw4effdd7O6mQAAAAAAAACQIdkiYFu4cGGpUaOG8dpkMsnYsWNl7NixWdgqAAAAAAAAALCsbDElQqNGjSQkJCTV5Vu3bpVGjRqludwdO3ZI69atpXjx4mIymWT16tWPzP/DDz9IkyZNxNXVVZycnMTf3182btxolmfChAliMpnM/ipUqJDmtgEAAAAAAADIebJFwHbbtm1y+fLlVJdfuXJFtm/fnuZyo6OjpUqVKjJ79uwnyr9jxw5p0qSJrF+/Xg4ePCgNGzaU1q1byx9//GGW79lnn5VLly4Zf7t27Upz2wAAAAAAAADkPNliSgSRh9MgpObEiRNSsGDBNJfZvHlzad68+RPnnzlzptnrqVOnyk8//SQ///yzVKtWzUjPlSuXuLu7p7k9AAAAAAAAAHI2mw3YLlq0SBYtWmS8njJlinz11VfJ8t26dUuOHDkiLVq0sGbzREQkPj5eoqKixMXFxSz9v//+k+LFi4ujo6P4+/vLtGnTpFSpUlZvHwAAAAAAAIDsxWYDtnfu3JGrV68ar6OiosTOznwGB5PJJPnz55d+/frJ+PHjrd1E+fDDD+X27dvSuXNnI83Pz0+Cg4PF19dXLl26JBMnTpS6devK0aNHUx0FHBMTIzExMcbryMjITG87AAAAAAAAANtjswHb/v37S//+/UVExMfHR2bNmiVt2rTJ4lb9v6VLl8rEiRPlp59+Ejc3NyM98RQLlStXFj8/P/Hy8pLvv/9eXn/99RTLmjZtmkycODHT2wwAAAAAAADAttn8Q8fu3r0r7dq1e+Qctta2bNky6dOnj3z//fcSEBDwyLyFChWS8uXLy4kTJ1LNM3r0aImIiDD+zp07Z+kmAwAAAAAAAMgGbD5gmzdvXvnyyy/l8uXLWd0UERH57rvvpHfv3vLdd99Jy5YtH5v/9u3bcvLkSfHw8Eg1j4ODgzg5OZn9AQAAAAAAAMh5bHZKhMRq1KghR48etXi5t2/fNhv5evr0aTl06JC4uLhIqVKlZPTo0XLhwgVZvHixiDycBqFnz54ya9Ys8fPzk/DwcBF5GFR2dnYWEZFhw4ZJ69atxcvLSy5evChBQUFib28v3bp1s3j7AQAAAAAAADxdbH6ErYjIzJkzZdmyZfL1119LbGysxco9cOCAVKtWTapVqyYiIkOHDpVq1aoZDzC7dOmShIWFGfm//PJLiY2NlTfffFM8PDyMv8GDBxt5zp8/L926dRNfX1/p3LmzFClSRPbu3Suurq4WazcAAAAAAACAp1O2GGHbq1cvsbOzk//9738yaNAgKVGihOTNm9csj8lkksOHD6ep3AYNGoiqpro8ODjY7PW2bdseW+ayZcvS1AYAAAAAAAAASJAtArYuLi5SpEgR8fX1zeqmAAAAAAAAAECmyRYB2ycZ2QoAAAAAAAAA2V22mMMWAAAAAAAAAHKCbDHCVkQkLi5OlixZIuvWrZOzZ8+KiIiXl5e0atVKXnnlFbG3t8/iFgIAAAAAAABAxmSLEbYRERHy4osvymuvvSabNm2SBw8eyIMHD2Tz5s3Su3dvqVOnjkRGRmZ1MwEAAAAAAAAgQ7JFwHbMmDFy8OBB+eyzz+Tq1asSGhoqoaGhcuXKFfn888/lwIEDMmbMmKxuJgAAAAAAAABkSLYI2P74448yYMAAGTBggOTOndtIz507t/Tv31/69+8vq1atysIWAgAAAAAAAEDGZYuA7fXr18XX1zfV5RUqVJAbN25YsUUAAAAAAAAAYHnZImBbtmxZWbNmTarL16xZI2XKlLFiiwAAAAAAAADA8rJFwHbAgAGyadMmadGihWzatEnOnDkjZ86ckY0bN0rLli1l8+bNMnDgwKxuJgAAAAAAAABkSK6sbsCTGDBggFy5ckWmT58uGzduNFuWO3duGT9+vPTv3z+LWgcAAAAAAAAAlpEtArYiIhMmTJCBAwfK5s2bJSwsTEREvLy8JCAgQIoWLZrFrQMAAAAAAACAjMs2AVsRkaJFi0q3bt2yuhkAAAAAAAAAkCmyVcB27dq1sn79ejlz5oyIiHh7e0uLFi2kVatWWdswAAAAAAAAALCAbBGwvXXrlrRv31527Ngh9vb24uHhISIiW7ZskXnz5kndunVl9erVUqhQoaxtKAAAAAAAAABkgF1WN+BJDB48WHbu3Cnvv/++3Lx5U86ePStnz56VmzdvyvTp02XXrl0yePDgrG4mAAAAAAAAAGRIthhhu3r1ahkwYIAMGzbMLD1//vwyfPhwCQsLk8WLF2dR6wAAAAAAAADAMrLFCNvcuXOLr69vqssrVKgguXPntmKLAAAAAAAAAMDyskXAtmPHjrJixQqJi4tLtiw2Nla+//576dSpUxa0DAAAAAAAAAAsJ1tMifDqq6/KwIEDpXbt2vLGG29I2bJlRUTkv//+ky+//FLu378vr7zyioSGhpqtV7169axoLgAAAAAAAACkS7YI2NavX9/4/++//y4mk0lERFQ1xTyqKiaTKcURuQAAAAAAAABgq7JFwHbhwoVZ3QQAAAAAAAAAyHTZImDbs2fPrG4CAAAAAAAAAGS6bPHQMQAAAAAAAADICbLFCFsRkbNnz8qiRYvk1KlTcvPmTbP5a0VETCaT/PTTT1nUOgAAAAAAAADIuGwRsP3uu++kZ8+eEhsbK4UKFRJnZ+dkeRIeRAYAAAAAAAAA2VW2CNiOHj1aKlSoICtXrpTy5ctndXMAAAAAAAAAIFNkizlsr127Jv369SNYCwAAAAAAAOCpli0Ctn5+fhIWFpbVzQAAAAAAAACATJUtArYzZ86UJUuWyMqVK7O6KQAAAAAAAACQabLFHLaVKlWS9957T7p27Sr58+eXkiVLir29vVkek8kkhw8fzqIWAgAAAAAAAEDGZYuA7RdffCFvvfWWODo6SpkyZcTZ2TmrmwQAAAAAAAAAFpctArZTp06V2rVry9q1awnWAgAAAAAAAHhqZYs5bCMiIuSVV14hWAsAAAAAAADgqZYtArb169eXP//80+Ll7tixQ1q3bi3FixcXk8kkq1evfuw627Ztk+rVq4uDg4OULVtWgoODk+WZPXu2eHt7i6Ojo/j5+cn+/fst3nYAAAAAAAAAT59sEbCdM2eObN++XWbMmCHXr1+3WLnR0dFSpUoVmT179hPlP336tLRs2VIaNmwohw4dkiFDhkifPn1k48aNRp7ly5fL0KFDJSgoSEJDQ6VKlSoSGBgoV65csVi7AQAAAAAAADydTKqqWd2IxylYsKDEx8fLvXv3RETE0dFR7O3tzfKYTCaJiIhIdx0mk0l+/PFHadeuXap5Ro4cKevWrZOjR48aaV27dpVbt27Jhg0bRETEz89Pnn/+efn8889FRCQ+Pl48PT3lrbfeklGjRj1RWyIjI8XZ2VkiIiLEycnJbJn3qHVp7JnImekt07xOWuuxRh3prQcAAAAAAADISo+K9yWVLR461rFjRzGZTFndDNmzZ48EBASYpQUGBsqQIUNEROT+/fty8OBBGT16tLHczs5OAgICZM+ePdZsKgAAAAAAAIBsKFsEbFOaJzYrhIeHS7FixczSihUrJpGRkXL37l25efOmxMXFpZjn2LFjqZYbExMjMTExxuvIyEjLNhwAAAAAAABAtpAt5rB92k2bNk2cnZ2NP09Pz6xuEgAAAAAAAIAsYLMjbENDQ9O8TvXq1TOhJf/P3d1dLl++bJZ2+fJlcXJykrx584q9vb3Y29unmMfd3T3VckePHi1Dhw41XkdGRhK0BQAAAAAAAHIgmw3Y1qxZ84nnrVVVMZlMEhcXl6lt8vf3l/Xr15ulbd68Wfz9/UVEJE+ePFKjRg0JCQkxHl4WHx8vISEhMnDgwFTLdXBwEAcHh0xrNwAAAAAAAIDswWYDtgsXLsz0Om7fvi0nTpwwXp8+fVoOHTokLi4uUqpUKRk9erRcuHBBFi9eLCIi/fr1k88//1xGjBghr732mvz666/y/fffy7p164wyhg4dKj179pSaNWtKrVq1ZObMmRIdHS29e/fO9P4AAAAAAAAAyN5sNmDbs2fPTK/jwIED0rBhQ+N1wrQEPXv2lODgYLl06ZKEhYUZy318fGTdunXy9ttvy6xZs6RkyZLy9ddfS2BgoJGnS5cucvXqVRk/fryEh4dL1apVZcOGDckeRAYAAAAAAAAASdlswNYaGjRoIKqa6vLg4OAU1/njjz8eWe7AgQMfOQUCAAAAAAAAAKTELqsbAAAAAAAAAAB4iIAtAAAAAAAAANgIArYAAAAAAAAAYCMI2AIAAAAAAACAjSBgCwAAAAAAAAA2ItsEbCMjI2X69OkSGBgo1apVk/3794uIyI0bN+Tjjz+WEydOZHELAQAAAAAAACBjcmV1A57E+fPnpX79+nLu3DkpV66cHDt2TG7fvi0iIi4uLjJv3jw5e/aszJo1K4tbCgAAAAAAAADply0CtsOHD5eoqCg5dOiQuLm5iZubm9nydu3aydq1a7OodQAAAAAAAABgGdliSoRNmzbJoEGDpGLFimIymZItL126tJw7dy4LWgYAAAAAAAAAlpMtArZ3794VV1fXVJdHRUVZsTUAAAAAAAAAkDmyRcC2YsWKsmPHjlSXr169WqpVq2bFFgEAAAAAAACA5WWLgO2QIUNk2bJl8v7770tERISIiMTHx8uJEyeke/fusmfPHnn77bezuJUAAAAAAAAAkDHZ4qFjr776qpw9e1bGjh0rY8aMERGRZs2aiaqKnZ2dTJ06Vdq1a5e1jQQAAAAAAACADMoWAVsRkTFjxkj37t1l1apVcuLECYmPj5cyZcpIhw4dpHTp0lndPAAAAAAAAADIMJsP2N65c0fq1q0rffv2lX79+jH1AQAAAAAAAICnls3PYZsvXz45ffq0mEymrG4KAAAAAAAAAGQqmw/Yijycr3bjxo1Z3QwAAAAAAAAAyFTZImA7btw4+ffff6V79+6ya9cuuXDhgty4cSPZHwAAAAAAAABkZzY/h62IyLPPPisiIn///bcsXbo01XxxcXHWahIAAAAAAAAAWFy2CNiOHz+eOWwBAAAAAAAAPPWyRcB2woQJWd0EAAAAAAAAAMh02WIOWwAAAAAAAADICbLFCNtJkyY9No/JZJJx48ZZoTUAAAAAAAAAkDmyRcD2UVMimEwmUVUCtgAAAAAAAACyvWwxJUJ8fHyyv9jYWDl58qS8/fbbUrNmTbly5UpWNxMAAAAAAAAAMiRbBGxTYmdnJz4+PvLhhx9KuXLl5K233srqJgEAAAAAAABAhmTbgG1i9erVk/Xr12d1MwAAAAAAAAAgQ56KgO2BAwfEzu6p6AoAAAAAAACAHCxbPHRs8eLFKabfunVLduzYIT/88IP06dPHyq0CAAAAAAAAAMvKFgHbXr16pbqsaNGiMmrUKBk/frz1GgQAAAAAAAAAmSBbBGxPnz6dLM1kMknhwoWlYMGCWdAiAAAAAAAAALC8bBGwNZlM4urqKnnz5k1x+d27d+Xq1atSqlQpK7cMAAAAAAAAACwnWzypy8fHR3788cdUl69Zs0Z8fHys2CIAAAAAAAAAsLxsEbBV1Ucuf/DggdjZZYuuAAAAAAAAAECqbDbKGRkZKWFhYRIWFiYiItevXzdeJ/47cuSILFu2TDw8PNJVz+zZs8Xb21scHR3Fz89P9u/fn2reBg0aiMlkSvbXsmVLI0+vXr2SLW/WrFm62gYAAAAAAAAgZ7HZOWw/+eQTmTRpkog8nMN2yJAhMmTIkBTzqqpMmTIlzXUsX75chg4dKnPnzhU/Pz+ZOXOmBAYGyvHjx8XNzS1Z/h9++EHu379vvL5+/bpUqVJFOnXqZJavWbNmsnDhQuO1g4NDmtsGAAAAAAAAIOex2YBt06ZNpUCBAqKqMmLECOnWrZtUr17dLI/JZJL8+fNLjRo1pGbNmmmu4+OPP5a+fftK7969RURk7ty5sm7dOlmwYIGMGjUqWX4XFxez18uWLZN8+fIlC9g6ODiIu7t7mtsDAAAAAAAAIGez2YCtv7+/+Pv7i4hIdHS0dOzYUZ577jmLlX///n05ePCgjB492kizs7OTgIAA2bNnzxOVMX/+fOnatavkz5/fLH3btm3i5uYmhQsXlkaNGsmUKVOkSJEiqZYTExMjMTExxuvIyMg09gYAAAAAAADA08Bm57BNLCgoyKLBWhGRa9euSVxcnBQrVswsvVixYhIeHv7Y9ffv3y9Hjx6VPn36mKU3a9ZMFi9eLCEhIfL+++/L9u3bpXnz5hIXF5dqWdOmTRNnZ2fjz9PTM32dAgAAAAAAAJCt2ewI25Ts3r1bQkNDJSIiQuLj482WmUwmGTdunNXaMn/+fKlUqZLUqlXLLL1r167G/ytVqiSVK1eWMmXKyLZt26Rx48YpljV69GgZOnSo8ToyMpKgLQAAAAAAAJADZYuA7Y0bN6Rly5ayf/9+UVUxmUyiqiIixv/TGrAtWrSo2Nvby+XLl83SL1++/Nj5Z6Ojo2XZsmXGQ9EepXTp0lK0aFE5ceJEqgFbBwcHHkwGAAAAAAAAIHtMiTB8+HA5cuSILF26VE6dOiWqKhs3bpR///1X+vXrJ1WrVpWLFy+mqcw8efJIjRo1JCQkxEiLj4+XkJAQY+7c1KxYsUJiYmLk1VdffWw958+fl+vXr4uHh0ea2gcAAAAAAAAg58kWAdv169fL//73P+nSpYsULFhQRB4+IKxs2bIye/Zs8fb2liFDhqS53KFDh8pXX30lixYtkn/++Uf69+8v0dHR0rt3bxER6dGjh9lDyRLMnz9f2rVrl+xBYrdv35bhw4fL3r175cyZMxISEiJt27aVsmXLSmBgYNo7DgAAAAAAACBHyRZTIty6dUueffZZEREpUKCAiDwMjiZo2rSpvPvuu2kut0uXLnL16lUZP368hIeHS9WqVWXDhg3Gg8jCwsLEzs48pn38+HHZtWuXbNq0KVl59vb2cuTIEVm0aJHcunVLihcvLk2bNpXJkycz5QEAAAAAAACAx8oWAdvixYtLeHi4iDyc79XNzU0OHz4sbdu2FRGRCxcuiMlkSlfZAwcOlIEDB6a4bNu2bcnSfH19jflzk8qbN69s3LgxXe0AAAAAAAAAgGwRsK1Xr55s3rxZxowZIyIPR8bOmDFD7O3tJT4+XmbOnMmUAwAAAAAAAACyvWwRsB06dKhs3rxZYmJixMHBQSZMmCB//fWXjBs3TkQeBnQ/++yzLG4lAAAAAAAAAGRMtgjYVqpUSSpVqmS8Lly4sGzZskVu3bol9vb2xoPIAAAAAAAAACA7yxYB29QUKlQoq5sAAAAAAAAAABZjl9UNeFJhYWHSr18/8fX1FRcXF9mxY4eIiFy7dk0GDRokf/zxRxa3EAAAAAAAAAAyJluMsP3777+lbt26Eh8fL35+fnLixAmJjY0VEZGiRYvKrl27JDo6WubPn5/FLQUAAAAAAACA9MsWAdsRI0ZIoUKFZO/evWIymcTNzc1secuWLWX58uVZ1DoAAAAAAAAAsIxsMSXCjh07pH///uLq6iomkynZ8lKlSsmFCxeyoGUAAAAAAAAAYDnZImAbHx8v+fLlS3X51atXxcHBwYotAgAAAAAAAADLyxYB2+rVq8u6detSXBYbGyvLli2TF154wcqtAgAAAAAAAADLyhYB29GjR8uGDRukf//+cvToURERuXz5smzZskWaNm0q//zzj4waNSqLWwkAAAAAAAAAGZMtHjrWvHlzCQ4OlsGDB8uXX34pIiKvvvqqqKo4OTnJ4sWLpV69elncSgAAAAAAAADImGwRsBUR6d69u3To0EE2bdokJ06ckPj4eClTpowEBgZKwYIFs7p5AAAAAAAAAJBhNhuwfffdd6Vr165SuXJlIy1//vzSvn37LGwVAAAAAAAAAGQem53Ddvr06cZ8tSIi169fF3t7e/n111+zsFUAAAAAAAAAkHlsNmCbElXN6iYAAAAAAAAAQKbJVgFbAAAAAAAAAHiaEbAFAAAAAAAAABthsw8dExE5c+aMhIaGiohIRESEiIj8999/UqhQoRTzV69e3VpNAwAAAAAAAACLs+mA7bhx42TcuHFmaQMGDEiWT1XFZDJJXFyctZoGAAAAAAAAABZnswHbhQsXZnUTAAAAAAAAAMCqbDZg27Nnz6xuAgAAAAAAAABYFQ8dAwAAAAAAAAAbQcAWAAAAAAAAAGwEAVsAAAAAAAAAsBEEbAEAAAAAAADARhCwBQAAAAAAAAAbQcAWAAAAAAAAAGwEAVsAAAAAAAAAsBEEbAEAAAAAAADARhCwBQAAAAAAAAAbQcAWAAAAAAAAAGwEAVsAAAAAAAAAsBEEbAEAAAAAAADARuT4gO3s2bPF29tbHB0dxc/PT/bv359q3uDgYDGZTGZ/jo6OZnlUVcaPHy8eHh6SN29eCQgIkP/++y+zuwEAAAAAAADgKZArqxuQlZYvXy5Dhw6VuXPnip+fn8ycOVMCAwPl+PHj4ubmluI6Tk5Ocvz4ceO1yWQyWz5jxgz59NNPZdGiReLj4yPjxo2TwMBA+fvvv5MFd2Ed3qPWpXmdM9NbZkJLAAAAAAAAgEfL0SNsP/74Y+nbt6/07t1bKlasKHPnzpV8+fLJggULUl3HZDKJu7u78VesWDFjmarKzJkzZezYsdK2bVupXLmyLF68WC5evCirV6+2Qo8AAAAAAAAAZGc5NmB7//59OXjwoAQEBBhpdnZ2EhAQIHv27El1vdu3b4uXl5d4enpK27Zt5a+//jKWnT59WsLDw83KdHZ2Fj8/v0eWGRMTI5GRkWZ/AAAAAAAAAHKeHBuwvXbtmsTFxZmNkBURKVasmISHh6e4jq+vryxYsEB++uknWbJkicTHx0vt2rXl/PnzIiLGemkpU0Rk2rRp4uzsbPx5enpmpGsAAAAAAAAAsqkcG7BND39/f+nRo4dUrVpV6tevLz/88IO4urrKvHnzMlTu6NGjJSIiwvg7d+6chVoMAAAAAAAAIDvJsQHbokWLir29vVy+fNks/fLly+Lu7v5EZeTOnVuqVasmJ06cEBEx1ktrmQ4ODuLk5GT2BwAAAAAAACDnybEB2zx58kiNGjUkJCTESIuPj5eQkBDx9/d/ojLi4uLkzz//FA8PDxER8fHxEXd3d7MyIyMjZd++fU9cJgAAAAAAAICcK1dWNyArDR06VHr27Ck1a9aUWrVqycyZMyU6Olp69+4tIiI9evSQEiVKyLRp00REZNKkSfLCCy9I2bJl5datW/LBBx/I2bNnpU+fPiIiYjKZZMiQITJlyhQpV66c+Pj4yLhx46R48eLSrl27rOomAAAAAAAAgGwiRwdsu3TpIlevXpXx48dLeHi4VK1aVTZs2GA8NCwsLEzs7P5/EPLNmzelb9++Eh4eLoULF5YaNWrIb7/9JhUrVjTyjBgxQqKjo+WNN96QW7duSZ06dWTDhg3i6Oho9f4BAAAAAAAAyF5MqqpZ3QiYi4yMFGdnZ4mIiEg2n633qHVpLu/M9JZpXiet9VijDluvBwAAAAAAAEjJo+J9SeXYOWwBAAAAAAAAwNYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG0HAFgAAAAAAAABsBAFbAAAAAAAAALARBGwBAAAAAAAAwEYQsAUAAAAAAAAAG5HjA7azZ88Wb29vcXR0FD8/P9m/f3+qeb/66iupW7euFC5cWAoXLiwBAQHJ8vfq1UtMJpPZX7NmzTK7GwAAAAAAAACeAjk6YLt8+XIZOnSoBAUFSWhoqFSpUkUCAwPlypUrKebftm2bdOvWTbZu3Sp79uwRT09Padq0qVy4cMEsX7NmzeTSpUvG33fffWeN7gAAAAAAAADI5nJ0wPbjjz+Wvn37Su/evaVixYoyd+5cyZcvnyxYsCDF/N9++60MGDBAqlatKhUqVJCvv/5a4uPjJSQkxCyfg4ODuLu7G3+FCxe2RncAAAAAAAAAZHM5NmB7//59OXjwoAQEBBhpdnZ2EhAQIHv27HmiMu7cuSMPHjwQFxcXs/Rt27aJm5ub+Pr6Sv/+/eX69euPLCcmJkYiIyPN/gAAAAAAAADkPDk2YHvt2jWJi4uTYsWKmaUXK1ZMwsPDn6iMkSNHSvHixc2Cvs2aNZPFixdLSEiIvP/++7J9+3Zp3ry5xMXFpVrOtGnTxNnZ2fjz9PRMX6cAAAAAAAAAZGu5sroB2dX06dNl2bJlsm3bNnF0dDTSu3btavy/UqVKUrlyZSlTpoxs27ZNGjdunGJZo0ePlqFDhxqvIyMjCdoCAAAAAAAAOVCOHWFbtGhRsbe3l8uXL5ulX758Wdzd3R+57ocffijTp0+XTZs2SeXKlR+Zt3Tp0lK0aFE5ceJEqnkcHBzEycnJ7A8AAAAAAABAzpNjA7Z58uSRGjVqmD0wLOEBYv7+/qmuN2PGDJk8ebJs2LBBatas+dh6zp8/L9evXxcPDw+LtBsAAAAAAADA0yvHBmxFRIYOHSpfffWVLFq0SP755x/p37+/REdHS+/evUVEpEePHjJ69Ggj//vvvy/jxo2TBQsWiLe3t4SHh0t4eLjcvn1bRERu374tw4cPl71798qZM2ckJCRE2rZtK2XLlpXAwMAs6SMAAAAAAACA7CNHz2HbpUsXuXr1qowfP17Cw8OlatWqsmHDBuNBZGFhYWJn9/8x7Tlz5sj9+/flpZdeMisnKChIJkyYIPb29nLkyBFZtGiR3Lp1S4oXLy5NmzaVyZMni4ODg1X7BgAAAAAAACD7ydEBWxGRgQMHysCBA1Nctm3bNrPXZ86ceWRZefPmlY0bN1qoZQAAAAAAAABymhw9JQIAAAAAAAAA2BICtgAAAAAAAABgIwjYAgAAAAAAAICNIGALAAAAAAAAADaCgC0AAAAAAAAA2AgCtgAAAAAAAABgIwjYAgAAAAAAAICNIGALAAAAAAAAADaCgC0AAAAAAAAA2AgCtgAAAAAAAABgIwjYAgAAAAAAAICNIGALAAAAAAAAADaCgC0AAAAAAAAA2AgCtgAAAAAAAABgIwjYAgAAAAAAAICNIGALAAAAAAAAADaCgC0AAAAAAAAA2AgCtgAAAAAAAABgIwjYAgAAAAAAAICNIGALAAAAAAAAADaCgC0AAAAAAAAA2AgCtgAAAAAAAABgIwjYAgAAAAAAAICNIGALAAAAAAAAADaCgC0AAAAAAAAA2AgCtgAAAAAAAABgIwjYAgAAAAAAAICNIGALAAAAAAAAADaCgC0AAAAAAAAA2AgCtgAAAAAAAABgIwjYAgAAAAAAAICNyJXVDQCeBt6j1qV5nTPTW2ZCSwAAAAAAAJCdMcIWAAAAAAAAAGxEjg/Yzp49W7y9vcXR0VH8/Pxk//79j8y/YsUKqVChgjg6OkqlSpVk/fr1ZstVVcaPHy8eHh6SN29eCQgIkP/++y8zuwAAAAAAAADgKZGjA7bLly+XoUOHSlBQkISGhkqVKlUkMDBQrly5kmL+3377Tbp16yavv/66/PHHH9KuXTtp166dHD161MgzY8YM+fTTT2Xu3Lmyb98+yZ8/vwQGBsq9e/es1S0AAAAAAAAA2VSODth+/PHH0rdvX+ndu7dUrFhR5s6dK/ny5ZMFCxakmH/WrFnSrFkzGT58uDzzzDMyefJkqV69unz++eci8nB07cyZM2Xs2LHStm1bqVy5sixevFguXrwoq1evtmLPAAAAAAAAAGRHOTZge//+fTl48KAEBAQYaXZ2dhIQECB79uxJcZ09e/aY5RcRCQwMNPKfPn1awsPDzfI4OzuLn59fqmUCAAAAAAAAQIJcWd2ArHLt2jWJi4uTYsWKmaUXK1ZMjh07luI64eHhKeYPDw83liekpZYnJTExMRITE2O8joiIEBGRyMjIZHnjY+6kWk5qUirncdJajzXqsOV6rNUXAAAAAAAAZD8JcSBVfWzeHBuwtSXTpk2TiRMnJkv39PS0SPnOMy1STJbX8bTVY62+AAAAAAAAwDZERUWJs7PzI/Pk2IBt0aJFxd7eXi5fvmyWfvnyZXF3d09xHXd390fmT/j38uXL4uHhYZanatWqqbZl9OjRMnToUON1fHy83LhxQ4oUKSImk+mJ+hMZGSmenp5y7tw5cXJyeqJ10soadVirHvpim/XQF9ush77YZj1PU1+sVQ99sc166Itt1kNfbLMe+mKb9dCXnF0PfbHNeuiLbdaT0/uiqhIVFSXFixd/bN4cG7DNkyeP1KhRQ0JCQqRdu3Yi8jBQGhISIgMHDkxxHX9/fwkJCZEhQ4YYaZs3bxZ/f38REfHx8RF3d3cJCQkxArSRkZGyb98+6d+/f6ptcXBwEAcHB7O0QoUKpatfTk5OmbrTW6sOa9VDX2yzHvpim/XQF9us52nqi7XqoS+2WQ99sc166Itt1kNfbLMe+pKz66EvtlkPfbHNenJyXx43sjZBjg3YiogMHTpUevbsKTVr1pRatWrJzJkzJTo6Wnr37i0iIj169JASJUrItGnTRERk8ODBUr9+ffnoo4+kZcuWsmzZMjlw4IB8+eWXIiJiMplkyJAhMmXKFClXrpz4+PjIuHHjpHjx4kZQGAAAAAAAAABSk6MDtl26dJGrV6/K+PHjJTw8XKpWrSobNmwwHhoWFhYmdnZ2Rv7atWvL0qVLZezYsfLuu+9KuXLlZPXq1fLcc88ZeUaMGCHR0dHyxhtvyK1bt6ROnTqyYcMGcXR0tHr/AAAAAAAAAGQvOTpgKyIycODAVKdA2LZtW7K0Tp06SadOnVItz2QyyaRJk2TSpEmWauITcXBwkKCgoGRTK2S3OqxVD32xzXroi23WQ19ss56nqS/Wqoe+2GY99MU266EvtlkPfbHNeuhLzq6HvthmPfTFNuuhL0/OpKqaKSUDAAAAAAAAANLE7vFZAAAAAAAAAADWQMAWAAAAAAAAAGwEAVsAAAAAAAAAsBEEbAEAAAAAAADARhCwBQDABvFM0JwpPj7e7DX7AQAAAJDzELDN4T777DO5fft2VjcDSVjzfUkaHLA0a/XFGvVMmjRJ/v7770ytQ0RkyZIlmV6Htd6XK1euSFRUVKbWYa2+HD16VOLi4jK9npCQEImKihKTyZRpdVhjH0vwtAQcrbXN7Owenpr98ssvIiKZsh9Y8/3PbNb4TD5NrPU9lvC5T/z5z4xjQdJzmMw6p8nsep628/HMPrcUebqOYyKZ/11prX3MGt/5T9O1hYj55yWztp+1jv3WYq1j/9PCGsdL3oNMorBJ8fHxmV7H0aNH1WQyaa9evfT27duZVk9cXFymlf00stb7omq+n+3YsUOvXbtm0fKt1Rdr1HPlyhU1mUwaGBio//77b6bUoaq6detWNZlMOnr06Eyrw1rvS2hoqObOnVu3bduWaXVYqy/jx4/X3Llz66+//qqxsbGZVs+sWbO0UKFCumDBAo2KisqUOqyxjyVIfPw/cuSIVerJDNbcZqqqp0+fVpPJpJ9++qnFy7Z2X6wlODhY//vvv0wrP+l5mTXO0yxdh7W+xxJ/HqOjozU2NtZIy6zj5w8//JAp5SY1ceJEvXTpkkXLtNb3mDX22aT1/PLLLxbfXqpZ9z1mjTpOnDhh8fKz4prvwoULev/+fYvX8TRdWyQ1e/Zs/fXXX7PtsT8rLF++PFPKtdbx0hqscbxM/Nlfs2aNnjhxghiQhRCwtUExMTHG/+/du2e2zNIHj23btqmzs7P26NEjU4IDifty5MgRPXfunF65ckVVLdsXax0QrFVPZr8vquZ9GTlypFaoUEFPnjyZ7fYxa9STsK3OnDmjbm5u2qRJE/3nn38sWkeCe/fuaXBwsDo4OOiIESMypQ7VzH9fDh06pAULFtThw4cbaZn1+bHWPta4cWMtVaqUhoSE6IMHDzKtnl69emmFChX066+/1sjISIuXb619LPGxZNSoUdqoUSM9f/58ptWnqjp48GBdsGCBxfe1zN5mSYNY0dHROm7cOG3fvr3+9ddfFq3L2u9/VFSU3rhxw+LvSeLyPvjgA82VK5f+9ddfmXKRlbius2fPZsqxLCYmRh88eKDHjh3TGzduGOmW6o+1vscSb5uPP/5Y27Ztq40bN9bXXntNIyIiLF6fquo///yjrq6uumLFCouXnbg/ixYtUpPJpDt27LB4PZn9PZY0iJ70Br2l9zPVhzc6fX19M2U/s9ZxLLGRI0fq+vXrMzWQM3LkSG3Tpo1xrWRJ1tzHJk6cqK+++qru3r07U46XT8O1har5Nvv888+1QIECeuTIEYtuM2tewyQO0Cc9r8mMz82///6r7u7u+u2331q03MTb//bt25lyLp60nsyU2cfLxO/t6NGjtUSJErpgwYJMudGRFTcesxoBWxvy22+/mb2eNWuWvvTSS/rWW2+ZjVCzxA6U+ACxdetWdXBw0LfffttiB6SRI0dqaGio2WtPT08tVaqUtmzZ0uirpfuyfft2/e6773TPnj0aFhZmsTqSlrNs2TL94osvdNasWXrz5s1MOdHNjPclJeHh4dq1a1f99ddfLVqutfpijXoSn3T8/fffmj9/fn355Zf177//tlgdquZ9Wbp0qdrZ2em0adMyrY7M2l6HDx/WvHnz6rvvvmuWbunRb9bax+7evWv8v3Hjxlq2bFndsmWLxYO2iW/Qde/eXatUqaJff/21RS8SrLGPJbV//36tW7eu7t271+JlJz727tq1SwsVKmTxYIo1t9mqVav0zp07qvpwhHrFihX1o48+StaO9LJWXxLelzVr1mizZs20VKlS2r17d6MvlhQaGqqffvqp/vjjjxYvWzV5EKJbt266bt06i9bx33//ab9+/bRSpUpqMpm0XLly2r9/f2O5Jc4xrPU9lmDUqFHq6uqqX3zxhS5cuFA9PDy0Ro0ayQYiWML169e1bt26+s4771i87ATr1q3TSZMm6XfffWfRcq3xPZZ4/5k8ebI2a9ZMXVxcdPDgwZk2Ou306dPauXNn3bx5s8XLttZxLHE9v/zyizo4OOiuXbssWkfS77Dnn39e9+/fb9E6rH1tMXLkSHVzc9Ply5cnCzxn9Hvsabq2SOy3337TDz74QJcsWaKqlg0WWePYn3TU7pdffqkDBw7UqVOn6qlTp4x0SwfBIiIitHHjxmbfl5Y0ceJErVevnj733HP61VdfWfQXIon3sV27duny5ct19+7dRvwiM+rJ7HPYSZMmqZubm+7ZsyfTb3DcuHFDL1++bLY8M+IxN27c0JiYGOPcJStGDROwtRETJ07UatWq6cqVK1X14WgRJycnHThwoJYuXVrr16+vs2fPNvJnZIdMvO6ECRP07bffVldXVzWZTPr6669n+G7IH3/8oX5+fvrCCy/osWPHdN++fVqyZEndsmWLzp49W7t06aJlypTR7du3Z7gviQ0fPlxLlCih3t7e6uXlpTVr1tSQkBCL1JF4/bffflsLFSqk1atXV3d3dy1btqz+8MMPxkW2JerIjPclJXPnztUiRYpotWrV9Pjx4xYr11p9sUY9iesYOXKkvv3221q6dGk1mUzaokULi223xPV8+OGH+vbbb2uBAgXUZDLpuHHjLF5HZm2vY8eOqZ2dnY4dO9YsfeLEiVqgQAG9evVqhutQtd4+lviL+aefftL58+eryWTSSpUqaUhIiMVO3hL3Z+nSpTp9+nTNkyePlixZUufPn2/xfTmz9rGkvvjiC3355Zf1pZdeytRRyV988YVOmTJFp06datFyrbnNVq9erSaTSV988UVdtWqVRkdH68qVK9Xe3l7/+OOPZO1JK2u//2vXrtW8efPqjBkzNCQkRF977TXNly+f8b1sCb/99puaTCZ1cHDIlNGViY0ePVqLFCmiP/30k0V/4n348GH19PTUPn366CeffKKbNm3Snj17aoECBTQgIMA4t8jIRYK1vscS/P3331q5cmXjPG/NmjXq7Oxsdh6btF1PKrXt8OOPP2r+/Pl19+7daW/wY+zbt0/LlCmjBQoU0FWrVqmqZaZ2sPZ539ixY9XV1VWXLl2qGzdu1MqVK2vNmjX19OnTFq1nzpw5WqRIEa1SpYrFbwhkxffYwoULdebMmfrZZ59lSvmqql999ZX27dtXe/XqpaqWCwpYex/75ZdftHjx4sZ3VlxcnF6+fFn37t2r169fN9LS42m6tkgsYeoFk8mkX3zxhUXLtsax/80339T69evrvn37VPVh0C5//vzaqVMnzZcvnzZt2lR//vnnFNuUFqntNxs3btQCBQpY5NwicR2ffPKJuru765QpU7R///5qZ2enI0eOtHjQfsSIEVq6dGmtVKmS+vv76wsvvGCxAQ6ZfbxMvL1u3bqljRo10q+//lpVH06JsmPHDn399dd13rx5evLkyQzXl2Ds2LFavXp1dXFx0e7du5ud/1ky5vPee+9p48aN9dlnn9Vu3boZAw6tHbQlYGsjjhw5os2aNdOAgABdtGiR9unTR7du3aqqqpcvX9bu3btrnTp19PPPPzfWyegOOW3aNC1SpIhu3rxZN23apHPmzNF8+fJZZK6ejRs3asuWLbV27do6duxY/eCDD4xlBw4c0G7duqmPj48xEio9O37idYKDg7VIkSK6c+dOjYqK0pCQEO3Zs6eWKlXKuGCwhEuXLmnDhg31jz/+0Nu3b2tsbKy2a9fOGHGX3r4klpnvS1JhYWFau3ZttbOzM/Y3S7JWX6xRzyeffKIuLi66e/duPXDggG7cuFFdXFw0MDDQohe7QUFB6urqqqtXr9bly5fr8OHD1d7e3qLzDmXm9lq2bJmaTCazC5tp06ZpsWLFdP369RltejLW2sfeffddLVKkiM6ZM0eDgoK0evXqxvQIlrzjPm7cOC1cuLAuWrRIv/rqK23SpImWKFHCYkFbVevsYwkmTZqkuXLlUi8vr0ybN+3ixYtat25dNZlMOnjwYFW1/DyZmbHNkn5XXL58WcuWLasuLi7ar18/femll3TdunU6ZMgQbdOmjcXmGM/s9z8+Pl6joqK0ffv2xiiOmzdvqoeHhw4aNMgidSSIjIzUmTNnar58+ZKN6Lek33//XX19fZN9T2b0POzQoUOaP39+HTlypNkUUjdv3tTFixdr4cKFtXXr1hmqI7HM+h5Lui9v3bpVS5YsqaoPg7UFChTQuXPnqurDKTIWLlyY4Rs4Bw4c0Fu3bhmvr1y5oi1bttRJkyapqmWPAdeuXdMPPvhAPTw8tG3btka6peqwxvfY8ePHtWrVqkZQY+fOnerg4KALFy5UVcturzt37mj16tXVZDLpihUrMuXi1lrfY2fOnNFnnnlGTSaTsW9lxs3HPn36qMlk0ueeey5TpkPIrH0s8XsbGRmpv/zyi/r5+enly5f16NGjOm7cOPX29tZy5crpiy++mGxEnC31JavqUX3465oCBQpo9+7dM2VkYmZew+zZs0d9fX21ffv2+ssvv2inTp2MwNa5c+e0Tp062qRJE12zZo2xTka+O3fu3Kk3b940Xl+/fl3btm2rY8aMUVXLHMv+/PNPnTp1qtmvaZYvX6729vY6fPjwDAVtE39m5s2bp8WKFTNG7gcFBamjo6PZtrKEzD5ebt26Va9du6YlSpTQiRMn6tq1a7Vr167q7++v1atXV19fX+N8MKM3amfNmqVubm76xRdf6Pz587Vu3bpat25di99QGzt2rBYpUkTnzZunY8aM0Q4dOmjevHmNeI81p0wgYGsDEnbCY8eOaZMmTTQgIECrVKli9hOC8+fPa48ePbROnTrJRiikt862bdsmm8dk/fr1mjdvXu3fv3+65hpLfJDcsGGDtmnTRp2dnXXixIlm+Q4ePKgvv/yyli1bNs0/l/ryyy+TpQ0ZMkS7du1qlvbnn39qhw4dtGvXrmY/aU6vWbNmafXq1bVp06Z68+ZNs4NHkyZNtEaNGhmuI7Pel4SyU3LhwgWtVKmSVqlSRc+cOZOuslOrL7P6khX19OjRwxj5kOCvv/7SQoUKafv27S0yiuT27dvasGFD/fDDD420qKgonTNnjtnFQkZYY3vNnj1bTSaTfvXVVzp9+nR1cXHRTZs2JcuXMNoivaz13p85c0a9vLzMfjp6//59rVevnnp5eWlISEiGH6wRHx+v4eHhxty1iXXq1EldXV0t8iCyzNzHUjvGzJ49W4sUKaLDhg3Tc+fOpbv8BCmdJO3evVtbtWqlLi4uxl18SwUgMvtzeerUKePiY926ddq+fXv9/PPP9bPPPlNnZ2etWbOmlitXTr///vsM1aNqnWOM6sN9oXbt2rphwwYNCwvTEiVK6BtvvGEs/+mnn9I8giS1/evevXs6bdo0NZlMZje1LWnbtm1aokSJFOf9i4mJSVdAKiwsTO3s7IyLzIQgUEJZt2/fNoLRixcvzkDr/19mfI8lvnBNOJ8LCwvTFi1a6PTp07VAgQI6b948I8/+/fu1U6dOZtNmPYnE23jDhg1qMpm0devWOm7cOGPbffbZZ+rm5maxAFTi17du3dKZM2dq2bJlzX5+m9HjTGZ8j8XHxycLKp46dUorVaqksbGxunLlSi1QoIDOmTNHVR/Oafv999+n6/ic2r5/9+5dffbZZ7VixYp64MABi17cZuZxLGk7Hzx4oBs2bFB/f38tV66cRkdHq2rG3vfUtsWYMWO0SJEiOm3aNIs+BNga50ojR47UoKAgXbZsmZYoUUJbtGihrq6u2qtXL/3qq6/0xx9/1LJly2Z4cEh2v7Z41HfFt99+q7ly5dJRo0ZZ/KZAZl3DJHwODh48qOXKldPmzZtrvXr1NDw83Mhz4sQJI2ibeKTtk0r8efn333+Nh6cNGzbM+AXKggULtFChQhb53OzZs0dNJpPmy5fP+OVzgu+//15z5cqlI0eOTPP7v3PnTuP/Ce9v3759jZvNq1ev1oIFCxrfl9HR0WbbMb0y43iZeD8eNWqU5smTR+/du6efffaZuri4qLOzs44aNcq4QditWzd97bXXMtyXffv26ZQpU3Tp0qVG2rlz57RPnz764osvGqO8M+r8+fNmv3xXfRgv6d+/v7q4uOiff/5pkXqeFAHbLJb0wP3XX39ps2bNNF++fGYnuKoPd5RevXqpr6+v8ZOs9IqJidHq1aubXUAlHHT79++vJpMpzYHOxH1JmOcjJCREGzRooCVLlkz2hPDQ0FBt1qyZvvTSS09cx/Lly7VOnToaGxub7Gcezz//fLKT9JkzZ6qHh0e6AkOJ+xMTE6Nz587V0qVLq7e3t7GtEk7cQkND1cXFJc0XIEllxvuStC/btm3T5cuX6969e415ci5cuKDPPPOM1qxZU8+ePZuhPiTIrL5Yu564uDiNj4/XVq1aaYcOHYz0hH08IVBQv379DG+7qKgo9fLySnbH89atW9qqVSs1mUz69ttvZ6gOa70vs2bNMn7ilVKwduzYsTp48OAMzWdorb6cPn1aixcvblxoJIyEu3Xrlnp5eekLL7yg69aty/Aoohs3bmiFChV00aJFqmo+d27lypW1UqVKOmvWLOO4kx6ZtY8l7vvRo0f1jz/+MBtRO23aNC1RooQGBQVl6MFjieu5f/++2Qnz4cOHtV69eurt7W3c8LRE0DYzP5c//vijEcz+888/9d69e/rGG2/orFmzVPXhhUPr1q3VZDJZ5GQ3s/qS8H186tQpvXjxot69e1ebNm2qo0eP1jJlymifPn2MPOHh4dq9e3ddvHjxE39mkj74aeLEiTpo0CDdu3evcRPjvffeU5PJlOGb2gntjI+PN/7/448/aqFChYyfjiceDbtp06Y0z5977949Xb9+vZYqVUrbtGljpCe9SL906ZKWKFEiwz9dzKzvsZUrV2qHDh307t27OmTIEHVxcdErV67ozZs3tX79+moymTQoKMjIf+fOHW3evLm2b98+3cfLQYMG6YQJE3TDhg06depU9fb21sqVK+u7776rhw4d0rp16+qUKVMyPIrn66+/1qFDh2qPHj2MUVZ37tzRTz75RJ977jkdMGBAiuulVWZ8jyUeebxmzRoNCwvTEydOaMmSJXXixIlauHBhs5sb+/bt09atW2foJsqWLVt04cKFumXLFuNBiXfu3NHy5ctrlSpV9ODBgxYL2lrje0xVzaYj2b59u1asWFFr1qyZoaBt4jpOnDihJ06cMAuUv/XWW+rt7a2zZs3K8E3tBJmxjyV+L3fs2KElSpTQ33//XVUfHhcmTJigK1asMKbBunLlilapUsXsmSy20hdr1ZP4vZ87d64OGjRIX375Zf3++++NkcfffPONMfLREkHbzLyGSfp52bdvn1aoUEELFCigv/zyi9mykydPav369bVatWppmgf64MGDRhB2xIgR+tNPP+nRo0f1o48+0goVKmiFChX07bff1v3792tAQICOHTvWIiP6v/jiC7W3t9exY8cm+5yvWLEizecaH330kfr6+iabA/21117T4OBg3bBhg9lNtNjYWF24cKEuWrQowwNCMvMc9vTp0/ruu+8ao05VH/6aI+kzS5o0aaKjRo1KVx0JDh8+bFxXJoymTXxe6enpqe+9916ay61Xr55+/PHHZmn//fefOjo6JrvBcOLECfX3909Wf2YjYJuFEh9QVq5caQQ0T5w4oYGBgdqwYcNkc7KFhYXp5MmT03SSkNqB6/PPP1dPT0/dsGGDWfr06dO1TZs22rRp03RdTM2YMUNHjRpl/MRiy5Yt2qxZM/Xz80t2R+L48eNpOrBGREQY+RN/6S9evFhLly6ty5YtMwtmhISEaLVq1TIUIEhY99atW7po0SJ1cnLSV1991SzPnj171NPTU48ePfrE5VrjfUlq+PDh6u7uruXKldNChQpp48aNjbtHFy5c0IoVK2qtWrXSPM+Mtfpi7X05sRUrVmjevHnN7uqpPvw5yyuvvKItWrSwSF/Gjh2rtWrVSnaXcMSIEdqgQQNt1KjRE39BWGN7Xbp0STds2KCffvqpLliwQMPCwoxgxtdff60mk0k/+eQTs/KCgoLUZDIZJ/e20hfV1L98K1SooD169DBex8bGanR0tDZq1EhNJpO2b9/+ietQTb0/derU0aZNmxqv79+/r/Hx8dq+fXt1dXXV7t27Z/j9t+Q+pmq+zUaNGqXPPPOMFixYUKtUqaLdunUzlk2dOlVLliypEyZMSNfNjcT9ef/997V58+bq6+urb775ph44cEBVH04v1LhxYy1TpowRXLOlz2VKeT788EPt2LGjlixZ0pgnuXTp0kbQ4+LFi7p27do0Bwes/f6vXr1aXVxcjKc1L126VE0mk9apU8cs/7vvvqvlypUz+xXRk3rnnXe0SJEi2qFDBy1Tpoz6+vrqsGHDjMDGtGnTNFeuXPr++++nuWxV820WFxdnts2rVaumNWvWNMufEICcMGHCE9dx4MAB7dmzp54/f17XrVunvr6+GhAQYCxPepFerVo1ffPNN9Pdj8Qs/T124MABNZlM+uyzz6qzs7PZjfmwsDAtWbKk1q9fX8eNG6dz5szRhg0baqVKlYwL0CepK/G+ePToUfXy8ko2UmnKlCnavn17zZ07tzo7O5vtw+m5oBo2bJi6urpqhw4dNDAwUO3s7HT48OF67do1vX37tn7yySdatWpVffnll9NUrjW+x7Zv366urq5648YNHT58uPr4+OjFixdV9eEITpPJpMOHDzfy37lzR1u1aqUtW7ZM97nlsGHD1MPDQytUqKClSpXSKlWqGIGJO3fuaIUKFbR69eq6Z8+eNJdtreNY4no+/vhj7dy5s9asWVOnTp1q3HzcsWOHVq1aVf38/NI1t3Ti9owZM0arVKmizs7O6ufnp8OGDTOWvfnmm1q6dGn97LPP0jzvv7WvLT799FOdOHFismBMQlkPHjzQmzdvaosWLfTFF1+0uetXa9aTYPjw4eri4qL/+9//tFatWlq5cmXt0KGDEbhfsmSJOjg46Jtvvmmx7/3MvIb5+eefjWPM4cOHtXz58tqmTZtkN4COHz+u/fv3f+J6zp49qyaTSYcOHar/+9//tGDBgnr48GGzPB9++KF269ZN7e3t1cnJSf39/Y3vlyf5/D+qLR999JHa2dnpp59+mmzZr7/+mqaA+m+//abdunXTevXqmb0H77zzjjo7O2vBggV1/vz5Rvq1a9e0cePGaX44mLWOl6oPY1cmk0lLly5tfPcnLiMyMlJ37dqlrVq10ueeey7NNyASl5XQr2XLlmm+fPn0lVde0cjISLM8Xbt2NbtOexKxsbH6888/Jxs8dO/ePQ0ICNDBgweb3QBVVX3xxRctPr3X4xCwzSJJR4eWLFlSZ8yYYYwW+ueff7Rp06YaEBCQbDh+gic5iCf+4B48eFBDQkL0ypUrevfuXb1w4YK+9NJLWr9+fWNuyZs3b2rLli2NOa2SlvE4I0aMUDc3N50/f75euHDBSN+wYYO2aNFCX3jhhRSDmk9SR+L+7t27V00mk9kJQufOnbVUqVI6b948/fvvv/XixYvapEkTbdq0abrvgPz4449qMpmMu4FRUVEaHBysTk5O2rlzZ927d6/u379fmzdvrn5+fukKClrjfVF9OCrJ1dVVd+zYoffu3dNt27Zp9+7dtWbNmsYdpIsXL6qbm1uaRnJZqy/WqCfpSOTvv/9eDx8+bJwwDxgwQH18fHTRokX64MEDvXr1qrZo0cLsJ+xp7cuxY8f0jz/+MNL279+vdevW1VdffdX4Yo2IiNDWrVub/Sz2cfu0NbbXkSNHtEKFCurn56dubm7q6Oionp6eOnr0aONYljDSdsaMGaqqOn78eHVwcNCDBw8+bjNZtS9J81y+fFlv3rxpjJ5YtmyZent7m/08LjY2Vnv27Kn//vtvuk90T5w4oZcuXTJGV/z+++/GJPqq//8+v/zyy7p7925j3bS8/5m1jyX14YcfqouLi27ZskV37typ8+fPV09PT23SpImRZ8aMGWpvb59s2oe0SPjZ6KRJk3TatGlapkwZbdy4sTHnV2hoqAYGBmq+fPnS9HCozN5mics/d+6cHjp0yHh95coVnTRpkubLl09HjhypPj4+GhgYqDdu3DAr40lPeK3x/icegbp8+XLNlSuXuru7a58+fYw8CaN3+vXrpwMHDtTevXurk5OT8UCatPjll1+0ZMmSZseOSZMmaZ06dTQoKEjv37+v0dHROmbMGH3xxRfTvP8m3mYJD0ht06aNcZ6xfft2Y0TPt99+q/PmzdOmTZum6ULk0KFD6uDgYJzs379/X9euXau+vr5mn5OE8o4dO6a1a9fW1atXp6sfmfk9lnBO1r17dzWZTNqsWTNjf0084rpHjx5atWpVDQgI0L59+xp9S+vF2/Tp0/Wdd94xGwmU9Dx45cqV+tprr2n+/PmT/UrtSf3666/q4eFhdkNx8eLF6uLiYowWvn79uk6aNEm7d+9uc+d9oaGh2rJlSy1atKgWLlzYbMDC2bNntXv37mpvb6/vvvuuDh061HigSlqC6Il9++23WrRoUd25c6fGxMTonj17dMCAAVqiRAnj14B3795VFxcX7dmzZ5rKzorvsVGjRhm/ehg8eLC6ublp+/btjZsEW7du1Zo1a6qPj4/ZSPu0mDp1qrq4uOi6det09erVOmPGDHVycjI79x48eLDmzZs3TQ9TtPa1RXx8vLZs2VJNJpO2atXKbCRgfHy83rt3TydPnqxNmjTRmjVrGstt6frV2tts165d6u3tbczxqvrw+iwgIEBfffVV49w5YW7O9N50yMxjf9Kb9F5eXjpx4kTjfDlheoT27dunOmr/UfVs377d+H7YunWr5smTR/PmzWs2nUbS74/169frgAED1NnZOdloydQkbsPatWv122+/1eDgYLM8H3zwQapB25TakdSYMWOMYOChQ4e0a9euWqdOHV2yZImRp0WLFurm5qanTp3S8PBwPX/+vDZr1kxr1aqVpu9Jax8vf//9d3355Zc1T548xiC6xO3dvn27NmzYUJs1a5amz35S8+bN09WrVxvH24RR6CNHjjTm+757965WqVJF33nnnTSXn2Dq1Knar18/4/W4ceO0cuXKOnv2bOMX3NHR0friiy/q9OnT011PehCwzWKffPKJFilSRA8cOGD8rC/hw/XPP/9oYGCgBgYGZnj+smHDhqmbm5s6Ozurj4+P9u7dW8PDw/Wvv/7Sl19+WfPnz6+VKlXSsmXLaqVKlYwPXFo+uAkXU4nv3iReP+FBZKVLl07zyJrEP3s9duyYqj6881W0aFGzoG2vXr20cuXK6ujoqFWqVNHq1aun+yRU9eGo2pdeekmLFi1qPHk4IWhbtGhRNZlM+uabb2qfPn2Mu+1pORhl5vuSkCeh34MHD9aOHTua5Tl48KC2bNlSe/fubeS/du1aug6o1tjHrFXPO++8o66urlqsWDEtU6aM1q9fX//991+9deuWvvPOO5o7d24tXbq0enl5mY0WSquRI0dq8eLF1cnJScuVK6eTJ0/W6Oho3bx5szZq1EiLFy+uderU0WeffVYrV66crr5k1vb6559/tHDhwjpy5Eg9d+6cXr9+XU+fPq0tW7ZUNzc37devn/EF99lnn6mDg4PWrFlTCxQoYIyGTCtrfF5U//9OtIeHh/bs2dO4ofHRRx+pu7u7NmjQQIcMGaL+/v5aoUIF4zP2JJ+bpDfrKlSooK6urtqwYUP96quvVPVh0CHhCdudOnXS559/XsuXL2+Un5ZjWWbuY4nz3L17Vzt37qyTJ0820h48eKDbtm0zgvgJli5dmu6pCo4fP67ly5c3e4Dd6dOntWnTptq4cWMjQLtr1y4dMmRIuurJjG2WdP+qXr26Ojs7a0BAgAYFBRm/DNm+fbu+/PLLxkNu0vpTe2v0JWmfvvvuO82VK5cuXrxYp0+froGBgWb5li1bpq1atdImTZrowIEDjZHDj5P0vVu8eLGWKVNGr1y5Yvb9NmzYMK1QoYKxDe/du5eh0ZUjR45UDw8PnTBhgn755ZdqMpm0b9++GhUVpf/++6+2b9/eGDHYpUuXJ74Q+fvvvzV//vw6depUo+2q5kHbxCNtE9ri5+dnjF5KC2t9j82dO1e/++47zZs3r3bu3NkYPZ+wPR48eKAPHjwwzpES0tLiwYMH+tprrxlzFyaW9D2+ceOGvv322/ryyy9rTEzMY/eBpO/b2rVrtVy5choeHm627Msvv9Q8efIY++/t27eTnWc9CWucw4wYMUJNJpN6eHgYgycS1r9y5Yp+8MEHWrduXW3Xrp0OHz48TUH0hL4m/Dtq1CizaT1UHx6nX331VW3Xrp0xP3dMTEy6j/vWOFdSfRhQKV26tNkv+Pbu3av+/v7aqVMnjYiI0AcPHui6deu0d+/e6erP7du3tWXLljpz5kwj7e7du7py5Up1cXExS581a5ZNnY8nXp7w/7t372rfvn01f/78yUaiqj6cr3zChAnpvlGT3a8tkh4bfvrpJyM4lzjPZ599phUqVDB+GZRYWvtirWP/9OnTtUiRIvr7778bN+sS+nvw4EEtX768vvTSS8YDxp/EoEGDtFu3bhobG6txcXG6e/dudXR0VJPJpMOGDTO7CZ/0sxEREaGjR4/Wjh07mp0HpCRp0Ll48eLq5+dnPOjzyJEjRp4PPvhAc+fObXx3P6mff/5Zu3XrZrZ99+/fbwRtv/nmG1V9+PP7mjVrqpubm3p6emqtWrXUz88v3UHOzDhepvYdl3CDsHDhwsYo24T2xsbGamhoqNlo+/SoWrWqli9fXjds2GBsk+DgYLW3t9datWppjx49tE2bNhnal1XVON9L/GuHN954QytVqqQNGzbUIUOGGNstMx48+SgEbLNQXFycduvWzfgpXUoX/ceOHdMaNWoYT75OS9kJ1qxZYzzc69y5czpz5kxt1KiRNm/eXK9cuaLR0dG6fft2fe+99/SLL74wdsLHHSCSfrAXLVqkNWrU0MjISGPdpHnWrl2r77zzTpoOPmvWrNEhQ4ZoVFSUvvnmm5ovXz69d++eXrt2TT/55BMtVKiQjhw50sh/+PBhXb9+vW7evNnsguFxkrY1YRtGRkZqly5dtFChQkbQNjIyUoODg7VMmTLGSDhVNbsgSYk13pekfUmY+2f06NHaoEGDZPP8zpkzRwsUKJDsya2Pq8dafbH2vrxp0yatXLmy7ty5U69du6Y//vijtm7dWn19ffXEiROq+nAfmz9/vn777bfputBRfThxfYkSJYz5mN555x2tVauWDhgwQO/evasnTpzQFStW6KBBg3Tq1KlP3BdrbK/79+9rr169tHfv3smW3b17V7t3727202jVhz+bK1y4cJrmec6KfWzOnDlatGhRDQ4O1qlTp2qXLl20ePHiumzZMlV9+HCrtm3baseOHbVHjx5puiGUOM/SpUu1WLFi+uOPP+qCBQv0nXfeUXt7e+Ni7cyZMzpgwAB944039K233kr2QKInqSOz9rGUxMbGas2aNZNNFxMXF6dvvvmmtm7dOtlopCf5XCbNc/r0aS1ZsqQxX1bC9j979qwWLFjQmP8rLfVYc5tNnTpV3dzc9JdfftGIiAht3ry5lixZ0uwmxsWLF/Xnn3/WV199NUM/h8yMvkyePNnsZ8179+7V3LlzGzcblixZovXq1VPVh8fEhGNrwvuUnpPchJFIy5YtUy8vL2Pu9YQyr1+/rnny5NG1a9earZeeYO2BAwe0fPnyun37dlV9eCM6b968OnfuXLN8Fy9eNPs53uP6deTIES1cuLC6urqa/XQwYVunNNJ2+vTpKf4ENDXW+B571PFn7969RtA28ZycSR+W9yTvy59//mncqJ82bZoeO3ZMr127pqNGjVJ7e3vjl2eplfXtt9+qj49Psp8yJpV4/snff/9d7927p7/88ovmzp3bmNYrYXTU9evX1dPTM9lNlLQEbDLzeywhX3x8vO7evVt//PFHbdu2rXp6ehp9Sfz+Jm33k9SReP2Eh81NmTJFq1atmmy+1a+//loLFy6c7GZDWr+TM+uYnNKD2Y4cOaIlSpQwBp4ktGPPnj2aJ08e41cciduX1mN0VFSUli5dOtlIsDt37uirr76qvXr1StYuWzjvS/rZT/wT4gcPHminTp20SJEijwzO2co5v7XqSXx8SQhm79q1S8uUKWNsp4TPYXR0tObPn994hkFaWOsaJrHbt29rq1atjJGnKcUwfv/9d3Vycko2d+qj3Lt3z/huT2iv6v8/aHLQoEGPfBDXjz/+qJ6enk88lciHH36oxYsXN87BFi9erCaTSRs1aqSHDx82tu348eO1Tp06aTqvuH//vrFdVqxYYcQIEoK2L774onFtofrwl0rffvutbtiwIU3xi8w+XiYu/8CBAxoaGmr2S6dDhw5pmzZttHjx4smCtimV8aR9SRAfH6+NGzfWihUr6vr16439Y+nSperg4KDPP/+8btq0yex86nH27dtntPXtt9/WVatWaWxsrC5ZskTz5MmjQ4YMMfIuXLhQ+/Xrp61atdJBgwZl6FopvQjYWlHSnTAiIkJ9fHzMgo2J71gm3GU7ffp0uueVCg4O1qCgIOMpxAlWrVqlfn5+OmXKlBTXS2uwVvXhSbWrq6vxOnGAYcuWLckmoH7SHf3LL7/UIkWK6PPPP69FixY1m1Lhxo0bOnPmTC1cuHCqk1mn9QP1+eef65kzZ1T1//uZELQtXLiw8fOOW7duaXBwsLq7u5sNoX8SmfW+qJo/fXvYsGHapUsXVX14AZM/f35dtWqV2f60efNmrVGjRrqfRJmZfbF2Pd98840OHDgw2fu5b98+bdKkib722mspBuXT2pfvvvtOP/74Y2OagAQzZ87UZ5991izQmVhaTqgyc3vduXNHq1SpYrQ/4XOS+ASjXLly2qJFC7P10vvkXmvtYwcPHtQ33njD7IT55MmTOmLECC1dunSqD0pI64nutm3btE+fPvrJJ58YaREREfrJJ59ovnz5Un2oZFrqycx9bP/+/cYThfv162f8NHDq1Klat27dZBds77//vr744ouPvaGVVOJpdb777jv9+++/9dKlS1qsWDGjX7GxsUabGzRokKGHM2XmNouPj9fr169rgwYNjPnLtmzZovnz5zeCnffu3UuxrPQEOS3dl4TPeMOGDc2+g0NDQ43gpurDz6Snp6dGR0cb6+zevdsYFfMkFzsrV67Uvn37qqrqkCFDtHbt2nrnzh29c+eOenp6art27czKOX78uFasWNEiTwdev369VqlSRVUfXvgVKFDACNbeunUrxRHPj+vToUOHNF++fNqmTRtt3bq1Nm/e3OznsElH2j777LNaoEABdXR0TNevETLreyzxecOiRYt00qRJOnjw4P9j76vjotq+tz9HQUVJaRBRQAGRTuluBETEVhALsZAwULHba4MFdjeY2N0d2NduEASRfN4/eM++58wMMGeA0e/93ecfZebM2b322muv9Sw8f/6ceDdfuXIFzZs3R1hYGA4cOICgoCBWFIIwuHXrFoyMjDB79mwMGzYMFEWRyKq8vDzExsZCUlKSJAIT1P9z586FtrZ2jRnDjx8/TozjI0eOhIWFBfLy8lBeXg5/f39YWlqSywGgykjfrl07vmQ6wqKh9rGa+vbq1avw9/dH69atWcaPjIwMFo+4MOty3759JLJhxIgR8PHxQWVlJfbu3QttbW2kp6cTIy5Qte5NTU0FegwKi4aUyUy6mf379+P169d49OgRZGVliRGlpKSE9K+ZmRnmzZvHqf63b98mc2jkyJHIzs4GUKWb+/j4sGhxgCrPSC8vrz/uzMesz+LFixEREQEHBwekpaWRtV9RUYGwsDBCj1FX/K+fLfbu3YvAwEAAVfuYrq4uvn37hvLycpibm8PBwYG1Bt+9ewcTExMcPXqUU/2ZaMgzDO+c/PLlC1RUVASuiaKiInKB8/DhQ04XTsy2aGtrY9euXcTwvWfPHpIgi9YPw8PDsWfPHvK7+fPno1WrVgINtuPGjWPlaPn06ROGDh1K5Mju3bshLy+PuXPnonXr1nBzc8PNmzf5Ina4cuPSnvuhoaGkLUyjLe1pW1N/CIOGkJe80WEGBgbQ1taGnp4ey+P41q1bCAkJgZaWFifKu+rA60RWWVkJV1dXGBgY4PDhw8Qou3nzZjRq1AiTJk0CIFyfvXz5Eh07dsSAAQPQv39/NGrUiFyMl5WVYePGjXxGW/o7Qf8XB/4z2P4GbN++ndw4DxkyBD4+PuT2m8aNGzfQu3dvljAXZQNv3749KIpCcHAwn4AZNGgQTE1NRVYMgCoPEHrBPnjwAO3atcOIESNYCyY/Px9eXl5YtWqVyOWEhISAoij07duXbxHn5uZi8eLFUFJSwvDhw0UuA6g6kJmamkJDQ4N4iND99uHDBxgZGUFHR4ccUH/8+IENGzZAUlKSEwF1Q41LWVkZ/P39ISMjg+7du/N558TExKBFixbIyMjA3bt38eHDB3h5ecHT01Nknt+GnmPiLMfT0xMURcHOzo7PG3Dq1Klo164d60AiCvLz86GmpgaKoljZZ2kEBQXB1dW1TmUADdtfnz59gq6uLlHUmLeZdL/Nnz8fenp6+PjxY52zaIpj7M+ePQspKSlIS0sTAxqNnJwc2NraEu9XZllc23bjxg3o6upCVlaWL7zq27dv6Ny5M0aNGiXQu1RYNNQcq6ysxJs3b6CkpITBgwcjMjISTZs2JXykt27dgoWFBXr06EEOHXl5efDw8OCcCODKlSto2rQpLl++jKSkJKiqqpKD/5IlSyAhIcFK3FBSUgITExOhuct4IY51WVhYCDs7O7x58waZmZmsjMDFxcXIyMioF0W3vtsiaG2dPHmSRJzQz9CXsxoaGsT7KikpCZqamnz7dk1l0RmYra2tISsry0pWevnyZaiqqsLT0xN79uzB8ePH4e/vDxsbmzp5I9Pr+N69e3BycsK8efMgIyPD8qw9e/YsgoKCiPFQGOTk5ICiKHKRsH//fnh7e8PPz4/lqcw02u7atQteXl58xhxh0dD7WFJSElRUVBAREQEzMzMYGRlh06ZNxJv12rVr0NPTg4WFBezt7TklgKExduxYqKqqonnz5sT4Q/dRXl4ehg0bhiZNmrCoUWjk5uZiwIABNfIkV1RUYOPGjbCzs4O+vj4UFBRYB/kTJ07Ay8sLenp62LVrF3bs2EGMuKLK5YbYx5jPr169GlFRUYiOjmbRqF2/fh3+/v5QVVXFzp074enpCWtra85l+fn5QVpaGqGhoazwV6AqSZaqqioWLlyI69ev49WrV/D29hYpkQ2NhpTJZ8+ehaKiIj59+oSEhAS0adOGGIASExPRvHlzlnz78eMHOnTowEoKVBMqKyvx5MkTtGzZEhMnTsSgQYNYRoFjx47ByMgIMTExhCs5Pz8fbm5uGDp0qEhtAhpeVxo7dizU1dWRkJCAOXPmgKIoTJgwgfAkV1RUoFu3bqAoSujIgN/VloYu5/r165CWloaRkRFkZWVZ6+XTp09o27YtrKyssHDhQuzcuRM+Pj4wMzOrk9eeOM4wx44dQ15eHgoLCxEUFIRBgwbxGUdPnz6Nvn37si5FuF48FRYWwsXFBXZ2dti1axfRKfbs2YMmTZrAx8cHFhYWaNeuHdljCgoKMGzYMIGy/9ChQxgwYADL0Pbr1y9kZWXh69evuHnzJnR1dbF48WIAQHp6OiiKgqmpKcvhjKuxtrKyEiUlJVizZg1sbW3RtWtXltG2R48ecHFxqVNeB6DhddipU6dCWVkZp0+fxocPHxAbG0vWP43bt2/DycmJjyKHK1JTU6GjoyMwItPW1hYGBgY4dOgQmRMbNmxAs2bNEBcXJ/T62b17N9TU1NCkSRPCE86MmNq4cSOaNWvGStD5O/GfwVaMqKysxKVLl6CgoEBu/bdv3462bdsiISGB8GJ9/vwZnTt3hru7u8ibEVOgeHl5QU5ODkeOHGEJ8A0bNsDS0pIvqYmw+PXrF7y8vDBlyhQAVcJ18uTJsLW1Re/evZGTk4Njx44hICAA5ubmIt1G0Atv8uTJmDp1Klq1aoW4uDiiWNPtzM3NJcT2XJRDQc8+f/4crq6uaN26NSusr7S0FKGhoWjZsiWrnIKCAmzZsoXP6F5beQ01LgCgpqaGZs2akVs7pgCLi4uDpqYmWrZsiY4dO8LS0lIknl9xtUUc5TDLiIyMhJKSElJTU1mKzeHDh2FoaChSdnte/P333+jUqRP09PTw6NEj1ndz5syBm5sbX8ZKYSGucbGysoKdnR35m3eTnDp1KkxNTevEJySuttBYsGABpKSkEB4ezjfO/v7+6NWrV53LAKq803R0dGBlZcVnlImMjERAQECdy2jIOXbq1CkoKCigSZMmxLOB6U3p4OAAAwMD6OrqwsLCgsUrJax8fvbsGYYMGQIZGRnIy8uTS07aUzUpKQkURSEqKoqVOKcut9712WeCZCmdFMHHxwfy8vIsY+CzZ8/g4eFRbZJRrqivttDtePnyJdLS0kj0hrW1NZSVlVmJ8Oh2qKqq4tOnT5gwYQKaN28ukuert7c3KIoiESLAP3Pn0aNHsLGxga6uLtq3bw8vLy/OXG/MOm/fvh3nz59HYWEh3r59C3d3dzRp0gTJycnkmeLiYgQEBCAiIoKTjnHu3Dm+g1htRtuSkhKS04ALxLGPrVixAlpaWuRAfPLkSVAUhQ4dOmDdunWkrI8fP7KSMQq7Lunx27ZtG1RVVWFgYIDZs2fzecrm5eVh+PDhoCiK5a1Mo6ZkUMx+6tGjByiKgrOzM9/cuXLlCvr27YuWLVvC1NQUfn5+InEKimMfS0xMhKamJqKiojBixAhISEiwIjju37+PXr16QVdXl5UAhitXuY6ODiQkJLBs2TK+5xISEmBubo6mTZvC2NgY1tbWdcohATTcPnb79m0EBwdDUVGRLzHbu3fv0K9fPzRq1Ajjx4/H9OnT4e3tzeItFRYZGRmQl5dH06ZNSUg83Z+7du2ChYUFDA0NYWNjA2tra3Ts2FGkCw5xzLEdO3ZAR0cHV69eBVBFVUNRFBo1aoTBgweTPiwvL8eECRNENjz+m84WXbp0AUVR8PT05ON+zsvLQ0hICMzMzGBsbIzOnTuLzFkqrjPMkSNHoKioSNbcsmXLICUlhb/++otE0eTl5SE4OBh+fn4irft9+/aRfbGoqAgeHh6wsrJiGW2PHTuGkSNHIj4+nqxJuu9qOnPQ3+3cuZPo3vTvlyxZAk9PT7LX0GHwXbt25TQezDYvW7YMy5cvx5cvX4jR1srKimW0vXbtGry9vet0UUOjoeTlvXv34O3tTRwxsrKyIC8vj969e0NCQoIV2cY1CbMgFBQUoE2bNrCxsSFGW3qOnzt3Do0bN4a2tjZLf6KjsekkZNWBrtv58+fRoUMHGBoaYtCgQXzG4bKyMmzatAkURQnc78SN/wy2DQx6YtATrbCwkMW/B1RlvzMzM0O7du1gZWUFMzMzmJiY1FnRYSoWNjY20NHRwY4dO0hGchcXF/j5+QmtFAiqR3x8PHx9fYkAyM/Px4oVK2BhYYFmzZqhQ4cOnA9TNbU3LS0NGhoaiIuLYxG204JX1HCFvLw8FpH527dv4eDgwOLLq6ioQM+ePXH9+nW+ceWiWNX3uPC2pbi4GJaWlrC3t4eqqirxEmC+78aNGzh69CgOHz7MiSdHHG35XeUw52bXrl1haGiIWbNm4cWLF3j+/Dk8PDzg6upa57bQePXqFQwMDGBtbY1r166RG2sHBwd07dq1Tu+u7/56/fo11qxZg1WrVpFkHNu2bYOkpCRf6BU9FwcOHIioqCiRsyg3VFsEgTn2c+bMgbq6OiZOnEgU24KCAlhZWbHoa0QBb0ixiYkJ+vfvTzwvCgoKYG9vL/B2XBTU5xzjzaSspaUFVVVVxMTEsDxHgKpLr5MnTyIlJQUZGRmcONKY4zhv3jxQFAVZWVm+EMvi4mLs2LEDnp6eCAwMRHR0dJ2y0NKojz5j9tXTp0+Rm5tL6ECOHj0KVVVVkjiprKwMP378gL+/P9zc3OqVE6uubaHbcffuXbRv3x6hoaEkAR8AODg4QFdXF+fPnyfPvnnzBq1bt4afnx+aNm0qdEg/s89KSkqwatUqzJ49Gy1atGDJGOYYv3//Hk+fPuVsFGTOMTrBWEZGBjmUHzlyBNra2ggNDcWSJUuwadMmeHh4sAw2tellRUVFyM3NJRnHeelgajPaior63seY7yspKcHMmTOxYsUKAP+Ej65cuRKdO3eGuro61q1bx8cby5XfG6iau+/evUNSUhIsLCyQkpLCx5FaUFCA+fPni5xF+/v371i7di0WLlwIJycn+Pv7kznA7J+PHz/i27dvQvMVC0JD7mPr1q1D27ZtyWXK7t27QVEUy7ObxuvXrzm1g1e3dHNzg7OzM5SVlZGZmclnHHn69ClOnjyJs2fP1jnRDI363MeY/Tt+/HhQFAVVVVWy19Pf5+fnY+HChbC2toaLiwt69eol9P7C7LMTJ05ASUkJysrKmDRpEl/C5Zs3b2L79u0YNWoUFi9eLDKfKO9v6nuOlZeXY/v27WTtZ2VlQU5ODlu3bsW+fftIxnaaTk5Qnf6UtjRkObxyLCsrCxs2bICysjJCQ0OJbGQa5YuLi/H27ds6yRegYc4wvM++ffsWmpqaLFqkadOmQU1NDU5OTvDy8oKNjQ3rkp7Lnnb//n0YGRkhPDyc6A7VGW2ZsqemPouNjcXkyZPJ37du3YKZmRk6d+5MqL0qKiowfPhwGBsb49OnTygoKEBgYCBWrlxJfsdVN0tISICKigpWrlxJHA5+/fpFjLbh4eHEaPvo0aN68RYHGuZs+f37d/z1118oLCzE6dOnoaGhgdTUVJSVlSEiIgIURfFFONeFsxao2t91dXVhaWnJMqZmZ2dj5MiRiImJ4Rv3mmj3eOdyaWkpSktLsX37dlhYWKB///58ntmVlZU4fPiw2OkPBOE/g62YwBQs2trafB4XFy5cwObNm5GYmIjVq1fXadNmgvl7Ozs7UBSF9u3bo1u3bnBxcSHGFC4C/MSJE3j58iVKSkowZcoUODo6Cizz2rVr+PvvvzkpbbzE2fPmzcOCBQtY3qsrV66ElpYWYmNjkZ2dDV9fX7Rp04Z8z9VjICUlBY6OjpCTk0OPHj2Qnp4OoIqvzNXVFQoKCujXrx+srKxgYWEhUqZ2XtTnuDDrsXv3bpbACQ4OhoqKCiu0CwDfDVRdjAQNMcd+VznMfujWrRskJSWhrq6OsLAwdO7cmSgK9bmxGhoaQlZWFpaWloiIiIClpWW9tKW++uvOnTvQ1taGjY0NFBUVoauri/379+Pnz5+IiYlB06ZN0bdvX7x9+xaFhYX48OEDJk6cCDk5OaGzwYurLTWBOabTp0+HkpISLCwsMHDgQISEhMDExKTOxmfectasWQNDQ0Ooq6ujc+fO6NKlC8zMzOptzQD1M8eYdT579iz5zdGjR6GlpYXo6GhW2LogcL2s+/DhA27fvo1Lly5h6NChkJeXJ7f7Nb2rPhSr+lqXEyZMgL6+PrS1tTFs2DASIrpw4UI0atQI7u7uCAgIgLOzM+uStr6NtnVpy6NHjwhHPJNTmIa9vT3atGmDc+fOobS0FF+/fkXbtm2hqKhYY0g6E8xxX7lyJRYtWkQuUHfs2IHmzZvzeZ8wL7153yEsZs+eDRUVFVy9epXP8HTy5En07NkTSkpKcHd3Zxlsaptjjx8/Rp8+fWBgYICmTZtCXl4ePXr0IJ5pNGijbVBQUL1wPtJoiH1s2bJlePv2LW7fvk28Zw0NDYkX5507d9C0aVO0atWKcMsKC2Y9Lly4gJs3b+LJkyfks9GjR8PCwgLTp09HXl4eAGDo0KEsTlau+uWiRYuwfPlyYmDauHEj7O3tERAQwDI4nzx5knUI/BP0Pt46LFiwgITx0oa0pUuXYv78+aAoSiBNjChJMpme8sHBwVBSUkJWVhZr7fB6ItaXLKvvfezr16+4dOkSjhw5gi5dukBTU5PoK7w8hcx3c0nKxzQyrFmzBhoaGkhKSqqV0/dP0McFOaO8ffsWr169wsePH2FlZUUosd68eUNCsXm5M+uC/7WzBS/Pb1JSEonSvHLlChQVFREaGsryemUmnOJ9hyioT9nPbC/9/I8fP9CyZUvs27eP9ez+/fsxd+5cREdHsy7Ralsvgvp048aNcHFxQY8ePQhdSFFRETw9PWFra4tNmzYJred9/vwZgwcPhoGBASviID09HR4eHujSpQtZ948fP4asrCy0tbWhq6vLMjpzxfbt26GhocGiuKLb+uvXL6xduxY2NjZwd3dnnSv+hLNldXWguapjY2MRFRVFjM2JiYnw8PAQKSqc+fz+/fuxcOFCbNy4kVxi00ZbGxsbbN26FY8ePUJQUBDhqwW47/1v3rzBo0ePWP2+bt06WFpaIjo6msjtoKAgli7zu422/xlsxYAlS5ZAR0cHffv2xdixY+Hl5YURI0awkhkIQn0pOsxJ5uXlhWbNmrGULC4C6ezZs2jWrBm0tbWhoaEBNzc3SEhIYMKECThz5gwePHhAFjUTXBdxYmIiVFRUEBwcjDZt2sDb25tFlr127VoYGxvD0NAQjo6OIgvVlJQUtGzZkngPhoaGwtzcHLNnzwZQNQaJiYno2bMnBg4cWGevZybqY1yYQjchIQF6enqYP38+OeyWlJQgODgY6urqOH36NHJzc9G1a1fiwVdf3qJ1bYuw9ajPuVwdmOuuf//+UFdXx+rVq1FYWAig5lBLUfDq1SvY29tDQUGBFdpZH22pa3/duXMHzZs3x9ixY1FUVITs7GxoaGiQZGIvX77E+PHjIS0tDTk5OSgrK8PR0RF6enoCuYd+Z1to1LR2md8tWLAAjRs3hpeXF+EZ5VKOsHXYtGkT2rRpAycnp3ovh0Zd5hhzbY4bNw6tW7fGggULyDo5cOAAtLS0MGTIEBLp4O7uju3bt3OqI7NPpk6diujoaOLN/fjxYwwYMADy8vIsQ93ixYtZlwL1Jc8A0fqMWf7evXuhrq6O/fv3Izk5GV5eXnBzcyNG28uXLyM6OhqjR4/GwoULRfZCbqi2AFUedeHh4Rg2bBjr89LSUrx48YJc/Pn6+qJ169bk3Tt27GAZ3IRFfHw8lJWVkZ6eTvSj8vJy7Ny5E9LS0oiKisKTJ0/g5+eHwMDAOo33r1+/EBwcjFmzZgGo6qPDhw+jc+fOGDt2LDEGfvv2jSXzaxufO3fuQF1dHUOGDMG6devw6NEjJCUlQU9PDwYGBnyJCzMzM2Fra8vytqkP1HUfY67H1NRUUBTFupTZv38/zMzMCD3ViRMnMGjQIIwfP15k3TU+Ph5qampQUVGBvb09SWYIVFE5WVpaErowRUVFkQ9QCQkJUFZWxqpVq8glRHl5OTZv3gxHR0d4eHjgzp078Pb25kyzVRvqU4eZOnUqDh8+jNzcXDx79gxv376FkZERFixYAKCKH1FKSgoURdUph0RCQgJ0dHQwZcoUFnVASEgIVFVVsWfPHnz48AGBgYGEwqQ++4xGXfYx5nyeOXMm4uLiiAH65s2bCAoKgqamJoufeu3atSyPUWGNnEDVZV3btm1ZfPgrVqyAhoYGJkyYQNaNv78/X5LOuqKuc4zZV+/evcP79+9ZsunBgwcwNDQkl0xv3rxBUlISTp48We9GDXHo/PVdDu1ZmZGRwTLOX7t2DcrKyggICMDJkyfh5+cHW1vbejPS0ajvM8zChQthb2+PcePGYebMmfDy8sJff/1VY0JH3nrUBt6ojE2bNsHR0RE9evQgRs+ioiKYmppiwIABnOr/6tUrJCYmomPHjqwLhXXr1sHV1RVdunQhUWIvXrzArFmzsHz5cqF1MiaXKo1Zs2bBx8cHJSUlpB94L36WLl2KqKioeh9/GqLIS2ZdsrKysHz5cqxatYroc8XFxXB0dESfPn0AVCWgDg0NZen7osj++Ph4qKurw8rKCkZGRlBSUiKys6CgAC4uLtDS0oK6ujqLakcYMNs0ceJEWFlZoVmzZujevTvLeXL9+vWwtbWFlZUVLC0t0apVq3o9h9UV/xlsGxD0pN2wYQPmz5+PuLg4ODg4QE9PDxRFQUdHBx4eHujWrRvi4+NZpNb1DabAsbCwQPv27XH58mXOhrSCggJ8+fIFz549w7Zt27B8+XJQFIXWrVtDT08PTZs2RevWrfmybXLBkiVL0Lp1a3KztmHDBlAUBUdHR1b29pycHNy7d4+TBy+zPR8+fICVlRVL0Lx+/RrJycmwsLDAsWPHyOfMBS+sQiKMEBZ1XHixdOlSKCsr49KlS3z1KykpQVhYGCQkJGBsbAwDAwOh31/bhsxEXdrCha9P1HLevHkj8DJBEJiKRnBwMDp27IgtW7YIVc8rV66QMBth8erVK7Rr1w729vYsao7aIMzGKGp/vX79GkpKSggPD2d9bm1tjXbt2rE8ad68eYMVK1Zg+vTpyMrKYh3qhEVDr5faPEAF1WP27NnQ0dHB9OnT64Ujt7py1q5dC1tbWwwePJiV+IbLO2qDqHOMxvTp06GoqIhLly7xJZA6cOAAdHV14eTkBHNzc+jo6Iis6IwdOxZKSkrYsWMHCSMDqkJto6Oj0bx5c8yfPx+enp7o2LFjnRJN1QZR+ywrKwtxcXEsjtrMzEz4+/vD1dWVeFryrl9h2yIoy3NtEKUtZWVlcHJywtKlS8lnR44cwahRoyArK4tWrVqREDtfX19IS0uTfZsrtm3bBk1NTYF8t2VlZcRzUF9fn8W7LsrhoKKiAgUFBbCzs0NUVBTS09OJIdDDwwP29vbEg4T5fmGiEZo3b45x48bx7cPbt2+Hubk5bGxs+HS9Q4cOicwrWFOd6rKP0Thx4gRWrFhBuJXp8tLT0wm916tXrxAUFIT4+HiBZQtT9+vXr6Ndu3a4fPky9u/fjxEjRqBVq1asS6wFCxZg0KBB6Nu3L+lfrut/9+7d1Xo+lZeXY/fu3bC3t4e6unqdnAFqgqj7GO9Fn4aGBusC4OzZszAyMiJG6AcPHmDgwIE4dOiQyIa05cuXQ0lJCVevXhVIn9W1a1coKytDX1+fFSUgDHipxYRBXfexxMREKCkpYcuWLSw95fbt2+jcuTOUlJSwdetWeHp6wsrKSiRjSkpKCpSUlHD27Fk+XSg1NRXa2trEWKepqflHzTHmWEydOhWWlpYwNDQkSX6Ki4tx//59SEpKYvr06Thx4gT8/f3h4eEhsOzf2RZAfGcYGpmZmdDS0uLj1ab79f79+2jVqhWMjY3RqVOnOu1jNaE+ZD9dpxkzZiApKQndunWDiYkJZGVlISEhAQsLC3Tv3h2jRo3CokWLRNL7gSrv8wEDBvDRhWzcuBH6+vqIiIggzgDFxcVCr0nmeB46dIhw+9K0HsA/RtuwsDBitGWORW37y19//QUrKyu+8evbty+sra353lNeXo4zZ84gLy+P5b0vav6Y2iCqvKQv6ZycnBAUFARJSUkyp1etWoXGjRsjNDQUlpaWMDU1JX0tyjzetWsXlJSUcPHiRVRUVOD58+dITk5G48aNic3n169fuHr1Ks6ePSsyjePkyZOhoqKCffv24fbt2/Dw8ECHDh3IBScAHDx4EHPnzkViYmK9RbrXF/4z2NYzajPslZaWYtq0aTA1NcWZM2cwf/58dOnSBT179hQ5iYGwYNbH1tYWLVu2rDEZCLMtOTk5eP78OZ/XzLt372BmZoZz587h169fuHjxIg4cOMBpgjPbXVhYiHHjxmHJkiUA/uFImzZtGuzt7dGhQweSSKu6ugrTno8fPyIvLw9t2rRhCW+gigqhQ4cOfBnchcGLFy/w9OlTvsNXTePFdVx431taWopu3bqREIHqNoBNmzaxQklqG6P169fDzc0N9+/fF2mDFLYtqampcHR05GSE4FpORkYG7OzscOHCBaEJ13n5oNTV1bFjx44af7Nu3TpQFEVuBrkahwwNDaGvr88yVAl67vHjx3xcYTVBlHF5+fIlrK2t0blzZ3IonDlzJiiKgo2NDQIDA9G/f38sWbIEX79+FcmrSlzrZdu2bVBRUeFL+lEdmOM2bdo0tG3bFuPGjcPHjx9r/B0NUfjOVq9eDWtra/Ts2bPGLPQvXrzAs2fP+MLThSlT2DnGi7y8PHh4ePBR+TDH4uTJk5gxYwYmTJggsqJz8eJF6OrqssLDme168+YNxo4di44dOyI0NFToiIcPHz7gw4cPnA5vNLj22a1bt2BpaQkFBQUsX76c9V1WVhYCAgLg7u7OMrRw2c/Xrl2LXr16iZQ4gmtb8vPzYWBggIEDByInJwczZ86Evr4+wsLCsHjxYqxduxba2tqYNm0aAMDDw0Pki+fk5GT4+fmx5AjvuH769IkzN2ZFRUW182P37t3Q09ODqqoqJk+eTMYkPj6eM9eboAuuyspKVh1XrVoFWVlZ4u3IdX2cPHkSM2fOxLx584j3eW0QZR+jcf36dUhISEBSUpL8hkkJZW9vD2VlZbRq1Qrm5uYiG57Wrl1LvHNpPH/+HPHx8dDU1GRdfIhyec7EwoUL4erqiuLiYoGeT0DVBfKNGzeEnmcXL17EqlWrsGnTJr5EL9WhLnrf2bNnMWTIEFa/AFWXxRRFYc2aNXjx4gX8/f0RFhYmEjdmZWUlysvL0a9fP4wbNw7AP33Pu5527dqFXbt2cTpIZ2VlIT09nRiQuBohRNnHTp48iTZt2rA4o5nl5uTkoG/fvtDT02MlmONSt48fP8Le3p4VEQiw+2Tr1q1ITEzEiBEjhN4rxT3HUlJSoKysjL179+LDhw/o1KkTtLW1yYVyamoqJCQk0K5dO9jZ2YmcxE5YiNIWcZ1hmFiwYAE6derE2p95119hYSGrTsKsF1EuaUWR/TX1U1lZGYqLizFo0CAYGhpi3759GDZsGBwdHREcHMw54SfdL5MnT4axsTHi4uL46EISExMhLy8PX19fliMMl/NGYmIiXF1d4efnB0VFRWhoaGD+/Pnk+/Xr1xN+39roSgSBHr87d+4QL+bDhw9DRUWFz77w8eNHBAUFsXIBCLMeHj9+jKtXr4pEM8dVXm7cuBGqqqrEsSAjIwMURWHLli0Aqryh16xZg65du2LEiBF1SvgKVOWqcHV1ZX2Wl5eH0aNHw9LSkpX8nQbXC+HLly+jY8eORG86c+YMmjVrBmdnZ3Ts2JHYnEQpR1z4z2Bbj2BOwrS0NERHR6NHjx6YM2cOa+JcvHgR6urqAg+PwkyO7du3c060APxj3KPRuXPnasMWmfWdNGkSzMzM0L59e2hpaWHJkiWssl1cXPgSGwDcJ/qWLVvw4sUL3Lt3D58+fcKjR4/Qvn17wjuTnZ0NaWlpmJiYICsri9O7mYiLi8OAAQOQk5MDR0dHxMbG4ufPn6w2R0REoG/fvpzeu3btWujp6cHU1BSysrIYMmQIzpw5Q76vTihzGRdBKC8vh729Pcu7hQZtRBf0m5qwfv16NG/eHEuXLsWXL18E1lkQuLYlLS0NjRs35suMLkzombDlbNy4EVJSUkhLS2NxR9GoTkHhPWwPHz68RmNEWloaJCUlYWFhgQ4dOtSaqZJZPt3eFy9ewMXFhe+mmdkWY2NjtGnTBlJSUmSTqc/+YuLJkyfw9fVF586dER0dDWVlZezcuROvXr3C3r17MX36dKiqqkJTUxMBAQGorKwUWhkX13qhw3kpikJiYqJQdQPYYUPTpk2Dvr6+wLVA48SJE9i9ezfnm2ZmOcuXL4ezs3O1ShVtINPR0UHTpk0xZswY1vqurkwuc0wQ3r59CxkZGVaEA42ioiKBhlNRjCnHjh1DmzZtBHoblpeXE7mVm5srtBFi8+bNsLOzg46ODtTU1IiiXNsBri59tm7dOpiYmMDGxoZvbh48eBC2traIjY0V6l1MpKWlgaIo7N+/n/W5MBcQorblxIkTkJCQgLa2NmRkZJCWlkbkYGlpKby9vdGjRw/ObaFBj2l0dDS8vb356lteXo5Dhw7xUUhx9cgHqi5Fxo4di9jYWOJh+e3bNz7PIF9fX75kirWBecHFy0fLHB9nZ2eEhYVxejdQ5YWkpKQEX19ftG/fHn5+fkJd2nHdx5j4+vUrid4ZOHAg+Zw2RlRWVuLAgQPIysriZKxj8mO+ffsWXbt2hZycHKKjo1nP0Ubb1q1bs/gHme8QFvR8iYmJQYcOHcjnTM+n06dP88me2nSlNWvWQEVFBQ4ODlBQUEBkZKRQXmyi7slXrlyBjo4O5OTkWJmrKyoqUFZWhuTkZFAUBV1dXZYRXRQjWWVlJVxdXVkhyPR7iouLWYZPGsLo/Q8ePABFUbCwsMCGDRuEjnyq6z62a9cu6Ovr4+PHj3wcrbwXg6IYuYEqnUlKSkogjzOznbw8uTVB3HPs27dvcHZ2Jnp5ZmYm5OXlibc7vZZycnKQk5PDyfAojvMrIL4zDA163k+bNg1WVlZ8F6oVFRXYtWsXKx8L/XltoJPSCTJc1QSusp9Zl4yMDCQlJWHYsGHYsWMHq7/2798PQ0NDvrJ431FdnWgwqUDmzZsHc3NzjBw5krWmly5dCmdnZ8THx4vk7b5t2zbIysoSZ50HDx5gyJAhaNeuHWtPWbFiBWJjYzmVwTQ8Hz16FBRFISMjAyUlJfj06RMGDBgAGxsbzJ07FwUFBbh9+zaCgoJgZWXFyT6ybt06tGvXDu3btwdFUayIp9rqx0Ve0s9OmjQJo0ePBlB1qS0tLU0umQsKCkiEHbMNwq5n5vinpaXhzp07yMjIgIaGBt/8PnDgABQVFfnWjDBgjuPr16/x+fNnLFu2DL9+/UJ2djaUlJSwdu1a5ObmQl9fH3p6ekhJSeFcjjjxn8G2AUDzr06ZMgWJiYlQV1dneWvcv38f0tLSfNmThVGo9u7dS4wPM2fOFFq4MN+9aNEijB07VqjfTZs2DYqKijh16hQ+ffqEvn37gqIoVkbDnj17olu3bkK9jwlm3WfNmgVJSUk8ffqUbJYbNmyAtbU12Wx3796N0NBQjBs3TuTwgTt37sDAwIAYOXbu3AmKojBnzhzCoVNUVAQbGxsWqXVtyMrKgoKCAjZv3oxXr15hz549UFFRgbGxMXbv3i1U3YQZF0HtLi8vR0hICOzs7Pi4iV68eIGoqCjCmygMXr9+DRMTE6Kcff36FTdu3MCFCxdYXn2885VrW1avXo0mTZoQpfDHjx/4+fMn30WGqOVUVlbi06dPsLOzIxvcx48fcfToUezbt4/Fscrbr8wyZs+ejd69e9fYFjpEZO/evbh69Sp0dHSwZ88eADUfYJjlpKenY/bs2dVufJs3b4a0tDTWr1+Pa9euYeHChWjcuHGtIciirn0ajx8/JpxedJIJJr5+/YqdO3dy8qwT13pZuXIlGjdujJMnT2Lbtm1QVFQUKmSbWc7mzZuRm5tLbs4FYceOHeQAeuDAgWo9t2oqZ+PGjbh165bASwWgynAmLS2NjIwM3LlzB2vXroW5uTl8fX35DHjVlVHbHKuuzrm5uXBycsLYsWNJ/ejnDh06hJEjR4p0AOMtb9u2bZCSkiIKIfPgdPz4cWRnZ9fogcmLjRs3EmVz7969iIuLQ9OmTWudq1z7TFB9NmzYACcnJ0RERPCVR4d+cQGvvKQvGWual4DobWHi9evXuH79Ot/Bt6KiAuHh4UhOTq7Rk5X3N4KwadMmUBRFvOBpfP78GRERESyPFGEQFxcHHR0dcnAePXo05OXl4e3tTTjM5s+fT9r0/ft3HDlyBIGBgTAyMhIpxI++4PLx8anWS9zV1RU9e/bk1JaTJ08SmhCgyjtESUmJzxO/rvuYIOTm5mLJkiVo3rw5kpKSyOeCPLxF9Ua5dOkSevfuDVlZWb5kNi9evMDAgQMRHBzMaSyqm2dnz56FqqoqX3KkL1++wN/fn+zbwuDIkSNo2bIlGZc9e/agefPmfAfPmsZFlD05LS0NrVu3hru7O98cKC8vx927d3H69GlORnRB/VVaWorIyEjY2tri7du3rGdevnyJsLAwFrWEsHj58iUMDAzQqVMnGBgYYP369XwcljXpfVzlGP3bpUuXQlFRkfQLc3/Jzs7mS87LxfhE48OHD7CwsMC8efP4Ejzt3r0bU6dOFarONMQxx3h/++zZM6ipqeHr1684fvw4pKWlyXmgsLAQ06ZN48vGLozsF9f5VRxnmOrqnp2dDYqisHbtWtbn+fn5CAkJwbp162qsOy/2798PCQkJUBSFmJgYocPa6yL7ExISoKqqiri4OISHh0NXVxcjR44k3585cwZSUlJ89F1cItcuX74MFRUVVjj6nDlzYG5ujtjYWNy8eRMlJSXo2rUr0tPTRaIOAKpoPezs7FifPX78mFC5MKMURC2DRkxMDFq0aEG41589e4axY8dCWVkZ8vLyaN++PRwcHDh5pK5fvx7S0tLYuHEj3rx5gxkzZkBWVpbvnCCqvBQ0ZvHx8Rg+fDj27t3LWvuVlZVIT0/H5MmTWZdPokQULlq0iFATXbx4EaamppgyZQprfd67dw8dOnQgdBiiYPTo0ejduzc+ffqEwsJClJeXo2vXrizaqm7dusHY2BgjRowQ6WJTXPjPYFvPuHDhAtq3b09unvfs2QNpaWkW8TwAtGnThi9kpjbQPGHjx4/H8uXL0ahRI0ydOpWTUpGWlgY5OTmhQuKKi4sRGBhIOF737t0LBQUFsnhpZWTy5MkIDQ3lK0tY3L9/HwsWLMCBAwcA/LOo09LS0LFjRxw/fhz5+fno3Lkzpk+fTn7HVajOnj0bMTExGDRoEOu3tFHHz88PYWFhcHFxYR3YhMHQoUMRExMD4J8+iI2NhYKCAuzt7XH48GG+33AdF2adr1+/jmvXruHy5csAqvgdlZWV0a1bN3z9+hWFhYXIzc2Fn58fPD09OfXV48ePYWZmhl+/fuHhw4cwMjKCubk5mjRpAnd3d1YiEFHbcuPGDUhISJDkZ48ePUJgYCA6duwIeXl5JCQk8F1oiFLOhw8fYGxsjC9fvhCPbTrMycjICHPmzKmxjJUrV0JBQUEgDQeNxYsXg6Io1kHT0dERbm5u1f6Gt5zU1FRIS0uTNcCLnJwcdOrUicXnR5czZcoUvvcJKoPL2ufFs2fP4O3tDT8/P5YhQtQQWHGsl9WrV4OiKOzduxdA1ZrR1dUlXknVKUvMclatWgWKomo0Fj148ABWVlZISkqCm5sbbGxssH///lqNtoLKqW78gapLLU9PT9Znp0+fRmBgIDw8PFjJuASVUdscA9gy5vPnz6zwsKlTp0JWVhabNm0i3j0/fvxA586d62RMYf6/vLwcZmZmcHd3Zxkii4qK4O3tzYmm5u7duzAzM0N6ejr5LD8/HyYmJgJlGA2ufcYLZnvS09Ph7OyMiIgIVkZ7Qc/WhLNnz7I8xHNyctCjRw9YWVmhbdu2WLx4sUDvm7q2pSaUlJQgOTkZGhoaQkeEMNt74MABrFy5kpW8JDIyElJSUti+fTtevnyJx48fw8/PD5aWlpyMgRUVFTh48CAsLCzQqVMnvHnzBj179sSNGzdIn0yZMgWKiorEc+T69etwc3ND586dOYf4McE02jJpLyoqKvDmzRv4+fmRQ7uwa2bmzJkk0SMNFxcXTJgwARMmTMCmTZvI54IuQoTZx2pCXl4elixZgpYtW7KMGHVJlrJo0SI4ODiQv69du4a+ffvCyMiI7wLq/fv3AttVHZj12rdvH+bOnYsVK1YQg1xsbCysra2RnJyML1++4OrVqwgMDOQ8zxISEkiSLaBqP/T09MTixYuxbNkyVh4EGnXZk3kTwZmYmCA2NpYlW3j7R5j2MN975coVnDt3joSBv3nzBsrKyggJCcGjR49QVFSET58+EWoXrnOAvmQKDw/H58+f0a9fPxgYGGDPnj3Iz88X2Bd12ceY+Pr1K7S1tdG9e3fW5z9+/ICvr6/Qnmu8ZRQUFLAMaYMHD4ampiYOHjxI+r+4uBhBQUEIDw/ntFeKc44dOnSI/D8oKAhhYWFo0aIFiwrp77//hr29PaeLDUC859eGPsMw67x161bMmTMHcXFx5PIkJSUFkpKSmD9/Pi5fvowbN27Ax8cHZmZmnOTLx48fER4ejpSUFOzZsweNGzfGoEGDag1rr4vsP3LkCNq2bUvW/86dO9GsWTPW70tKSkgia2HBrNPatWsxcOBAyMnJoWXLlixHkIULF8LZ2RlycnLo0KEDDA0NRbo8pZ9dv349OnTowKejZGVloVmzZmjevDk2bNggsJ7VgVdnZWLYsGFo0qQJmWOlpaX49OkTMjMzcfXqVU7e6NevX+fTV2/fvo3Q0FAcP34cFy5cqDe9Lz09HQsXLgRQNT4GBgaQlpZmycTv37/Dz8+PRV0kCu7evYtBgwZh586d5LMpU6agQ4cOGDlyJE6fPo379+/Dx8cHjo6OIusZDx48QMeOHVlRiBUVFbCxsUFcXByAqnHo0aMHtm3bxknH+B34z2Bbz9izZw9MTEzI/+kQQqDqZpL2vho/fjxnL5c3b95g7ty5ROlcu3YtGjVqhGnTplU7oZnChN6EeMPPq8OXL1+gqKiIy5cvE+8uprF24sSJePLkCZ49eya0RxkvTp8+DYqiBAqUp0+fwsLCAm3btoWWlhYroYEw5fA+Ex8fD4qiYGVlxXebf/z4cSQkJKBXr14YO3as0LxSlZVVIeD+/v4YOnQogH+MWOPHj0d4eDicnZ0xcOBAFsG4IOWgpnFhPj9+/Hi0b98eRkZGkJeXR0xMDN68eYMzZ85ATU0N+vr6MDIygo2NDUxNTYXmeaTx8OFDaGtr49y5c3B1dcXo0aPx999/48yZMxg8eDAsLCxw8uRJgXUTdo7du3cPkZGRsLS0xPTp06Gvr48hQ4Zg9erVWLJkCQwNDdGrVy/WZiRKOe/fv4eGhgYOHDiA0NBQjBo1Cl++fMG9e/cwffp0aGpqYuvWrdWWISsrW6PHJ1CVJI++1KDny9GjR6GpqVntJsm1LTdv3oSNjQ2fp3RoaCgxetd0UOO69gWhOkMEF9AhOg25XiorK5Gfny/Q83To0KHQ0tKqNpxQ0PjXdjB59OgRRo8ejSdPnuDnz59wdXWFra1ttUZbZpiSMOXQzy5cuBAmJib49u0b63t6nUZGRiI/P79eZExKSgpsbGygoqICDw8PoqwPHToUrVq1gq+vL3r27Ak7Ozt07NiRk1zmpQ7q168fevXqRXhQDxw4AGtra5ibm+PgwYNYt24dfH19YWJiwmnPPHv2LCwsLPg80JydnQmFD299eesm6prhNdq6ubnB09NT5KQcZ86cgaenJ0JDQ7F8+XLo6upiwIABhDNYVlYW8fHxLGofUeSlsNi4cSNGjBgBVVVVVqSCsEhISICuri6cnZ3h5uYGKSkpXLlyhWRzbtasGTQ0NGBgYAB7e3uRDKjl5eU4ceIEzM3NoaenBzMzM7x8+ZLVL2PHjkXLli2Jl+2zZ884HaiqQ3WetklJSTA1NeUc2jpnzhyYmJgQuRscHAxlZWX0798foaGhfFx5ouxjvL/jRV5eHqFHoGW3qKisrMT+/fuhoKCAoKAg8vmlS5fQr18/GBkZCbwk46pfJiQkQEtLCwEBAQgJCYG8vDwyMzPx8eNHTJ06Fa1atYK0tDT09fXh7Ows9Dyj6zFy5Eh4eHiQkM3g4GAoKioiODgYnTp1QseOHVlrrj7WJFO2LF68GObm5hg+fDinZJWC2gIA48aNg46ODkxMTCAjI4N+/frh1atXuH//PjQ1NdGxY0e0adMG1tbWMDMz46xbMuHn50cMhD179oShoSE0NTXh4uLCqhfXPuMN6x42bBiGDRuGlStXAqiSxx06dICvry+uXLmCvXv3ws/Pj5U4pzYw6zRt2jS4urpCRUUFERERJEIgKCgIenp6CA8Px4gRI2Bvb895rwTEN8fu3r2Lli1b4sCBA6isrMSMGTOgrq7Oip4sKiqCv78/PD09OV9mifP8Ko4zDABC1xIaGorg4GBQFIVt27ahsLAQixcvhqKiIlRUVGBkZARXV1fO+1hubi4yMjKIYTQ7O7tWoy1vnwkr+2nQl8xAlbFWRkaG5V197tw5FBYWYvDgwSJdaI4fPx5KSkpYvXo1VqxYAR8fH+jq6rIu469cuYItW7YgLS1N6OSS1c2hGzduQEtLCxMnTmTloDh37hyCg4ORnp4ucv6gFStWICoqCnPnzmUlNaaNtuvWrRMYASVseTdv3sScOXNY9HoBAQGQl5eHubk5VFVV0bVrVxa3ryhzubi4GH5+fggJCSGfhYWFQU5ODjt37sSLFy/w8OFD+Pr6wtLSsk660YEDByAvLw8VFRU+ass5c+bA3d0dFEXBxMSElZSP6x4zc+ZMREZGon///ize/cLCQkRHR8PV1RUxMTFwd3eHmZlZtfzsfxL+M9jWM06fPo3Q0FBs2LAB0tLSLHf7EydOIDo6miU0uAo83pDENWvWkJtKeqEWFBTw3SatXLkSsrKynJXDwYMHIywsDM2bN2fdsr59+xbe3t6sWzdRJnp+fj5mzpyJJk2aYNasWeQ9dL88f/4cu3btwoYNG0TODMgMsZ8zZw4oiuIjAhcELuWkpKRARkYGFy9exOfPn7Fr1y5ISEjg3r172L9/P6SkpARyx3Adl/nz50NJSYl4cE+cOBEURZGwtIKCAixZsgSzZ8/G6tWrOfdZeXk53r9/D1tbW4wbNw5BQUGscN6cnBzY2dkRwnbem1wubXnw4AEGDRoEWVlZxMTEsOqYlZUFKSkpHD16lO93wpZTUVGBoqIihIaGYsiQIfD09GSFw3/69AldunQhoT51aQsv3r17B0NDQ8IDVJ1yzqUcZlgITX0xdOhQclNIg5c7t65tYeLJkycIDAyEnZ2dQP46YTFt2rQGXy9MRYmWTbdv34a+vj4rxIeGICOHMOWUlpayvGvy8/OJ0Xbfvn1kDQoyEnMp5/Dhw5CWlibKN3Pv2Lt3LyQkJAQmx+A6/lOnToWKigp2796Nz58/w9zcHPr6+mQ8MjIyMGbMGHTr1g2TJ08WOcFYYmIi1NTUkJycTJLZ0Yb6s2fPIigoCGpqajAzM0OXLl1EMtrRSROAf9ZM586dMWPGDNZzvOHd9bFmmPvhsmXLMGzYsDopgydPnkRAQAAUFBT4KCjWrVuHRo0aCQxPrs/1D1TtAa6urggNDWUdFITF+vXroaKiQiIodu3axcfLe/36dWRnZ+P06dOcDai83i/Hjh2Dm5sbmjdvTjhf6XC+9+/fQ0VFheVZxvsOUcE02tIHL2lpaZHC+06dOgUnJydi0FJVVSWJh+jDs4+PDwoLC/mih2oa+5r42wUhLy8Ps2bNgq+vb53pCcrKynD06FGoqKjAz8+PfH758mVERUVBUVGRjwuYC3bs2AFNTU2yT61evRqNGzcm3s2lpaUoKCjAsWPHcOfOHZEM9du2bYOuri6MjY3h6OgITU1NMi5v3rxBUFAQoqOj+ehC6romme9asmQJrKys0KdPH75ElFywaNEiqKiokKityZMnQ1JSklwSfPv2Ddu2bcP8+fOxefNmkfVx+vmoqCiSzAwA5OXlIS0tTXgGedvJtc8SEhKgoaGBYcOGITExERRFYerUqSguLkZWVhZsbGygpKQEIyMjBAQEiLS/TJo0CSoqKti0aRPu378PHR0dWFhYkHPavHnz0KdPHwQGBmLMmDEi7ZXbt28Xyxx7//49bGxsSMRWXl4eIiMjYWJiAjc3NwwcOBD29vYsxxmu51fey+aGOL9WVlaK5QyzY8cOqKur49atWwD+cT5iGkefPn2K27dv49atWyJfBPLqjceOHUPjxo0xcOBAonfm5+fzRSSKKmM2bNiAnj174tChQywnLaBKz4yPj2fRYXCZA2/fvoWZmRkruvjZs2eIi4uDlpYWH0+5sGXwzvvExESEhITgxIkTAKrollq0aIG4uDhkZWWRyJ1BgwaR8ec6l2fOnAk5OTn07NkT8vLyCAoKYvV1bGwsWrRogdTUVD6qQi5grpmUlBRoaWmRSKFz585BRUVFYMSOsONP/+bq1auQkZFhOY74+vqiY8eOaNKkCezs7DhdatIQtPcPHz4cEhISGDVqFHJzc1nf5efn4+bNm7h3716dLs+nTZsGiqJgbGzMJ3fu3buHQYMGwcPDA926davTxaM48Z/Btp7x5s0baGhogKIoLF68mHxeXFxMvJK4KLolJSUCOQ2Z76A3venTp+Pdu3dwd3dnuayvXr0aEhISnG7ZaCxbtgyKiooICwsj9cjNzYW/vz9cXFzqJYNefn4+Jk2aBIqiSGhCZWWlwHdzDe9avHgx7O3tcffuXfLZpEmT0LhxY1aoLO/vasOnT5/w6tUrImwqKyvRu3dvUBQFfX19NG/enAjRjx8/QkVFhS/5lyjj0rNnT5J5fOfOnZCXlyfG5+oSN9TWZ6dOneIzvs2fP59wTdEKPI3w8HC+5CBc2sKsz71797BgwQLiOcqc161ateLL3ChsOcz3ZGRkoHHjxgL5EWNiYlhZvekyKIqq0bNSUJ/xlr1y5UrIyMhUy/G2atUqNGnSpNa28G5WlZWVZK4OGTIE/fv3J5+Hhoay+qwua786PHr0CF27dhWYGKo6rFixAtu2bSN///r1C3369Gnw9cKLkpISeHp68lELMLFo0SIoKCiIVA698RcUFBCjbWZmJt6+fYvg4GBWkpiFCxfWWI6gORYbGwtZWVlimGWupfbt2/NlDRd2jgFV8+fjx4+ws7MjSt6pU6fQokULEjZeHbjuA5cuXUK7du2IMWDfvn1o0aIFq3+AqvBLptdwbYrbihUrWB7zNJhrpkuXLiSsu7KyEmFhYazQrJr6TNDeXdO+wfyOKz8avcfk5eWRz06fPo2kpCSSKZh+Z1FRERQVFVmh8bW1pS749OkTX5SKsJgyZQrhQqU9eGjvt/z8/Dp5pDBBH2DLysqQnZ0NQ0NDGBsbsw5Pz58/h6amJrKzs0VpSq2gL7hUVFQgKSkpkOanJjDnyt27d3H9+nUkJSURmU9j4sSJcHNzY/VTbfsY7+Fu2LBhmD17NvEUqk5P/fHjh8ihg7yG8bKyMhw5cgQqKioICAggn589exbTp0+vk345bdo0wtu4e/du1jwrKChgeUTRqG1tClqTx48fx8mTJxEZGYlRo0axnh88eDCrXUDt+5iw8oH53MyZM9G/f/86HTj79u1LKKJ27NjB0i2r48kWZnyqO8Ns2LCByAFjY2O4uLggNDQUxsbGSE1NRXFxMXmWqxw7efIk2rRpQ7w5d+/ejSZNmvA5ajx8+BAfPnwQen+hUVlZib///hvm5uZkTp8/fx5SUlIsxxYaXJLzCOovcc2x9PR0yMjIkKiJ79+/Y9OmTejVqxcGDBiAqVOncjI68+p9NOr7/CqonIY8wwBVFyV0Mr5t27axPFHz8vL4OH4BbmdMQZzE9GdHjx5F48aNMXjwYNy5cwdubm6IjIxktaW2M0x1yMnJQdOmTUkCLRo/f/6Ej48PoqKiRA4Zz83NhYaGBgm9p/HixQsYGBhAVlaWRY/A1VCXkJAANTU1jBkzBr1794aioiKRMenp6bC3t4e8vDyJuBE1MgyoSpJK05Ddv38f7u7u8PHxYemSvXr1gqurK6f+qm7NlJeX49atWyS/Aw0zMzMkJyezPuOqwwJVaz08PByjRo1iyau7d+8iKytLpEtNZln79u1j7f9DhgxBmzZtkJqaKnCt0KjLnrZixQpQFMWaU3SdSkpKSIQ0ULeIKnHhP4NtPYKeWFevXkXz5s3Rq1cvbNy4EXv37oWHhweMjY05cbHs3LkTXbt2hYGBAYYMGUJu8gQhPT0dTZo0gZKSEnR0dFiGgylTpnAW3LxhUu3bt4eNjQ2Cg4NhZ2fHEnb1YbT98eMHJkyYAIqiiNeuKJsCc3GfO3cOCxYsAEVRfGEDEydOhKSkJGcCeKDqts7R0RHKysrw9fVlufUfPXoU2dnZuH//Pvns6tWrMDY2ZoXm/vjxo9Zx4W3/jx8/oKOjg3379uHChQus28+SkhLEx8fjzJkznNpy6dIlUBQFZ2dnvt9OmTKFeL3RHGmFhYVwd3dncb8K05YTJ05g9+7dAsNbeG+/gKqkFGZmZiwBX1s5NZVBC24fHx9i7Prx4wd8fHxYymFZWRnWrFlDeE8FoaY+Y+Lx48ewsLAg3nzMufnlyxcMGjRI6LZUtxaio6PRp08fAIC/vz9atWpV57UvDLjcGNP8rIKUhyNHjtTbeqkNdP9funQJsrKyAg17b9++hZWVFbZs2SJyOfS8KygogLu7O6ytrdG2bVsYGBiQ8SwoKICTk1O1PObVzbG8vDyEh4dDTk4Ox44dI236+vUrDAwMCDUHUPscE4SPHz/C1NSUeCExZUxRUREyMjKEykxfG/bs2QNTU1MAIIkNaGNzfn4+X+IhoHbFraZ5xkRISAjhgvX394e6ujpZM58/f662z5jl5+fn80W7VLdGuWQDp8G7xzC9T5ne3HSZDx8+hKmpKcsjUZTxr28IGrNBgwZhwIABOHjwIGRkZFhGlCVLlmDChAl11ikuXrwIiqJYfNUnTpyAoaEhDA0NsXPnTuzbtw/+/v4wNzevFx2mOuTk5KBz584sGVcTatrHgCqvvd69e5M5S4czDhkyhDxT2z7GHJdx48ZBSUkJ3t7eMDc3h4mJCZE5NelgXPWzO3fuoHHjxsTIQaOkpATbt28HRVFkL2OC6yU9jXnz5iEuLg779u3jS5yyY8cOpKSk1HhQ5EVNaxKoSm4SHx9P/v758yc8PT1Zn3HZx+ikOzX1s6gXQrzvLCoqgrm5Ofbv348rV66w+qu0tBTTpk0j3mpcUNMZJjMzEzo6Omjfvj0cHR2JV62Xlxd69epF6iiKHFu/fj2hVqCznNPG+u/fvwtsC1fDwKtXrwj9HW9ynsLCQmzdupUVTSkMePuL94KnvufYvXv3WI4e79+/h5eXF/E+rQ7CrElh92OgbudX3nJ4qZ3q4wwjaG6MHz8eAQEBOHz4sMB9bOjQoZxzPAij99N9f/z4cTRp0gTNmzdH+/btSVklJSW1nmGqA93OXbt2QUpKCgkJCTh58iROnDgBLy8vFi1VbfJfUJ8VFBQgLCwMUVFRfNEAffv2hYeHB0xMTDB79uwa3yMIhw8fhra2NpExtA7A1OU/f/6M+/fvs5K+ck3IePHiRVy/fh39+/dneW7fuXMHHh4e8PX1ZXm10r8VZr+sbs1U99t3797B3t6eZeAVVl4uXLgQCxcuZNF0paWlQVpaWmB0I297agNvzp327dsjJCSERac3YMAA6OnpIS0tjdNezAXz5s1Do0aN+JxBBO2dfzr+M9jWM+hJcObMGVhZWaFNmzawt7dnuV0Ls9mtW7cOcnJymDBhAmbMmIFWrVqxiOd58f37d7Ru3RqOjo58iv7Pnz/r1Bag6oCdkpKC2NhYLFu2TOQw2JpQWFiI5ORkSEpKEuVKVCQmJkJdXR0zZszAgAEDIC8vD09PTxJKBFSFfFEUhYMHDwr93oyMDEhLS2P58uXYu3cvbG1t0atXL4HPlpWV4du3b/Dz84OXlxefoKtpXJjPfvjwgcydiRMnwtbWFk2bNmV5CH/9+hUeHh5YtGiR0G0BqjwRWrZsifDwcPj4+ODs2bOs71NSUtCiRQs4OjqiW7ducHFxEcglWVNbduzYAYqiYGFhQTicedvIbPePHz8QGBgIV1dXvrVSXTnVlcGsZ2pqKnR1daGnpwd3d3fY2dmxLlFo1LY+a+szJkaMGAFZWVmBBk6ml44wbWFuKvRno0aNwrBhwxAeHo527drxyRhR1359IS0tDRISEsSQWNPGWJf1wgWfPn2Cp6cnoqKi+Ma6rKyMj1JCFNDvffbsGSiKYnEx0fOtOo94gH+OMY22nz9/RmRkJJo2bYrIyEiMGTMGnp6eMDEx4WtPdXMMYK8/Ouzu169fMDQ0JPxVTDn85MkTuLq6cpKXvOXQuHr1KgICArBixQo+6qDTp0+jd+/eApN0VQdh5hltEIiIiMCkSZPQo0cPgWtGUJ8x3zdjxgw4OTlBR0cHAQEBOHHiRLUXGMzfbd68GYcPH65VORS0x/BmeGa+o7i4GAEBAQLXTE3j39Bg1uXOnTuEmmjXrl2wsrJCs2bNWAkt8vPzERAQUGsGcGHLnjFjBsurjjbampmZgaIoREZGYsqUKfV68VwdhD24CyP7t23bhmbNmmH48OFISUmBn5+fwIO0MO15/Pgxhg8fTgxDly9fRs+ePdG2bVvCm1hfh5nv379jzZo10NDQILzrNF6/fg1dXV1QFMXnQVgbmPPswoUL5O8tW7ZARkYGTZo0YYX1FhQUwNvbm49KqCYIsyYXLVoEiqIwe/ZsLF++HIGBgZx1JRoHDhyAiooK8TKtbd/kAmZ/vXr1isyTSZMmoW3btmjSpAkrCU9ubi7c3NxqNeLxorYzzLdv32Bvb4/g4GC+PZeLHBO0vxw6dAghISFIT0/n21+OHDmCAQMGcOITZ5ZB7yOfPn2ClpYWYmJiIC8vz5pjtPGGiwOFMGe+pUuX1tsco0P4u3btyhrbqVOnok2bNpwjQpgQZj9myidRz6/ClDNx4kRIS0uLfIZhtv/SpUtEL7ly5QpsbGwgISHBimorLCxE586dERMTw0l2CiP7eWFgYMDqM2H5XmtDSUkJtm7dilatWkFTUxOWlpYICgoSeq9k9tnjx49x8+ZNsoYPHjwIaWlpTJw4kVz+FxYWokuXLlixYgXGjx8PIyMjTJ48mVOdd+zYAS8vLwD/yH5678/Pz8edO3f46i1MPzH7f/To0VBWVkazZs0gISHB5yl87949eHt7w9LSknAkMz2jawKXNVNZWYmfP38iMDAQzs7OnPR+oEr2JiQkQFZWFh4eHoiOjkZubi6Ki4vRo0cPDBs2TOSE0rx1nzRpEoYOHQo9PT1ISkoiMDAQp06dIt9HR0dDX18fCxYsqDaSo66YO3cuGjduTKKT/1fxn8G2AUBP1h8/fuDTp0/Izc3l5HZ96dIl6OnpYf369eSzmzdvomnTpnyhHUDVwd/X1xdaWlr1bkitSdA0xAGnsLAQI0aMYGUP5orr169DSUmJlTX9wYMHUFZWhpeXFwknBapCR4Ttq7Nnz6JVq1asG7sNGzYgJiYGOTk5LBL4kpISHDp0CAEBATA2NubEkcJ8ZurUqYiMjCSh0QcOHICZmRlcXFzIZvfp0yf4+/vD3t6e85jQv92yZQu8vb3h5eVF6CNo74DMzExMnjwZffr0YXFWClPWgwcPYGVlhaSkJLi5ucHGxqbaZEylpaWYM2cOXF1dOXlw11YGc3wvXbqENWvWYOTIkfjrr79EUnBq6jPa+40ew5s3b6Jr166s99ekgAnbX/S/w4cPJ4n0eA2CvxtHjx4FRVHEA/3hw4cYO3Ys/Pz8MHLkSJYXZWlpqcjrRRTMmjULnTp1atCb1S9fvsDCwgJGRkac5bKgOUbThtDrcs2aNejZsyd8fHwwePBg1nrh4v2wZMkSjB8/ntyqb9iwAWpqaqwEBD9//kRAQADnZCPMcnbs2EHCqp4/fw4jIyNy+GSW4+fnx4k6qLZ5xusJFx4eDoqiYG5uzlozwpQ3adIkqKqqYv369Xj69Ck0NDRgb28vkB6EN+ScoigcPny4xvfXtscwvWuLioqwcOFCuLq68iWX/N0eA8xxT05OhoWFBaGjycvLQ9euXaGrq4uMjAx8+fIFd+/ehZ+fHywsLDhnhOZ9jikjZ82ahUaNGpGDG02PoK+vz/L0/BNkZm2yn5cT2dbWFk5OToiOjhZpH9u5cye0tLRgYWHBmlc3btxAz549oaOjI5SnrSDwym26XsXFxUhPT4eysjLLaPvlyxdERkbi3LlzIsuX5ORk6OjosCInkpKSQFEUtm7dilu3buHu3bvEk1jYeVbbmmR6io0fPx6tWrWCjY0NevbsKfJlQFlZGXR0dEhyxOrArPuGDRtq5ZXn1S179uxJ6EDOnz9PErC8fv0aQNVe4+fnBzs7O05tEPYMc+3aNZZxgVmGMHKM2Z7MzEyyh928eRN6enpo3LgxyxhZVFQEPz8/TmHdvIkoZ8+eTcKS58+fDxkZGRYtFX2B5uvrK7T+wuXMN2nSpHqZY0DV3pmcnAxVVVXY2dlh1qxZePjwIaysrKrlExXmncLux3SeCVHOr7WVw/Qw3b9/v0hnGN5IBDrBW3FxMQoLCxEXFwdDQ0NMnDgRb968wYULF+Dn5wczMzNO+xiXcxJQJUd5o4MaYg/78uULnj59itevXwttw2DWdcKECTA0NIS2tjbatWuHCRMmoKKigvDYu7u7IzQ0FLa2tsRb/dOnTxgxYgSsra1Z+WdqK2/FihWwt7fH6dOnISsryzLObdmyBcOGDRMYzSlsW+7fvw8LCwtcuHABx44dQ9euXWFjY8NHrXjz5k2MHDmS09mFy5r5+fMnFi9eDC8vL5YOK4zez4vXr19j5cqVMDMzg6GhIfr164fAwEAEBgYS42lddMlFixZBRkYGZ8+exdOnT7Fz504YGRkhLCyM5egUFhaGbt26NajeSlOk1Dc9mDjxn8FWSHCdSFy57pjPpKamokePHuTWuaysDHl5edDX1yecTEx8+vQJK1euFFpwV+fZKCxEXVTC/q66TNfC4sqVK9DQ0CDE9XS/XL9+Hc2aNUNERARfshRh+mzfvn1YsGABS8H09PRE27ZtIScnB3t7e8TGxpLv7t69i5UrV9YpKY+Kigq2bdvGCq1avXo1rKys0KpVK9ja2sLS0pJlsBNWcSsvL8e7d+9gbGyMDx8+IDs7G507d4aXlxfk5eUxcuRIocJ8a8KjR48wevRoPHnyBD9//iS8nkxlhIndu3ezEuoIU44wZdTUJ1wzj9fUZ3FxcayDRmlpKSePJ679tWLFCujr6zeIx3tdUF5ejo0bN0JVVRUjRozAy5cvoa+vDz8/P/Tq1Qvm5uaws7Nj8Xzfu3evTutFGDDlCpdQJVHw7ds3REZGEu9LLon/qptjcnJyLA80QR7CXBAfH0+SptAXQO/evcPYsWMhJyeHzp07o2/fvnBxcWEZ0rl6JowdOxbq6uqs0KcTJ06gSZMm6N27N1atWoU9e/Zwpg4SZZ6lpKSgY8eOnOfZq1evYGFhQZTqM2fOsPh9mXVl/p/O1FuboijsHjNs2DDy3fr16xEZGfnHrX8aEyZMgJqaGrKysliHpa9fvyI0NBSGhoZo1qwZbGxs4OLiUifjw6xZs8ghnbnOZ86ciUaNGhFuydLSUly9erVBPWpFgTCynzm+X758YXnBcB37ffv2wc/PD9LS0nx8rjdv3kTv3r0hJSVVIxWXIPDmEIiKioKjoyPWrFlDvNMyMjLQsmVL+Pv7IyMjg/D/iZoAZsKECVBRUcGpU6f4wtCHDRsGDQ0NSEtLw8bGBm5ubpw8xYRZk0OHDiXfvXnzBgUFBSIZOICqy/6KigpMnDgRgYGBApNV8v6ODqXlzbpdHRITE6GkpIQ9e/awjPXbt2+Ho6Mj5OXlYWlpCXNzc1hbW3Nal6KcYUQBL22bpqYm0tPTSeTKhg0bQFEU4uLisHv3bmRnZ5NIFK6XQsA//JhMWqAnT56QxLlDhgzB8OHD4e7ujo4dOwp96SxsfzHf8/r1a05zrDZ8//4d48aNg7e3N6SkpKCgoIDg4GDO7xFlP/7y5Qun8yuXcng9IJng0mf0RW12djZrPRYUFCAhIQFGRkaQlJSEpaUlvL29Oe9jwsh+5lwtKipCZmamyPu+MPNeVBsGjblz55I+A4CuXbtCWVmZJII9efIkZsyYgYiICIwePZoVpfT27dtqI92qq8O3b99gYGAAiqJYOReKi4sRGBiI/v37i6zrr1mzBiEhISzd6+HDh+jbty86derEZ7Stra5MiLJmtm7dykrULcr6561bWloaRowYQXifZ86cyfmdvAgPD2dxKwNVF2saGhoICAhgGW2F8Sivru7CjuvmzZv/OB2ZC/4z2AqB6iZHbZNEVOHw+PFjPtLpyspKmJqa8iVt4AUXY+2LFy/4snFWB2ZbhOEaYZbTkJn3BPXxmzdvICUlxQpRqqiowNevX8nG2rlzZ871KigoYIVRBQYGonXr1jh79ixu3ryJuXPnomPHjiQUggmuB5DMzExoamqSjNKVlVUJgeiwjr///hurV6/GtGnTsGXLFpEz9gJA9+7dSYjCgQMHICcnByUlJZYHpKhjWFpayjoQ5OfnE2Vk3759pN6C5pSwfSZsGYISX4iKhuozUfrrTyVNLyoqIpm6KYrC2LFjya3tp0+f0KtXLzg5OQlMXiSKMUWU/hbXb0QJLxJmjgnruS0I69evh6amJispXnl5OfLy8lBeXo6srCwEBgYiOjqac7IRJmbOnAkVFRVcu3aNhPjSfXjixAn4+PhARUUFzs7OiIiI4HzYEXae0QaX8vJykbLPPn78GAYGBgCq5DOTs/DHjx/YuHEjH81FWloap0zN4txjGhoPHjxAu3btiFdxfn4+njx5glWrVpGIhL///hv79u3D3bt365TQoqysjCT9pMujv6cPbE2aNGEdeoA/q8+Elf2C5KUofIJA1fpzcnKChYUFKzErUEWPkJKSInIfJSYmQlFREaNGjUJ4eDh0dHQQFhZG5M3x48dhbGwMa2trlpGDq3x98eIFi+/+27dvePDgAWbOnEmMA48ePcL58+dx//59zvNM2DVJR3Rx4cZjfk9HUNCgPSzpnA7V/Y6WMcJyvB4+fBitW7cmhviysjK8e/cOFy5cQHl5Ob5//461a9diwYIF2LFjh0i6ZV3OMFwxdepUqKio4NKlS3zG7XXr1sHe3h4tWrSAg4MDgoODRboUWr16NdTV1XHt2jXW5yUlJfjx4wdWr16NTp06oXv37hg7diznvVLY/hI0n+p64cz04K+srER6ejq6deuGZs2asTjxhUVd9D4uc4zrvi9qP9HRQLTe9eXLF9y6dQszZ84k9FA/f/7E6dOn8ffff4ukW9TlDMOVg5WJhrBh0F7mfn5+RD86ePAgZGVlCTVJdRRStenJzPpkZGRgzJgx2Lp1K4kI2LhxI/T19dG1a1fcuXMHBw4cgK+vL+uCnmub8vLyEBMTA1VVVfj7+7O+o422Tk5OLHonrhBmLjs6OtbbWYkJ3rlx5coV9O3bFwEBAaxLIS6gf9OnTx9069aNlEN/PnPmTLRo0QI9e/ZkRYVw3fv37dsn9LmeV1/8X8R/BlsOWLRoEfr06YNhw4aRxEXCCMLjx4/XSOJc3e+YKCsrg56eHitJzfjx40VKBABUeTxpa2tDVVUVfn5+NWZ8Z9YpPT0dSUlJNXKNMJ9ftGgRhg4ditjYWL4kLTX97vDhw3zKES+Ywp3OXEwLr+TkZL4wtsLCQsTExODkyZOQkpJi8Q6Jgl27duHly5fk76dPn0JKSkpghkeu2LNnD+zs7MjhIyUlBW3atIGuri48PDyQm5vL9xtRBXeXLl3ITbSZmRmMjY3h6ekJf39/Fq1EXcFMJEArI5mZmXj79i2Cg4PrPB7ClMFLPC4qxNFntbWFNj5UVlbWWWlvKBQVFWHz5s0YMWIEuRyiZeaFCxdAURTnzOlA1QH88OHDSEhIwIoVK4RO6MO1n0Qtpz4uqRp6jiUnJyMwMBBAVWKkZcuWoWPHjmjVqhWL848JrjKmqKgIgYGBRJl9/fo1srOzERYWhlmzZuHt27eorKzE58+fWYoXV4VKmHnGu5/UNBeY40fXq6ioCEZGRhgwYABkZWVZ/L7379+Hk5MTi5tr4cKFUFRUFNpYKwgNucc0NG7fvg19fX2cP38eZ86cQUxMDIyMjKChoQETExM+qgpAtIQWr169QmVlJYqKijB8+HBISkry8SyPGDECFhYWcHR0/GNlJRP1uY8x++rkyZM4dOgQq+9PnToFPz8/2NjY8Hna0uC67q9evQodHR2WN+XevXvh4+ODXr16EV2wvLwcnz9/rtOl48OHD0nY5ZUrVzB48GAYGxtDVVUVrVu3rpcEU0zU15pk1mHXrl0wMjJC586dcfnyZeKNnpSUBB8fH5bXsCBjLRcZc/DgQRgbG+Pjx4949OgRkpOToa2tDU1NTZiZmQnkVucy/lzPMEyZyRV5eXlwc3MjHm7v3r3D+fPnMWDAAKxZswYFBQUoLi7Gixcv8OXLF5HnWWxsLPr27Qugaq9cs2YNrKys0KFDB3JBxGtsErbPxNlfwuLTp08YPHgwBgwYgLKyMs7rpaH0vt9RzqtXr2Bubo5169YhOzsbUVFRMDc3h6GhIVq3bi1QFtdFvtQm+7kaBnmpmYYPH445c+YQasDq5h/z8/PnzwvtdEDvxTY2Nnj27BlOnTrF4pH+9esXli1bhps3b3JqBxMpKSmQk5ODh4cHpKWl0bt3b1y7dg3l5eXYtm0bjI2NoaCgAAsLC4SGhoocGUbj8ePHSEhIgLS0NBYsWMD67tGjRwgMDMTgwYPrpFuIosPWBlHrc/HiRTRt2rTG/CzCYOXKlZCQkODj8l6xYgW8vLxgZmaGMWPGiFTX48ePQ1VVVSi+bt6cQP+r+M9gWwOYgzxx4kQoKSkhIiICjo6OkJOTI5xsNblnp6amgqIoYuAVBXT4roWFBY4dOwagKpOqjo6O0EoBs47btm2DtrY2tm/fTjhFTE1NBSrrvMJeUlJS4EFLEGbOnAlZWVn07dsXGhoaMDAwwLlz5wRuZsxyli9fDmVlZVy8eFHge8+cOcO6SZ8xYwZ8fX3RqVMnTJo0Cc+fP0dhYSGGDh1KwtQXLVoEd3d3WFpaoqKiAq6urqwwtrqArvvjx4/h6OhYbb254MCBA9DQ0EBQUBDU1NTQr18/pKamYseOHdDR0amzIAX+qfeqVasQFxcHS0tLODs7o7i4GEePHoWNjQ1Gjx5d53KYYN4Uu7u7w9raGm3btoWBgUG93Xo1ZBni7jNx9FdDo7CwEM+fPyd/03145MgRWFpact5At27dCjs7OxgZGaFVq1aQl5eHlJQUMjIyqr25Z5YLVCXcoG/lf3c51f2+oeYY/f7ly5fDwMAA/fv3h4mJCbp164bk5GSkpKRAUlISz58/rxNtRGVlJfLz86Gnp4fBgwdjz549CA0NhZOTE1xcXGBgYIDExESRw5t4UV/zjDekOz4+Hjk5OQCA6dOnQ1FRkZVwiOYs9PPzI7+ljbubNm0SqS28aIg9pj4haE//9esXOnToAAMDA0hKSmLYsGE4cOAAXr16BSMjI1bYoqhlTZ06Fd27dycex7m5uRg2bBgkJSWRlZWF8vJylJWVITw8HMePH68T1ZK4Ud+yPz4+HhoaGtDT00Pz5s3h7u5OPFCPHz8Of39/dOrUqU4HaRpXrlyBqqoqy3sfqOKxbtmypcAy6mLk6N69O2RkZNCiRQuMGDECmZmZAABDQ0NMnTpV5PfWhPpak1OnTkWvXr1w9OhRODk5wcrKCjY2Njh27BiWL18Oc3NzclHI7KO//voLCgoKnC+Ejh8/DhMTE7i6ukJZWRmRkZFYuXIlTp8+jVatWnFOKikM6uMMI+idnz59IsmFs7Ky0KNHD3Tq1AmmpqZo164d5s6dy7fWuax9+tnp06fDyMgIo0ePhrW1Nbp06YK4uDhER0dDXl4enz9/rtdIwoboL2HLpZGamgpDQ0MSFcMV9a33iaMcQX1bUlKCwMBAmJqaolGjRhg1ahSOHj2KvLw8eHp6YtasWXVvRDX1qKvs5+XgVVJSgqenJ8zMzGBqaorz588DqJ4HHqgyrlEURaI9hUVQUBA6duwIaWlpZGRkkM/fv38PFxcX1mfCtqOyshK/fv1CREQEzp07B6BqnG1tbREWFkb2M6CKYu3r16+cLmmY/fX+/Xu8f/+efPb27VuMGTMG+vr6fMm9mZ7VddEt6msuZ2Zmcubr5YWtrS0r+aSo6N+/P+Tk5HDo0CG8ffuWJOXbsmULVq5ciUaNGgl1RuLt1w8fPkBZWRnXr1+vsc95bVguLi5CcSP/ifjPYCsE/v77b0yePJmQv7969QqDBw9Go0aN+Iy2vLffCgoK2LlzZ53Kr6ysRGlpKRwcHJCVlYXg4GDo6+uLFEK2Z88erFixguVBlZ+fD1NTU5iYmLA8yHjJ9mVlZWvk4eOtx8iRIwl/DQA4ODigTZs2OHPmTLVhY2lpaZCXl8eOHTsEljFv3jwoKyuTg/DixYshJyeHOXPmoG/fvnB2doahoSFycnJQWlqK1NRU6Ovro1OnTqwsl66urpgyZQpf+VzA/N3Pnz8RFBQET0/PelPcNm3ahAkTJmDbtm0kycH79+9hampabzxgAJCdnQ2KouDq6sry5Lh06VKD0FnQysizZ89AURQ6depU75m6G7oMcfaZOPpL3CguLkZwcDBCQkI4rb+VK1dCRkYGq1atwqNHjwBU3f7369cPkpKSJLmQMAoorzHhd5RTExp6jj179gzTp0+Hm5sbVqxYgcePHwOouhBzdHQkMkcYMDmBebF7926oqalBSUkJEyZMINnnY2NjSbhUQ0HUeQZUcRaqqKhgw4YNJELmyZMn6NOnD3R0dNC/f3+MGTMGrq6uLM5C+mAg6kGXiYbeY+oDTM+bs2fP4vTp08R4VVJSgt27d+PMmTOstnTq1KlaL25hUR0PJ+1pS6+dDh06wNTUVOSQyN+J+pL9q1evhrKyMm7cuIG3b9/i+fPnMDY2RqdOnchlxOHDh2FnZ4fo6GhOdRSky125cgUqKirE2MScI23btuWjpqgr6KSVvI4Rrq6uRFbXF+q6JnkTZeno6LA8p06ePIkRI0agTZs26N69OyiKQnh4OOt3ubm5sLKyYnlfcsGePXswa9Ys7N69mxxeP3z4ADMzMz5vqPpAXc8wNe0v8+fPh4KCAmRlZZGUlESiT8LDwzFw4MB6qf/169cRHx8PU1NT/PXXX+SclJmZCTc3N6Fo4rigrv1Vlzwl9PyeNWsWdHR0BEbziYq67McNXQ7ToHf48GHs3r2beE+Xl5fj8uXLLIMgUHWmnTNnTv1VnIH61PsfP36MYcOGEW/jixcvonv37tDR0SGGT0GXmaLYMOh5du7cOcKBTSM/Px9+fn5wcnISydns7t27ePLkCfr3789K8k0bbcPDw4l+Wd07qgOz3ZMnT4aJiQnatm2LDh06EFqKd+/eIT4+HgYGBgIjQhtCL+M6l+kEt7QxXljwGjYpiiKc83VBfn4+hg4diubNm0NXVxc6Ojpo3749SktLce7cObRr146Pd14YFBcXQ0VFhTgQCrLB8c5laWnp/5KO/ZuxZ88eUBQFfX19cnAHqpSbwYMHQ0JCAkePHgXAFviihCrVhLKyMpiampK6iJIZ8tu3b5CVlQVFUZg8eTKAfyZ0fn4+zMzMYG5ujlu3bvFNdDk5uRrbwhRUFy5cwNGjRxEZGcmXsMLBwYF4iPIKbGH7LDw8HEZGRti4cSN69+7N8vi9dOkSunTpAktLS8I7VlxczGpPYmIiNDQ08PTp0xrLEQaFhYU4ePAg/Pz8OGW3FzYcl/4/zS3m7+8PR0fHejPU0fU4efIkMdDw1q0hNqEvX77AwsICRkZGDZYwp6HK+B19Jo7+EgcKCwuRmZkJb29vTok5gCqP02bNmhGuPmaff/78GYMGDULjxo35PJ24KqDiKqcmiHOO/fr1i7yfmeFa2IMOL29gRkYGJk2ahMmTJxNezI8fP7JodyoqKuDt7Y2RI0fWSxt4Ico8Y7b34MGDaN26tcCLscePH2P16tWws7ND9+7dkZCQ0KBrUtQ9pqHRu3dvlvI7evRotGzZElpaWmjSpAn69u3L2mN//PiBt2/fkizaddnDBPFwfvjwAadPnybzeePGjRg9ejSSk5OFzgr+J6I+ZH9cXBy6du0K4J8+yM3NRdu2bdG9e3fy3JUrVzjNK+azixYtwowZM0iIYkREBDQ1NVl5Ej5//gwjI6NqL+TrA0VFRcjJyUFgYCArwVR9oj7W5OHDhzFo0CCkpKQA+EcO0zh//jxWr14NMzMztG3blni40WWIwskvqH5lZWX48uULAgMD4eDg0GBrpD7OMEBV5MuiRYvw119/kb3x8ePH5MKRhpeXF8aPH18/lUfV/sDc68rKyuDv74/g4OAGMT6K2l/MMb59+zbu379PuC+F3f8ePnyI3r17c044WB3qovc1dDldunRhXeqMGTMGsrKy0NfXB0VRCAgIYFFQFRQU4NmzZ/D19WVdBDYE6kP279y5E61bt4alpSXLMHb9+nVERERAV1eXGPfq04ZRVFSE1NRU6Orqon379vDy8oKdnR3MzMxEMjyPGTMG6urqaNasGWRkZPg4u48ePQoHBwd4eHjw8YHXBubcnzZtGhQVFbF582bs378fffr0gZKSEqG+ePHiBRITE2t0LKsPiDKXaQqC6sZMGPqLW7du4cGDB3yJ2euK48ePY8uWLdiwYQMZ95EjR8La2pqV0LMmLFq0CObm5hg5ciTmzZsHZ2dnTJo0SeClkqC5/L9srAX+M9jWips3b6JPnz5o0qQJCUOnJ/eHDx8QExMDiqKI9y0ALFu2DC1btqw3Yy1QJfysra1ha2srkuCm65yTkwNjY2PY2Njg3bt3rO8KCgqgrq5OuJoAYO3atZCWlq6xLczFPmbMGLRs2RIaGhqgKArz58/n8zRydnbmyz68fPlyyMjI1LigmF4aISEhMDQ0hJaWFh9H2YkTJ2BiYkLC4mjhcPPmTYwePRoaGhr1EvYHVM2BESNGoF+/fkKPC2/indrw69cvTJ8+HV5eXrC0tPyf964Eqi4PIiMjSWh5Qyg94ihDXPi3tOX9+/eIjo5G9+7dOR3YcnJyQFEU8ZgRdJv68OFDtGvXDn369CGfceX7E1c5DQ1heJ2YKCwsxPbt2+Hh4QFTU1OhD1Tjx4+HjY0NUZhGjx4NBQUFODo6wsLCAo0bN0ZaWhp5X35+PrKzsxEYGFinRBC1gcs8mz9/Ph8n++LFi2Ftbc3qx9qoGxpKHouyxzQ0Pn78iPDwcCgoKODIkSP4+++/0bZtW1y6dAnPnj3DiRMnoK6uji5duhDv5EWLFsHS0hJOTk513sOq4+Fs1aoVjI2NBXLs/+4+ExV1kf30nO3evTs8PT3J57QOsmvXLmhoaJCs97y/ExYJCQnQ1NTE3Llz8ebNG1JvHx8ftGzZErNmzcKSJUuIkaOh1kpFRQX27NkDJycnuLq6NpiuJMqapOVFRUUFXr58CSMjI0hJSWHIkCGs+vPKlYKCArRr1w4JCQn12gagah789ddf8PHxgZWVVYPqlqKcYcaMGYOgoCDy98iRI6GgoABTU1Po6elBQUEBBw4cYJ1hLl68yLe/1Cd+/PiBffv2wcPDAyYmJqTP6nsPq+uZb+zYsVBSUkLr1q2hq6tbI/8+LyXduHHjRPJ6qw6i6n0NXc6vX78watQoNG7cGBs2bMDr16+hr6+Py5cv4/v377hz5w7s7e3h5+dHPDeXL18OR0dHuLu7N/hZrD70fpo7XEZGhs8Id/36dfTs2RPNmzdnGTmXL19eLzaM4uJiPHr0CElJSZg4cSJSU1OFTmLInJNXr15Fu3btcOLECWRkZMDV1RVOTk58CQz379+PQYMGCb1/MUPxKyoq8P37d9ja2mL58uWs5xITEyEnJ0ciIeicDw15Buc6l7ds2QKKokhUy8uXL7Fp0yYkJCRg3759hGpBmKjA2oy1zN/UlM9IUHlAVf8NGDAALVu2FMq4XlFRgfLycixduhRJSUmIioqCiYkJ1NXVyYVWWFgYYmNjMX36dFZ0IB21/TvPY/WF/wy2DFS3yO/cuYOQkBC0bNmShBTQk/Ddu3eYN28eWUgPHz4ERVGcsmsKK1yePHkitLCr6Z05OTnQ0tKCp6cnn/dWUVERKaOkpAQxMTGsrOS84OVrdHBwQHZ2NnJycuDv74+OHTti+/btfN4DQ4YMIeXcuHEDHTt2rPG2StCi79u3LyiKQmJiIp+XV/v27ZGcnMz67MePHzh06BDf4aQ6CDsuubm5QvPkjBo1ChoaGqS+wpaxc+dOTJw4UeQDu7i8sUQpR1gye3GWIWo54ihDlLaIA8K2hSuvFFAll6ZMmYKmTZuSBCOCZEL37t1hb2/P992KFSuEUkDFVQ6NhphjXbp0wYQJEziFab59+xYpKSkYMWIEJwPEmjVr4OjoiICAANy+fRthYWG4efMmysvLUVlZSfhw6f3w0qVL8PPzQ0BAgMiHnfqcZxs2bEDv3r356jBr1iyYm5sTgy3T2LJr1y5WtE1d0BB7jLjw/PlzDB48GPLy8hg5ciRiY2MB/NNXt27dgqysLPFy+/79OzIyMkTKOs+L38HDWd9oCNlf3TsPHToEKSkprF69mvX59u3bYWJiUqew5z179kBVVVVgnoaysjKMHj0adnZ2sLa2Rrdu3UROAFPbwZDGmzdvCH8xXQcuaOg1ST977tw5ODg4wMDAgDVfmW2m++qvv/6Cu7u7wIRgdcWuXbswe/bsOl0GNcQZ5tevX5g3bx4sLCzQv39/PH78GD4+Prh16xYKCwtRWFiIyMhIyMrKEmea7OxsuLq6wsfHp8GMaTk5OUhISMDAgQMbXB8X9cx3+vRpaGtr4/jx4zh48CDCwsIgJydHwt+Z4A2FbtKkCSfPwYbU+8RRTmFhISZPngyKojBs2DBERUWhsvKfRL4PHz5Ehw4dMGDAAABV5+I9e/bUaR9rKL2/uksDmh/b0tKSz3B/6dIlTJo0iXUepyiqQb1HuazJtWvXIjIyEhMmTCCfnTlzBsHBwXBzc+Mz2tKorY8HDhyIrl27kuRrQJVHc9u2bQnlItPZzMXFhRWNIkpbhK0bDWHn8q9fvxAXF0doDN69ewc9PT04OjqiTZs26NChA1xcXPh4iOsaFbho0SJCbVVbPzAv1Q4dOoSQkJAajbXV0WbSKCgowOjRo2Fra4t9+/YhOTkZLi4uCAsLI3XZsWNHjR7H/2v4z2D7/8GcHNeuXcO1a9dYfDV3795F165doaqqyme0pUEvKNqjRBBEzTrOXKy1LQxmW9LT0zFu3DhERUXh4cOHpM6PHj1Cq1at4OXlhc+fP/O1Rxhlh/n8zp070bt3bwwfPpxVz6CgIJiYmGDbtm18Rlsav379IjxqtWHXrl3kBgmoMpy0a9cOa9asIbeQP378IFxTwkLUcWH2jzA37Ddv3oSJiQksLCw4G21p1Pa8qG3h6iEgajlc2iuOMupSDpc+E1dbxIH6WC/CtOvcuXNYsGAB/vrrLxw5cgRLlixBo0aNqk1YEBwcjKioKPJ3ZWUlbt++XasCKo5yxLUup0+fjkaNGmH27NmcjLZ02CQg/KVARUUFtm7dChcXF1hbW8PCwgIfP35kjW18fDxUVFSIx05OTg75vrbDTkPPs/LycvLsoUOHSGjW6dOnQVEUUlNTWc8XFBQgJCQEa9euFaoeTIhrj2loMOvz9OlTxMTEQEpKCv7+/gCq+pvei5csWQJtbW0+PuT6MKKIm4ezLhCH7Gc+e/z4cWzatAnXrl0jXH9jxoxBmzZtsHTpUhQWFuLt27cICAiAv79/nebVggULyNhXRz3x/ft3FBUViWywEeVgKMyz4l6TGRkZ6Nq1KzG8nj17Fg4ODggODmble+B9Z0REBBwcHGrkxa5urggTBktDmHUpjjMMDTqs2traGi4uLnB2dsb3799Zbe3WrRv09fVJ31y/fl3o/aUmb7Oa8PnzZ/JsbXtlQ/cXb52XL1+OFStWYO7cueSzgoIC9OrVC3JycixuS0GRQTVFOYpL7xNHOcxni4qKkJKSgsaNG8PCwoLPo3XHjh1o3rw539m+IddLXc6FDx8+RE5ODouSKCsrC35+frCzs2MZKZmg21PdhTQXWcL8jkntx0VefvjwAd26dYO8vDwxmNM4c+YMQkJC4OnpyUePIAy2b9+O1q1bY+DAgawx8fT0hJOTE/mbngv9+vVDv379OJcjrjXz5csXDB48GBRFQU1NDcnJyWTvz8zMhLu7O6KiolgUaDREjQrs168f9PT0ah1T5ve0w1xNl4+8NqwRI0YgJiaGL+/BwYMH0apVK9ZlLl1WSUkJ0tPTWfvq/zr+M9iCPZmSk5Ohr68PbW1t6OnpEa5XoMpoGx4eDg0NDYEZYWtbVPWRdfzMmTPVZtTjXTRJSUnQ0NBAREQEAgIC0LJlS2zbto0YCh89eoQ2bdrAzMxMaA4RQWU9e/YMXbp0gYyMDBwdHVnPVVRUIDg4GObm5khPT+dTbrhsSk+fPoWZmRmCgoJYxOJhYWHQ1NREaGgopk2bRugShD0UNPS48OLevXswNjaGmZmZUEZbpuCmjesN2RZhMtuLo5z/2sK9LeKAuNYLnSjHzMwMMjIyaNeuHdLT07FgwQJQFEUymNJr5++//4abm5vA7PO8/HbiLkcc4898dvHixaAoCrNmzRLKaFuXw0F5eTnWr18PJycnSEtLE8MsrRjeuXMHGhoafHywv3u/ZO5Fly5dQvv27TFo0CCyF06ePBkSEhKYMWMGLly4gKtXr8Lb21sk/lVx7zHiAJNmaejQoaAoii8aZ/Xq1TA1NeWLgKkLficPpygQt+wfM2YMFBUVoampCR0dHXTq1Al37tzBz58/MXHiRDRr1gwaGhpo164di2JJ1IvBsWPHQldXl/xNv6e0tBTZ2dl8RkZRjMPCHgyZbagtYYq412R5eTlmzJgBCwsLREdHkwPryZMn4eDggJCQEBZXJo38/Hw4OzsL9GCmwWz3rVu3cOzYMeTk5BBZVt3YMteJMBnIxdVnzHoVFBRg6dKlMDc3h5qaGmkLPa/Onz8PTU1NPm+t2uYz83zw9etXoZNEcpm/Dd1fDg4OLCPG9+/fYWNjA4qiMGLECNa7aKNty5Yt+WjkhMlTIq6xF/e6pNdIQUEBZs6cCYqi+ELiMzMzYWhoyJkmQlyyn/n8pEmTYGpqClVVVbi4uLCSY2VlZcHf3x8ODg6ceV6Z6+ndu3f4+++/WZRR1e25ghzBuODmzZvo168fZGRk+Lw/z549CycnJ5ajmDCg1/7Bgwehra2NIUOGEIrGU6dOwcjICD169GD9xsnJCaNGjeJUjrjn8rdv3zB69GiEhYXxOU6MHz8erVu35rP1CEt/wawT/d4HDx7AysoK27Zt43tG0O8WL14MBQUFkl+oNiQkJEBNTQ1xcXEYOnQoFBUVERMTQ76/dOkS5OTkCN0Db/3+RGenuuA/gy0D06ZNg4qKCs6cOYPPnz9j9OjRoCgK8fHx5Jm7d+/C3d0dgYGBnN4t7qzjq1atgpaWFuFqPXv2LCiKgoKCAjIyMsiNxL179xASEsJpYjPrNHToUHTv3h2vX79GbGwsdHV1MXfuXD7uPwcHBxY3LtdyaOzfvx8eHh4ICQnBqVOnyOd9+vQBRVHw9vbG/PnzhU4y8ruywQtrtGWWs2rVKgwePLha47q42iKOcv5rS93nWENAXG1ZvXo1mjRpgu3bt+Pnz584deoUnJ2d4ejoiKdPn2L8+PGgKArr1q0DULV2AgIC4ObmxulmWhzliHP8eZMACWO0ZZazbt06TJs2rcYymGAmfdq6dSv09fXh5OSEL1++kGeePn0KTU1NlryuDeLss7Vr1+LNmzeYPn06HB0dMXToUJLQZ/ny5VBWVoaqqio6dOgANzc3zqG2/6b1T2Px4sVwdHQkffH8+XNERUUR+ov379/j8+fP8PLygre3d4N6BouTh5MrxDH2zGdPnDgBMzMznD9/Hvn5+Th06BC6du0KHR0d3Lt3D0CVIXPnzp04evRovdBT7N+/H/r6+li9ejXL0yUvLw/Ozs7YunUrp/fVx8FwyZIlNR4MxTEugvaE4uJiLFq0CDY2NoiMjGQZbZ2dneHk5ER4EpmoydDBrFNSUhIMDAzQqlUrODk5wc/Pr1oKMObvVq9ejW7dutVIjfE75Bjt0Zifn4/U1FSoqamhS5curL69ceMGWrVqJfQ79+/fzzJOp6SkwNnZGYaGhli3bl2NxgRmWzZu3Mjn8cWEOPpr3759fJGLz549Q2hoKFRVVYmHJf3OHz9+wM/PD97e3qx61uZd92/Sx5lITU1Fu3btSGJE+lKLoijMmzcPt2/fxsuXL+Hr6wsnJydO5+TfsV5SUlKgrKyMY8eO4d69e+jbty+JtqJx8OBB2NjYYNCgQUK3hdepzcrKCi1atICvry+mT59OvuPdc5m/W758OUJCQoTea5i/vXv3Lvr3748OHTrweYDfvn1b5EiUp0+fYsiQIZCXl0dUVBSeP3+OiooKbNy4Efr6+tDT00NYWBhsbGw4OYEBv0/v+/z5M4uDlq5zamoq3NzcWBdT165dE4r+ojr97efPn/Dx8UGXLl1q/V1aWhpatmxZoz7AnD8nTpyAjo4OLl26BKDKI7p58+ZYs2YN6zcaGhqsxPP/ZvyfNdju3buX5fVx//59+Pr64ujRowCqbqLk5eXJ4kpMTCTPPnv2jJOAaOis44MGDcLevXvJ34WFhZg/fz7hK9u7dy9kZWWxadMmDBkyBAoKCti0aRPfIZ7rbcTHjx/h5OSEkydPAqjyqBowYABsbW2xcOFClmBghkVwBR3uSCMzMxOurq4ICQlhhT56eXlh8ODB5O/aDmziygYvqN0VFRW4e/cuOnbsWK3RllkOzS1VXeiHuNoijnL+awv3togD4mrLqVOnQFEUpkyZwvr9nDlzoK6uji9fvuDXr1+YOHEiSRbRtWtXViZlYYw14ihHXH3GfJ5Zp7/++qtGoy3zd6mpqZCRkcGBAwdqbBMNmjaA9jQuLy/H5s2bYWNjA3Nzcxw7dgyZmZnw9/eHubm50Aa0hu4zpoxdunQp4f0qLS3FrFmzYGtri5iYGEIR8fz5c9y7dw937twROtRWXG35Xbhw4QKUlJTQuXNnPqNt48aNoaamhhEjRsDBwaHBMoIzUR88nPUNcY/9unXrEBMTwxc6evPmTQQEBKB3794CeWDratguKysjh9qZM2fi+fPnuHHjBvz9/WFtbS1Sclxe1OfBUNzjcubMGdZvi4uLsXDhQtja2mLAgAHEueHw4cMYMmSIyM4TixcvhoqKCuFzHTVqFKSkpFgUYoJ+t3LlSlZ/CMLvkGNZWVmgKIqEtBYUFGDFihUwMjKCr68vbt26hbNnz8LPzw82NjZC9dvGjRvRpEkTkmhyzZo1UFJSwuLFi9GzZ09oaWkhISGBz2OLty2pqamQlZWtlitb3P01ffp0lmPRy5cv4ebmhlatWuHly5esd//8+ZPVVzNnzqyRBuHfpI/z4sOHD2jbti06depEjNs/f/7EpEmT0LhxY0hJSWHUqFHw9PTktI+Joy1Xrlxhye4rV66gU6dOJPr0yJEjkJGRQXBwMFq0aIF58+aRZy9cuCDSfjx9+nTijbl9+3bExcVBR0cHI0eO5HuWty1ycnJ14sW9desWIiMj0aFDB5a9gwbX9owePRq6uroYNmwYgoOD0ahRI/Tt25esl6dPn2LUqFGIjY1FcnIyJ93iT9P7SktL4ePjw6Jxo1FbgjFmv27fvh1RUVH49u0b2beuXbsGJSUlvugq3rbUdCk0bdo0Ej1Mz+n169ejU6dOAIDdu3dDRkaGXJD9+PED2dnZ+PXrF2JiYv6Iy3lx4P+kwXbWrFkIDAxkTcTv379j8eLF+PHjB86cOQNNTU2kpqaioqICvXv3ZmUOpyGMgGjorOPPnz/HhAkT+G7gb9y4gbdv3+LZs2cwMjLCokWLAFQtrsaNG4OiqGrJuoXB7Nmz4erqii5duiA/P5+lDAwYMAB2dnZYtGgRX7ZyrkJ17dq16N69Ox/vy/79+2FkZISAgABWqK2g/hUEcWWD5+UVevz4MQlvqKysxL179wQabQWVU51SJa62iKOc/9rCvS3igDjb8uTJEzg5OSE4OJh1ITNnzhy0bduWhKUVFhZi0qRJoCgKenp6nLMPN3Q5v0PGFBQU8NGm0NQOvEZb5u+ECYnkxdevXzFu3DhISEiQW2+mp62UlBTCwsJY+1NtipU459np06exfPlylvJfVlaGWbNmwc7ODkOHDhUYzSDsHvZvWf+87aXrd/XqVaipqbESyD179oxEJu3fv588K+yaFBcPZ0NDHGNPP0v/GxgYCIqiYGFhwWeYnTt3Llq3bl2n5GKCQPd1aWkphgwZAgsLC1AUBVNTU5axXpgxEcfBUNxr8sSJE2jXrh3Gjx/PekdRUREmTZoEJSUlxMbG8o1XbTKG9pYGqvq2tLQU3bt3x4IFCwBUGTulpaXJZdrPnz9J1ACv3K+Nt/R3ybE3b96gX79+aNasGaGKYHratmjRAj179sSwYcM4zbNx48ZBW1sby5Ytw6hRo1jeWYsWLYKBgQHi4+NZfKVc9srf0V+0Jx59+Qz8Q92kpaVFvKyZZQgjk/9N+jjvmqL//vz5M9q1awcbGxtitC0qKsK8efNAURSfflAbxNGWuLg4uLm5sT779u0bpk2bhp8/f+L48eNQU1PDypUr8e3bN7i5uYGiKJIAtLo+qQlfv36Fu7s7K3Hlt2/fkJaWBj09PUIdxrUtXHDr1i0MGDAAioqKdeKpP3v2LBQVFYn3JlB16SsvL48+ffpUS20mjHz5k/S+nz9/4saNG/D29oapqSmZv7XZRwTVaeXKlRg8eDCsrKzQtm1bDB06FKdPn0ZRURHCw8MxceJEAPxzKi0tDfLy8tW25dy5c2jfvj38/f1ZznmZmZno0aMHtm7dCmlpaVY0w5EjR1hOFcCfofc1NP5PGmyBf4ikb9y4gW/fvgH4h3Nv1KhRiIyMJIri+PHj4ePjAy8vL84Gx4bMOk4refQizMjIwNKlS1nPHD16FObm5kQAXb58GcnJyViwYIHIXigVFRXIyMhAy5YtoaOjQxRBWmkqLi7GwIED0bZtWxLCxuXdTCxZsgTGxsYYPHgwH1H67NmzISsrCxcXF5IITtA7BEEc2eCZv5k8eTIJsVBWVmZ5sdH0CJaWlnxecKmpqbUaUsSV2V4c5fzXFu5tEQfE3ZYnT57A19cX3t7eePLkCU6cOIGmTZvyHSzz8vKwdetWkT3rGrIccfQZU9bNmDEDTk5O0NDQQHR0NCuMijbazpkzh88IKUxIZHUKXm5uLiZMmACKoojRtry8HFu2bIGJiQlGjx5Nnv1T+gyo8kZp1KgRmjZtSg5kzEQjs2bNgoODA3r27Cl0dvrf1RZxQdAF75UrV6CmpobAwEDSfw8ePMDcuXM5Hw7ExcMpDohz7JmGpaFDh6Jly5ZYvHgxa52fOHECBgYGAj0H6wq6/ysqKvD161ecOHECd+/e5eSNLo6DIdDw48Jbp9zcXIwZMwb29vZITk5mve/du3do3bo1lJWVCQ2NMGtl+vTpMDc3x6lTp8hnlZWVCAkJQWZmJg4dOgRpaWmSMLG0tBRr165lZbYHhNMtAfHrVpzu3gAApUBJREFUysy/3717h6ioKEhISBCjbUFBAVJTU6Gjo4Pk5GTym9rmGfP7+Ph4tG7dGioqKnx7/eLFi2FgYIDExEQSKk9DmL3yd8n9devWoVGjRqy8K3///Tc8PDwgISEhkmz8N+njNHbu3EnO/PR7Pn36hHbt2sHOzo6M+Y8fP7Bq1SrO+5i42kLvt8+fPye2C/rfyMhIjBw5kjwzZMgQ2NvbIyAgAJWVlUK1hfeZHz9+oG3btpg0aRLr87y8PHh7exNdj1eW1/eF85UrVzBz5sw6GejOnz+P1q1bE6oCus5bt24FRVGIiYkRSE0jDBpy/KuLwK0O2dnZ6NatG7y9vTlTRTHfP3v2bOjr65MzxdKlS9GnTx9ISkpi7NixsLe3h5qaGh/9Dh0lUdOFIO3k4eDgAB8fH2K0vXnzJuTl5UFRFJYtW0ae//nzJ3x9fdG/f3+h1+S/Bf+nDLbz5s3DkSNHyN8HDhyAgoICli9fTiz1JSUlcHV1RUREBICqyREaGorNmzeT3/0J2c3Hjh2LTp06EQPfhw8fEBISAhsbGyIkAGDDhg1o1qwZTp48iSdPniAwMJBVjjDKtKD2lpaWYvv27ZCSkmKRQNNC4efPn5g1axYnocos59y5c+T/6enpsLCw4MvmuHbtWnh6eiIpKUloQ7q4ss4zMXnyZKiqquLw4cN4//49unTpwsfFcv/+faioqKB///7ks4yMDEhLS9d4MyWOtoijnP/aUrc51lD4nW158uQJ/Pz8YGFhAUlJSWzatAlA9ZlmRb2Aqu9yfkefJScnQ01NDStWrMDp06ehrKyMzp07E4of4B96hI0bN5LPVq5cKdBAXR3mz5/PF4727ds3YrSl311WVobDhw8LHfEg7j778OEDFixYAAUFBZKcBQDLe3r8+PEYNGgQ50vaf9P6p0F7jfCG2wPA8ePH0aRJE/Tv358vcY8ofHUNycPZ0BD32G/evBnOzs4svbZXr15o164dUlJS8OjRIzx58oRkvm6oA44wxvTqII6DoTjGhdkHa9asQWZmJoCq6L2EhATY2tqyDIxPnz5F7969sWHDBk4yZu/evQgMDIS3tzehIwOAHj16QFdXF/Ly8qyEmB8+fICHhwfr0Lt582ZISUnVaEj5HXJs8eLFJO8G02gbGRkJSUlJ4lWXl5eHXbt2kflV27wW1L9Tp05FkyZNMHLkSHz69In13dKlSyEvL8/qs9TUVEhJSf3WOVYb0tPT+Yy2z549Q2xsLKez2L9JH2fi48ePoCgKAQEB5EKLnjsvXrxAy5Yt0blzZz7nIGH2MXG0ZfXq1bh9+zb5e/PmzZCQkMDhw4dJHX/+/AkzMzNyLi8qKkLXrl1ZzlO1rZf79++TiM/k5GQcPXoUFRUV6NOnD7p3745Xr16xnh86dCg6d+7MWmcZGRk1ymRBa5KrEVZUo+2VK1fQokULcglEG7rz8vLQqlUrNGrUCHPnzuX0zoYef+Yc5I1crgnXr1/nTOXF+/u+ffsKvLA/duwYBg0aBDs7O1AUhQkTJrDOTZ8/f2bZcnjBjAxft24d7O3tERISQi5U9u7dC4qiMHr0aOzbtw/Z2dnw9PSEiYkJ54uUfwP+zxhsb926BV1dXXTr1g3nz58nn/fv3x/6+vpIS0sjAjw9PR2NGzdGQEAALCwsOE+Ohs46XlFRgZUrV5LJTdf7zp076N+/P+zt7VnGwM6dO4OiKGhra8PMzIxTpkamUL106RJ2796Na9euEQVn48aNaNq0KcuTijf7IddwuOTkZOjo6LCM5GvWrIGFhQWioqKIt0VoaChSU1PJmAiTYEgcWeeZuHXrFtzc3IjhZP/+/VBQUICvry8aN26MtWvXkmdfvHjB6qtJkyZVyycprraIo5z/2lK3OdZQ+BPa8uTJE7i7u6Njx464fPky+by+N+n6Kud39Fl2djYMDQ2JYnT58mU0bdoU6urqsLe3Z2WE3rZtG9nLPn/+jOjo6BqNtcz25+fnIyIiAi1atMDhw4dZz338+BHOzs6gKIp4dtGoTf6LY78UhG/fvmHu3Llo0qQJUlJSyOdMrjph9xZxtUVcYLaXPszs3LkTcnJyfMlK3r59C319fVAUhbi4OM5lMedYQ/JwNjR+x9hnZmbCxcUFISEhrD6ijZzKysro2rUrQkNDyTgKM5dreqam7+oilxvqYCiOcWG2OzExEWpqali8eDFJvpiXl4fExERYWVmhe/fuOHz4MLy8vNC9e3fy29rk5F9//UX+n52djYCAAHh5eRGjw7dv32Bubg59fX3k5+cjPz8fnz9/hp+fH+zt7cn7y8vLMX/+fD4ZLu4+4+23L1++wMXFBcrKyoTygf7++fPnMDIyQosWLViXkHR7agJzvqamppJkP0DVWUNLSwvz58/noxLauXMnefebN28QHh5eLZ/knyT309PTISEhwaJHoCHMWezfpI/z0kUBVXJGXV0dwcHBrMu979+/E/kSHR1dYx/9jracO3cOjRs3RmxsLMvz29PTE5qamjhy5Ag5e0+fPh2ampoYMGAAHBwcWDkEapLRFRUVePz4MSiKwvz58xETE4MWLVoQA/ahQ4cgLy+P+Ph4UofCwkI4OTmx9v7i4mIsXbq02vMrc1zevXsntPc3c/7S4ykqBg4cCAUFBRaH6+fPnzFkyBDs2LGDkzG4ocd///79hMt7xIgRCAoKqnUfF3UvZr5327ZtMDMzg76+PvFG5rWFFRYW4uPHj+jVqxdMTU2FvkRjfr9w4UJ0794denp6oCgKgYGBRB5v2rQJhoaGUFVVhZ2dHYKDg/+oxLLixP8Zgy1QpfTZ2dkhIiKCKDkAMGDAAOjp6SEtLQ0FBQUoKSnBhg0bEBERgdGjR3OaHOLKbl5RUYHNmzfDw8MDgYGBxNP27t276NOnD+zt7VnCICsrCydOnBA5K3BSUhL09PRgYGCATp06wdHREXfv3gUAbNmyBVJSUhgzZgyndwrChAkToKKiglOnThEOSRqbN2+Gu7s7pKWloa+vDyMjI6EN6eIaF168fPkSS5YsQUVFBU6ePAk1NTVCW+Hj4wMZGRksWbKE9ZvaDOriaos4yvmvLXWfYw2BP6ktT58+ha+vL3x9fVmXbfWNupbzu/rs2rVrxEh65MgRtGzZEhs3bsSHDx8gIyODwMBAPt5HuryavBGZ9aBl8atXrzBkyBDIycnxJVwZMmQITE1N4ejoKHTYXUP3GbMOK1aswJgxYxAZGYkrV66gqKgIJSUlmDt3LuTk5FgHXOb+KKzi+yetmbqAWf7KlSuxdOlSYnjas2cPWrRowTLaFhQUYPDgwbh+/TonBVqcPJwNDXGMfXXfZWdnw8PDA0FBQSxj1tChQ6GqqoqVK1cS/ZD3Mr22crZs2YI5c+Zg4sSJuHz5co1rgfndrVu3iJeMMOU01MFQ3GtywYIFUFZWxq1bt8hntD5XVFSElStXwsTEBHp6evDw8CDf1SZjNm3ahC5durB0w4MHDxKjLX2YP3/+PDQ0NKCrq0t0dUtLSz7e9T+hz5jf0/vQgwcP0KVLF2hoaJDzBY2IiAhoaWnByclJqD7jRXx8PLS0tDBhwgSSRwKoilZs3bo15s+fT+QcE8xLAUH4E+X+unXrQFEUyyFEGPyb9HHmd0uWLMH48eOJZ+jNmzehrKzMMtqWlpYiJiYGjx8/5mysE9f4b9u2DVpaWoiNjcWdO3fI576+vlBVVSWRFi9fvsT06dPh6emJ/v37czZwpaeno0mTJmjevDnRhen67dixA2pqarC3t4eLiwvs7e1ZZ3Eawuw1EyZMgJ6eHtq0aQNLS0scO3aMlQyeCd5omilTpnDyNOXFixcvEBISAikpKSxcuBBpaWnw9PQk+ivw59h8XF1doaCggLCwMCgoKLB0p+rAy5krKB9DTXj79i3evn0LPz8/NGvWjJW0jvlu+v/FxcVQVVUl7RQWc+fOhYyMDLKysnD9+nVMmjQJFhYW8PPzI/L4w4cP+Pvvv/HhwwdS3p+QWFbc+D9hsGUqOVu2bIGtrS26du3KupEfMGAAdHV1sXLlSoGHAmEmx6lTDZ91nFmnw4cPY8SIEWjSpAnCw8PJgrx79y769u3LZ7SlwfVWIjU1FaqqqkRwT5gwAU2bNiUH9oqKCmzZsgUURWHx4sWc3s3EixcvYGZmRjwsvn37hgcPHmDGjBm4evUqgCpPuAMHDmDDhg0sj4GaII5xqaysrFbg0pws/fr1w+DBg8m7oqKiYGRkxNogaoM42iKucv5rC/e2iAN/YluePHmCgIAAWFlZsRTV+oao5YirzwTJmB8/fuDDhw8oLCyEh4cHpkyZgsrKSpSXl8PKygoSEhJ8no9cQkinTp2Kfv36ERn87NkzDBo0CPLy8uSAUFxcjO7du+PAgQPk3bWV0dB9xmxDYmIi5OXlERoaCnNzc6iqqmLSpEn4/Pkzfv78ifnz50NRUZGVaZsL/sQ1U1ckJCRARUUF69evx5s3bwBU1XHPnj2QlpaGn58fFi5cCE9PTzg7O3M65Iibh7MhIe6xz8zMZHH2A1XOCB4eHvDz82P1affu3WFgYICMjAzOB7aEhASoqqoiKioKDg4O6NixI2bPni3wWeZaX7p0KYyMjIT2FGyog6G4x6W8vBz9+vUj5b148QI7d+6Es7MzhgwZQrK3//z5E8+ePeN08Pz+/TuRZ0zP2EOHDsHf3x+enp6s9y9btgxLlixheYn+KWcYgC2bZ86cieHDhxMjxJ07dxASEgINDQ3i2ffr1y/06NED2dnZInmObdiwAcrKyqx1w6zn2LFjoaOjg8mTJ7MS2TD7QBD+ZLl/8OBBTkaNf5M+zkR8fDxUVFSwceNGFpXKjRs3oKysDCsrK4wePRru7u6wtLQkc/NPagvThpGeng4tLS2MHj2aRd3g6+sLFRUVVqQFVxsG/XxWVhYkJSWJpy3vxf6lS5ewfPlyDBo0CLNmzRI6twOzPps2bYKCggI2btyIPXv2IDQ0FOrq6li7di2fsZc3mkZCQqJeomm+fPmC5ORkGBoawszMDL6+vkJfogENP/7MOrRu3RqSkpKs5FvC/G7JkiUwNDTEy5cva/zNjh07CJ3m6NGjERAQAKDKGzggIAD29vbYunWrwDLoNtjZ2VVLASEIRUVFCAgIYPEil5eXIyMjA3p6eggJCRHoVPK7nRp+F/71BlvmpJo0aRIGDhwIHR0dwmPDVG6jo6PRvn17LFiwgOVuL6yCIK7s5kBVqKCxsTGGDh0KR0dHqKmpISgoiEzue/fuoX///mjXrh3h0uKKiooKlJeXIzIykoSM7t+/HzIyMli5ciWAqgVHl3ns2LE63Xo8fPgQMjIyOHv2LK5cuYLBgwfD2NgYqqqq0NbWZoX20hBmsxPnuABVXg7Z2dksrqH8/HxYWFgQDrOysjKEhobi4sWLQhs4xNkWcZTzX1tEn2MNiT+1LQ8fPkRcXFyDb9ailCOOPqNDmoEqb+D379+zsqrm5ubC1NSU0OEUFxdj0KBBuHDhgsiHwsTERKioqGDbtm2ssLVXr15h0KBBoCgKPj4+MDY2Fjrsjoa45tm3b9/QrVs3XLlyhXw2bdo0GBsbY86cOQCqko6kpKTA29tbJIPAn7pmREVaWho0NDRYiesqKiqI0e/KlSswNzeHg4MD/Pz8OB1yAPHxcIoD4hz7Bw8eQEdHB3369OG7UDpy5Ajk5eXh5+fHCkXt378/VFRUsGnTJqHHZ/fu3WjdujUxcG3fvh0SEhIC+5r5zrS0NMjJyWH79u3VvltcB0Nxr8mKigq4urqiU6dOyMjIgKenJ7y8vNCjRw9YW1sjIiKCJcPp39QGZvsvXrwINTU1Vt4IptFWEHUIILyBS9x9lpiYCGVlZWzevBnv378nnz948ADBwcGQkJBAr169YG5uDisrK1aCOy5ISkpCZGQkAFT7jkGDBqFLly6c5H9D95eoug7vmvmT9mNxzrH169dDU1OTbx+jLyA/fPiAwMBA+Pv7o2vXriw6pD+lLcyxmzZtGiZMmABFRUU0btwYgwYNYoX0+/n5QV1dHfv372cZeUXRacrLy7FmzRpQFIXp06fXeuHHRcfcuXMnli5ditWrV7M+HzJkCFRUVFiUKLz7S0NE03z9+hU/fvzg7L3ZkONPz8GKigr8+PED9vb2sLW1haamJo4ePUp+y5yrTBov4J9EnMz9VBBKS0uRnJwMiqLg7+8PaWlplv3i2bNn8PPzg7u7e7VcyJmZmaAoCjk5OTWWxYuAgACSM4qJXr16gaIo2NnZ8V2i/V/Fv95gS2Px4sWQlZXFmTNnkJOTg+3bt6NDhw4ICwsjfGkAEBYWhm7duonM/yGO7OZnzpxhebwCVZ4m1tbWCA4OJpP75s2bmDZtmsiHdfp3vXv3xpYtW3DkyBGW10tZWRnWrl2LTZs2cb7Jqw7du3eHjIwMWrRogREjRhBjs6GhIaZOnSryextqXCZNmsTiCx45ciTU1dUhJyeHDh06wMfHh/TjmDFj0LRpU8TExMDKyooT34s42vI7yvmvLX+esQb489sirhtWrkbbhuizlJQUcsAAqryBtLW10aZNG+jp6WHnzp0oKSlBbm4uDA0NERISgsWLF8Pb2xuWlpacPB+ZyMzMhKamJlHcKisr8enTJ9y8eRNFRUUAqjyXoqOjMXbsWNIOLuU09DxLS0uDgoICzM3N+TJ+jx8/HioqKuTCMT8/n9PlmbjbIk7ExsaiX79+AKralZGRARsbG1hbWxMex9LSUs6HHHHycIoTDTX2gubjunXrYGNjg/79+7MOVQDg4OAALS0tjBs3jnVgHzx4MJ49eyZ0exYtWoTOnTsDqDLWysrKEu7PoqIiYizmepgW98Gwocalun2BjhLT0dHB1KlTCR/6smXL4O7uzmewrQ285eTm5mL27NkwMTHB8OHDyeeHDh1CYGAgfHx8BHIAc4G45NjOnTv5qA9yc3Px5MkTEiEyc+ZMREREIDY2VmhjmqDve/XqBWdnZ/I3PZ9+/frFoscTRf6LY46dPXsW+/btw+fPn2ultWD+jjc51O9qy+8qJzk5GYGBgQCqEmcuW7YMxsbGaNWqFaGiKysrq9P5VVxtmTNnDuTk5HD8+HGcPXsWS5cuhYyMDIYOHcoy2lpbWyMoKIjTu5ng1d+WLl0KiqIwe/Zsoiv16tWL5ezGBTk5OVBVVSXeuwBYyUptbGzQp08fAPzUR7VF03DV2wTlKOCqJzfE+DPrc/DgQZZnuLe3N9TV1VlGWwB8VBL0fszlQtvY2BgURWHatGkAqvqC7o9nz57B398fXl5erMT2NAoKCvD8+XOh2sT8bPLkybCxscHFixdZfT9//nx4eXkhMTHx/6xHLS/+zxhsu3fvjv79+7M+y8zMhLq6OgIDA1lGW3py1MVo25DZzffv3w9FRUXWIb64uBizZs2ClJQUunfvzscfJowQokOqgKowWJpLbvjw4VBWVoasrCzLOPnlyxd4eHhwzqZYE0pLS3Ho0CGWNxRQxeHCTBYgCup7XD5+/AhbW1t4eHhg+/btJPnP+fPn8fDhQ+zatQtGRkYwMzMjc2rChAkICAhAVFRUnUKiGnqOibOc/9ryZ+Lf1BZxob777OLFi+jQoQO8vb3x7ds3ZGdnQ1lZGfv27cPu3bsRFxeHRo0aEcX3+vXrMDExgY2NDby9vTl7PjKxZ88e2NnZEWqalJQUYiR2c3Mj3r11vaxryHl27do1ODg4oFmzZoRXkg63+/HjBxQUFPgSydQlcdL/+pqh65iUlAR7e3uMGTMGnTp1QmhoKIYOHYqBAweiTZs2ePfuncDf1QRx8nD+DtT32DPXVVFREetQu2nTJlhYWLCMtrm5uYiOjsaWLVvIb4VJMCvoMDR9+nQMGTIEFy9ehLS0NEv32rBhA6ZPn86KQuNKTdGQB0NeNOS4HDp0CEuXLsWePXuI0aS4uJiVf6GsrAy+vr7kAkRYMMtZu3Yttm7disLCQuTl5WHu3LkwMjJiGW0PHz4MOzs7jBw5klM5giAOOZaRkQFXV1eUl5cjJycHs2bNQps2bWBoaIjw8HDyTuYc5lLO6tWridfb/PnzYWBggNOnT7Pe9/HjRzg6OrL42EW9rGuo/oqPj4eysjIUFBTQtm1bVoJs3nfzXqDY2NgIndBJHG0RVzn075cvXw4DAwP0798fJiYm6NatG5KTk5GSkgJJSUk+OfKnnvkrKirg6+vLR221ceNGSEpKYujQobh//z7r+bqCWe9ly5ZBQkICERERsLW1ha6uLqfk5UwUFRVhx44dMDQ0hIODA/mcfl+/fv3Qu3dv1m9WrFhR6/7CbDOtmwoyyPKipjUkLOpz/JnPJyUlwcDAAKmpqaw9xdPTE61atUJmZia+fPmCoKAgYuQGhDfW8iaXjYmJQVRUFCiKIntvRUUFGZtnz57Bzs4Ow4YNq/G9NZVz4sQJnDhxgujj3759Q8eOHeHs7Ew4jAsL/197dx5XU/7/AfxzJERRiCiSVFqU0qqdtEoUZqzZ97JlS7ax77uSJbux72Mb+75vo5IQssSkItGk+/r90e+e7z3d0E3Lrd7Px2Meo7uec885n/M57/P5vN/p6NChA+bOnZuvbVhelPmArXgj9+nTB506dQIgPIhmzJgBFRUVtGnTBjdu3JB6X0EVVtXxvHJ43blzB4aGhlKFZN69ewcdHR2oqanxDXt+vy8pKQm1atVCmzZtMHz4cFSrVo2/852VlYU2bdqgfv36SExMxPv37/H69Wt4enrCxsamyC46P3/+jNjYWLRt2xampqaF8j2FvV2ePHmCtm3bwtfXF4MGDRI0ZNnZ2bh58yYMDQ0xaNAg/nHJC69fWafCWhd5+B5aF/lUltaluBT2b7Zr1y44OzvD3d0d48eP54OzYosWLQLHcXzKmJSUFKSmpv5ycv6DBw+ifv368PX1hYaGBgIDAxEeHo6dO3dCV1dXcJPzVxXVfiYSiXD37l2YmpqiefPmghuZCQkJaNiwoVTV8V9VFo6Z27dvo3///jA3N8fixYv5KYo7duxAq1atvlsY5EeKKw9nSSqsbS/Z/5w3bx5at24Ne3t7/P7770hKSgKQU4DG1tYWzs7OGDNmDNzc3GBvb1/gC5yzZ8/y09KvXr2KChUqgOM47Ny5k39NRkYGPDw8BFPyDx8+jFq1aknd+Pje+hTlheH3FEV/fOzYsWjYsCFatGiBli1bwtXVVVAXIy0tDTt37oSPjw9MTEwKfPNMnEs4IiKCD74lJyfzQdvg4GD+tVeuXCm0C9uibseioqLQoEED/Pbbb2jUqBG6d++OBQsWYPXq1WjcuLFUnub8EolESE5OhrKyMh+w+Pz5M5o1awYbGxvs3bsXSUlJiI+P51NwFEYe2aLYx06fPg0rKyucO3cOb9++Rf/+/WFiYoL58+fzox3zGhUcEREBZWXlAk8dLyv98fj4eMyYMQOurq5YtWoVn1f73LlzcHBw4NvSwlBU65Kdnc1fg4tvxmRmZvKfO2zYMKiqqqJ3796CAHRhB223bNmCvn37YtCgQQWquSPp06dP2LNnDzQ0NODp6QkgJ2ArEolgY2PDFzUVf//AgQN/eH6RNGPGDFhbW6NVq1ZYtGgRPxssr2WVXL/w8PA80y7mV2Fv/+nTp0NdXR0XLlzIs9/j5eWFunXrwsDAAM2aNeO3yd69e1GlSpWfHvuS22bfvn24dOkSP5hBnL4h9w3T169fIyUlpcD71pgxY1CjRg3o6OhASUmJT3v1/v17WFtbw9TUFNra2jA1NYWBgYHc3pwvKWUuYPu9HSkiIgIKCgqCUaRATkJmR0dHBAUFFXoE/1erjucepi++SMrIyECrVq3g5OQkyM3z7NkzdOjQATt27CjQukRHR0NJSQnVqlXjp7yJp3Ddv38fpqamqFevHho1agQbGxtYWVkVWeL87Oxs7N27F46OjnBxcSnU7ymsqvPi31g8IqR69epwd3eXel1YWBjs7e35E4dYYTRChbUu8vA9tC7yqSytS3EpjN9Msn3YuXMn3N3doaysjBkzZgD4XwcXANq3b4+AgABkZmZK5bT6FVu2bMHEiRPx559/8hc3r1+/hpmZGS5duvRLn53br/xmed3YlHT37l0YGRnB2NgYa9aswd69e+Ht7S1IS1OYSvMxI/79MjMzBaMos7Ky0LZtW5nzPEp+JlD0eThLWmFu+4kTJ6J27dqYPXs2pk6dCmNjYzRq1IgvAHj06FEMHjwYtra2+P3332UKCkq2DX///TcMDAwwYcIEvHv3DkBOWgQlJSXMnz8fMTExuHr1Kjw8PGBmZia4gIyLixMEKn/0PcV1YZiXwtwuixcvRoMGDfg2cNasWahUqRKaNWvGTxWOi4tD9+7dERAQUOBp0Bs3boSGhgZu3bolFZj7999/MW/ePDRr1gw9e/YUvK+wfreibscWL16MwYMHCwobPnr0CGZmZjIV/cxrVqSzs7NgZPinT5/g6uoKY2NjVKlSBebm5oV+DVOYv9eWLVswYsQIjBkzRvB4UFAQTExMBMWgJJe9sPJ8lqX+uPg6ViQS4cuXL/Dx8YGnp2ehB4IKY12+d+xOmTIF1apV44Oy4m0+adIkWFtbIyAgoEDHfXp6+g+fl/yNJIuByTITYefOnZg9ezbmzp3Lp+ZJT0/ng7b6+vrw9PREt27doK+vn2d+1vws35o1a1CzZk0sW7YM7du3h52dHfr06cOvo+TnSb4vMjISHMflOyj8PYXV73/9+jVsbGz45UlMTMTZs2cxdOhQQeHPP//8U5BmQfxayboA3/sOsXHjxkFTUxObNm3iRyanp6fzhdIiIiLw77//ws/PTzDyWdZtExMTAyMjI9y4cQN3797FrFmzBLMDP378iL/++gvz58/HypUrC5RirawrUwFbyR1o//79WLt2LebMmcMHOvv164caNWrgyJEjePnyJT59+oR27dph1apVRTbsuqBVxyWXY+7cuejQoQN0dHQQFhaGmJgYfPjwAQYGBnBwcMDUqVOxb98+tGrVCm3btpWpyqWkW7duoUaNGqhVqxZ8fHzyPJlt3boV69atw+HDh2Ua9SL5WT87QYi9fPlS5u/Jr1+pOp/XHe1nz56hXbt2qF+/vlQi9Y0bN8LIyIi/ECpsv7Iu8vY9tC7yqSytS3EpjDZGsg3fsWMHnx9RPCVd/PyAAQPQvn37An1HXvIK+n779g2pqanw9vaGg4NDkXSkCvKbfa8Tntvdu3dhaWkJjuMwdOhQTJ06lZ/tIC/rIo8+fvyIPXv2wMPDA6ampjKPFCyJPJwlrTC2/bNnz6Cvry+ohv3t2ze0atVKULjk27dvghFXsvbHVq5cibFjx6JWrVpQU1PDpEmT8OHDB6Snp2P+/PmoXr066tWrh+bNm8PDw0OQmuJn+0BxXRjmV2Fslw8fPqBjx4786KBDhw6hevXqGD16NNzc3GBsbIwrV64AyJlyn9/++LVr16ReM3bsWHTu3Bnfvn0TFKER+/jxIyZPnoxu3boV2ZTRomjHJNdTMjjz6dMn+Pj4wNXVtUDrIx5BCQA9evRA586dBc9/+fIFt2/fxpYtW3DmzBm5u7aQ5ObmBo7j4OnpKbV8wcHBMDMzw5QpU5CWlsY/Hh4eDlVV1UIrxCjP/fGMjAyZviM9PR07duxA69atYWZmJnOBsfz6ld9McllOnjyJ3bt3Y9OmTQByjhkvLy/Ur18fDx48wOfPn5GZmQk/Pz/s27cv3zGMv//+G48fPwaQc0MwIiIiX/0fyeteWdr9sWPHQltbG87OzvD09IS6ujo/0Ozz58/YvXs3zMzM0KBBA0E+a1mPydOnT2P8+PH8+TI7OxtLliyBra0tevXqxccdcqcpEN/gkDzP/orCOGYyMjLQsmVLDB8+HCdPnkTnzp1hZWWFVq1aQUFBAaGhoVLvkTxH5Nfs2bOhoaGBy5cvC35v8e/zxx9/gOM4GBsbw8jIqMBpMGbPno2QkBCEhIQIvkM8O3DRokV5vo+CtUJlKmArNmbMGGhra8PNzQ1WVlaoU6cO/v77b3z48AGDBw9G1apVoaOjw+dIK+ph179S3Tw0NBR169bFihUrsGPHDtSqVQuenp7Izs5GUlIS+vTpA3NzcxgaGsLNze2XT0IpKSm4c+cO6tevDw8PD6nnc3+urAfUkiVLEBERka/3Sm6PojhwC7JdJF+blJSE9PR0vsMknmLl6OiIJUuW4OvXr3jx4gVatWoFLy+vIh3W/yv7mLx9D62LfCpL61JcfrWNASAoVHPgwAFYWVnB3t6enx6blZUFBwcHmXIkigOV+V2ur1+/YsaMGWjTpo0gn2hJt8unTp3ic3tNmDABEyZM+OHrb9++zRfPEs94kLUQkCzk7Zjp1KkT1q1bJ9N7nj59ikGDBqFv374yjxQsyTycJU3WbZ+7f/DPP/+gVq1auH37NoD/jW5KS0tDgwYN+NoB+b1hkZdp06ahevXq2LVrF44fP44ePXpAX18fYWFh/Oi9hIQEXL9+HbGxsfx3yXoxXVwXhvlRGMfkvXv38OTJE9y/fx/a2tpYvnw5gJz+LcdxqFOnjqAOw8++a/To0XB1dRU8Js5bKS7+Jvk5WVlZ/EhlycJ/RdXOFHU79vnzZ8ydOxeenp4wNzcv0HVMeHg4ateujaZNm6Jly5Zwc3ODm5sbTp48iffv3wtmC0gq6XMY8P3jtkePHmjQoAE2bNggFaDs2bMnunfvzr937969qFSpUqEFa8XksT/u7++PiRMnCoLVP5OYmIipU6ciODi4yAt+/upvNnbsWOjp6cHc3BxmZmbQ19fH48ePER0dDX9/f36EuL6+vmBE6s/a/8TERLi4uMDGxgZ9+vRBxYoVBUHS75H8XMlcqj+zcuVKaGpq8ukmN23aBI7joKKiwqfU+vTpE3bt2gVdXV3BoANZjsvTp0/D2NgY9erVE4wu/fr1K5YuXQo7Ozv07t1bqg1YvXq1zIW58kOW7Z/Xaz5//oxJkybBxsYGioqKCAkJ4dM19O/fX5BisaA+ffoENzc3vlbR8+fPceLECXTv3h1jx47lt/O1a9ewb98+mW5uXbx4kU8/lpmZiUGDBoHjOL4AoJg4aKuoqIiZM2f+8jqVdWUuYLtx40bUrVuXL8Rw9OhRcBwnSCp/8uRJ7Ny5Exs2bBBUHS4OsjTg9+7dg6GhIT/d7Pr161BUVMSGDRsEn5eRkYGXL1/+Us5CkUgkWLZLly6hfv368Pb25j+vf//+CA8P519fEIGBgWjSpMlP3y+5LLJUNy4oWYf3T58+HXZ2djA2NoajoyO/jcQ5bZWUlGBgYAB/f3/BqJTiuHAvruAArYv8fUdxKUvrUlxk7bwtXboUnTt3RqtWrTB9+nQ+gLJ//36YmpqiZs2acHJyQs+ePWFsbJzvkY8jRoxA/fr1+Zkn+d2Wu3btwqRJk4r8YkfSj5YtLS0NWlpasLW1Rb9+/VC9enVB4Y3vuXv3LgwNDWFnZ5fv2R6FQR6OmYEDB6JKlSrYvn27TO97//49v18VJJhWUnk45cXP1kfyefGFzrdv39CoUSPBqJSsrCxkZGTA1taWL9hVECKRCB8+fICFhQUWL14seC4kJAQaGhqYNGlSnhfnsm6borww/FWybJe8LF26FO7u7nwwbfv27fDz88PChQtlvqYQH1dPnjzhg/Pr1q2Duro6Dhw4IHjt8+fP0alTJ0EqiuLK81dUx2Z4eDjGjBmT7/NLXjc4/vnnH6xevRpTpkyBu7s7OI6DjY0NatSoASMjI7Ru3ZovCFRcZNnHEhMT8e7dO7x//55/rH379jAxMcGWLVsE9S8k3/vt2zfs2LHjp1Ohf5W89MdnzJiBChUqYM6cOTIFbVNTU/l/F+VNIUmy/mbiGw/iHM4bN24Ex3F8UU4gp51ZtmwZlixZIvPU8TNnzkBTUxOVK1fGwYMHAeS/CNaqVatgZGQkVdQ8L8nJyQgODsbGjRsB5MxEUFFRwfz58xEQEABVVVX+ptbnz5+xZ88e6OnpSd24yo/U1FSMHz8edevWRa9evQTrk5mZieXLl0NXV5dPJwbk3FyrUaPGL6cO+ZkfbX/J527cuIFLly7xfVhxXEdczFLM0dEREydO/OXlSEtLg6urK4KDgxEVFYUOHTrA1dUVzs7OsLKyQs+ePQUpMID87WOpqalQUVGBu7s7XxwxOTkZYWFhUFBQ4HPiS+5X06ZNg4ODA+Wq/YkyF7CdPn06X3Drzz//RPXq1fkgo2RjLUleh13fu3cPFhYWAHJywCgrK/Pr8unTJxw5ckTqjlFBTqiSUxwOHjzI3226ePEiGjRogCZNmsDW1ha6uroFqtQpuVwPHz6EpaUl/vzzT6nX5PW+ZcuWQU1NDYmJiTKvV1GZMmUKatasiQ0bNmDhwoX47bffBHe2nzx5gg4dOkBLSwubNm0q8KgUQkj5NG7cONSuXRvDhw9HcHAwlJWV4ePjw3fm9u/fD2dnZ6iqquLYsWMytTG3b9+GqakpLCwsZA7aislLQC09PR3VqlVDtWrVBBc0P3Pv3j3UrVsXrVq1KsKlk0/jxo1DpUqV8h20/ZURnEDJ5+GUd5LruXDhQgwZMoSfMjp37ly0aNGCD3aKX29lZYX58+f/0vd++fIFNjY2/EWsZNvRqlUraGpqYvLkyfm6OJdUXBeGRU1yPcLDwzFs2DB06tQJ69ev568l5s+fDy0tLdy/fx/Z2dnw8/PD1KlT80xp8z2Sr9m+fTsqVqyIo0ePQiQS4fHjx/D394eDgwN27tyJb9++IT4+Hr6+vrCxsZGL3ym3vI7bHx3LebUpshQz+vTpk6DIptj58+ehpqaGW7du4ciRI1i7di2GDx8uV/1wyWWeMmUKbGxsULduXbRu3RorV67kn/Pz80OzZs2wbds2qZG28rgPFBXJ32vp0qXgOA6zZ8/OV9C2tJxPRo8ejdmzZwMAdu/ejerVq2P16tUA8N1in/nZB8Trf/v2bVhYWMDGxgZOTk6IjY397mdI/mYRERGoUaPGd/O85vX7XrlyBU+fPsXDhw+hq6uLFStWAMiJzXAcB47j+BkkX79+xbZt22BmZsbns87v9wA56WEmTpwIS0tLTJgwQbA+mZmZguKl79+/h4+PD7Zt2/bd7ylqkvvyxIkToa2tDT09PVSqVAnz5s0T3LT59OkTbt26xael+pU2bMOGDfw5fcGCBbCysoKKigomTZrE590NCgpC7969C/wdt27dgqamJtq2bcsHbdPS0jBixAgoKCjw6Sfyqj1BQdvvK3MB2549e6JPnz44e/YsVFRUBEnnZ86cicmTJ5fg0n1fXjvp7du3oaGhgcWLF0NVVVVwAj937hzatm3LV28uyPfknkaxd+9eVK1aVVAAIjExESEhIZgyZYpMd/K+d9CJqwz7+/v/9H0RERGoWbOmzKOBClPuhvH9+/ewsrLi7xoCOXdqQ0JCUKlSJT6gEhcXh9GjR+eZd4wQQsRyj4y9e/cuGjZsKBgtEx0djcaNGwvazQ0bNmDkyJEFamMePHiAZs2aoXnz5vkK2kq2+UWVizu/JJczISEBKioqqF+/PpycnAQd/Z8VIvvnn3+KZfaGPBozZky+graSv9uOHTuwdu3aH75eXvNwlgZjx46Furo6tm/fjqdPnwIAXrx4gZEjR0JfXx/t2rXD5MmT4eTkBCMjI5ku2r73u3bo0AEtWrTgg0DibTds2DBYWVmhRYsWP7y5/iPFcWFYHMTbZfr06RgwYAD09PTQtWtXfPv2DRcuXECbNm2grq4OQ0NDGBoa/nKKtTZt2qB+/fo4fvw4gJyZdf369UO1atVQv359GBgYwNraukjT0hSU5H729OlTxMXF5et9kusgvsD/HsnfdebMmfD19YWWlhZGjRrFjxgEcqZuGxgY8AGh731fSci9b0ybNg01a9bErl27sHr1aowaNQqKioqYNWsW/5qAgADUqVOH3y/KK8l9TJyC5GdBW8nfe8OGDb80O6Go+fj4IDQ0FCdPnhTEMEQiEebMmfPdfJ/fk7vtF6dROXnyJNzc3NCyZUs+aCuW+7cU53n9XuoAye9Yv369IFYB5NyIcnJy4o/tEydOYODAgVi4cKHgPPb169fvpi7J/T0nTpzAmjVrcPToUf58mZKSgnHjxsHa2loqaCv5GSKR6LsD+IqD5HJNnz4d9erV44tVBgcHQ1FREaGhoXxfe/v27fD394e7u/svtfvJyclQV1eHhYUF/zs/e/YMz549E7zO3d0dw4YNK8Ca/c+dO3dQp04d+Pr6SgVtFRUVsX//fqn3ULD2x0ptwPZ7HdBjx46hefPmqFixIp8rFci5KGjbti1Gjx5dXIuYb5LrIs6rJ9avXz9wHCfIzff161e0bdsW7du3L3BuxDlz5mDVqlX8QXvu3DmoqqoKfrO85OciQfJ7duzYgT59+iA5OZm/KLhx4wZq164tdcDmlQi8sHPLyKJz587o0aOHIMehOEAgXnbx6OS0tDQ4ODggNDRU6jcqzxehhJDvGzFiBCIjIwVTHW/evAlNTU3ExMQA+F9A9+7du1BUVMxzhENBOm/5DdrmrqY7cODAn15UFxXJ5bty5Qr/27x//x5NmjSBvb291GyM8t7+fi9w/bOgreRrw8PDUbVqVZw4ceK73yPveTjl2d9//w0dHR1BZWnx7/H69Wvs3LkTLi4uaNeuHfr27SvTRVvuY+b+/ft8IC0pKQlaWlrw9PTEv//+y/d1OnXqhOPHj6Ndu3awtLSUeX2K88KwKJ05cwZNmjThp+4ePHgQVapUEaQlu3XrFtasWYNFixbJNKjhR/u5uDiP+Hj79OkT7t27h02bNuHEiRPFmjYiP6ZOnYrXr1/zf48fPx7a2tqoW7cuvLy88Pz58+++V7KdWb9+PcaNG5evVDWhoaGoVasWXynd1tYWhoaGfEFOkUgEfX19Ptdz7u+SFykpKXB2dhbkFk9LS8PSpUtRrVo1wfk+NDS0xIPNJeV7NU0WL178w6Bt7vOYioqKILBfUr53/K9Zswa2trZQUlLiZ9QCOcUOfXx88McffxToO44dO4YDBw4ICnoeP34cbm5ucHR05IO23bp1E7RvERER+S5kFxISgoYNG2LOnDmCm+fh4eHgOA4JCQlISUlBu3btMHjwYP55WQtljh07Fo0aNYKxsTFatmwJDw8P/sZMSkoKxo8fj5YtW2Lo0KFy1Z/YsmULv++KZ1D4+vpi3759AIB9+/ZBTU0NPXv2BMdxCA0NRVpaGjIyMnDp0iWZZ+vm1d7FxMTAyMgI1tbWgn58amoqLl++DC8vL5iYmBTKuSWvoO3Hjx8xatQocByHc+fO/fJ3lCelMmAreQAeP34cO3fuFHRAe/bsCRMTE6xatQrp6em4e/cuvL29YWFhUeQFxn7FvHnz4Ovri8DAQJw/fx7Z2dl48OABfHx8UK9ePSxfvhyzZs2Cu7u7IGehrLkR3717B2dnZ9SuXRsbN25EVlYWHjx4UCh3PCRfv3r1agwcOBCWlpbQ0dHB4MGDcfbsWXz+/BmdOnXCpEmT8lx+WU4QRWnnzp1QUlJCcHCwIGjr6emJzp078w2QeJ09PDwEJyFCCPkRFxcXmJqaYuvWrXzQNi4uDpUrV8bWrVsB5LSP3759w9evX2Fqaio1eiE/vjdN9f79+zAxMflu0DZ3e16pUqVCq6YrK8nlmjBhAiwtLbF161b+Iu3Zs2fQ1dWFk5MTnj17hszMTHTt2rVcFzOQ/M0yMzOlRq+IZ4bkDtrmngqpqqr63amQkkpLHk55s379ehgbGwsuoH7Wr5P1giokJAT16tVDnTp14ODgwOfyvHXrFrS1tdGkSRM4OTnB3Nwcurq6AHJyFpqbm0ulLMitpC8MC0vuYNi+ffv4tGS7du2CiooKH0RJS0vDqVOnpJZf1hloUVFRGD16tGBkNZDTn1RXV8fx48fz/P3lJXD36tUrKCoqok2bNkhOTsaOHTugra2NnTt3YteuXTA2NoaZmVmeswFzn18UFRWl2om8xMbGwtzcHGfPngWQU3xSSUmJnx0o/r2cnJwwderUwljNQuHn5yd1jfD+/XvUrFlTKpd0cnIyfHx8MG7cOKltLS/bvrjknpGRe5bPwoUL8wza5jWlv6SvKwHhcl24cAHnzp3jbzQ8fvwYjo6OaNasGY4cOYKsrCw8fvwY3t7esLKyyld72bVrV8FI3OHDh0NVVRWNGzdGlSpV4OXlxQc4jx07xt8gsre3R4MGDfjz+O7du8FxXL5+s40bN0oVWxR79+4d3NzcwHEc9PX1BfELWS1cuBBaWlq4dOkSgJybRZUqVUKLFi1w9epVADlB28GDB6N///5y06fYvHkzdHR0MHHiRP74ffv2LTZv3swHZLW0tLBs2TIA/6s3MGTIEMENrF8JQIt/i5iYGBgYGMDOzo6vjXHy5Em4urqiXbt2hTp7I6+gbWpqKpYuXSpX5/7SoFQGbMXGjx+PatWqoUmTJlBUVOTzoyQkJKBHjx7Q0dGBiooKzM3N4eLiIpdTiMSWLl2KmjVrIjQ0FHp6erCxscHq1ashEonw6NEjjBo1Crq6unB3d8egQYMKXPhl1KhRaNmyJTp37gw9PT0oKSlhzZo1hXIXSrJhnDNnDgwMDPhcbMuXL0ePHj2gqKjI3/3S0NBAQkKC4DMOHz4MjuOKPBF4fh06dAiVK1dGUFAQH1BZvnw5bG1tMXnyZD6Qm5mZCScnJ7lNuUEIkR+S7W3Hjh35oiLioOmoUaPQsGFDQbHMjIwMGBsbC0biyPpd0dHRePToEV68eAEgp81+8OBBnkHbvGY8yEO7PGnSJH70We4ApDhoq6mpiebNm8PAwKDYiovIG8ntvmDBAnh6esLU1BTjxo0T5CUNCQlB5cqV+anvkvJbRbms5eEsLuJjbOXKlWjatKngJrD4v127dvFVtnO/Lz+fDeTMamrSpAmuXLmCvXv3YujQodDS0uJTO3358gV//PEHxo4di8mTJ/P9yh49esDX11dww1qW9SrOC8PCtHLlSjx48AB79+6Fj48P9u/fL5Vi7fDhwxg2bBjflhbE1KlTUaNGDbRu3RrKysro0aOHIBWOl5cX6tevjwMHDsjdbyQpNjYWjRo1Qtu2bRERESGYqZeWlgYzMzOYmpoKikLmDqbJcn6JjY1FkyZN8PnzZ+zdu1dQ3yMjIwNbtmzBhw8fcPLkSbkKCty5c0cq+C4SidCzZ0907txZagR6ly5d0KlTp2JcQvkjuZ/MnDkTjo6OqF+/Pvr168dfXwL/C9rOnTtXagZQfs9jxW38+PFQUVFBo0aNoKamxvf3Hjx4AHt7exgYGKB27dqwsrJCy5Yt89VefvjwAUFBQahRowYiIyORlJQEIyMj3Lx5E69fv0ZMTAyaNm0KR0dHPH78GEDOTbslS5YIZoh+/foVhw8fxqlTp/L8ntwzYkaOHIlevXoJHsuda3rLli3YunVrvmcIhIWFCYKVSUlJ8PX15UcAHzlyBCoqKhg+fDgcHBzQokULPhAtOWtHHoK2KSkpmDBhAuzs7ATpGsSpGUaMGIGuXbvy59rx48fD2dkZLVu2lCk+c/z4cUGu40WLFglmPol/i+joaOjo6KB169b88XLnzp0iqblz584d1K1bF35+flI58eWpfZZ3pSpgK3nwPX36FPb29rh06RL+/fdfzJkzBxzH8Tl/0tPT8eLFC+zfv58vCADIz86R+wAMDQ3lOytfv35F9+7dYW1tjfDwcH6ZxR1eMVnXRVyE7fbt20hPT0dmZiaGDBmCSpUqYd26dYVWMfvmzZvo2bOnYOqF2IkTJzBgwADY2tqC4zj+bpN42757904w4qYk5N42Bw4cQOXKlTF06FAAOftfaGgoLCwsYGpqioEDB8LW1lbmvHKEkPJJJBIJOt2SlaCzsrLw5MkT9O7dG2pqaggLC8PChQvh7u6OZs2ayXThnruoiYGBAZo0aQJ1dXXBtEBxeoQWLVpITSsMDw+Xm5Ep0dHRMDQ05AuMJScn4+7du1i8eDEOHz4MIOf8+ccffwimKJfndnnChAmoV68eZsyYgT///BOVKlVC37598ejRI/41Y8eOlapEvXr1aigpKRUoSF+a83CWhOjoaCgoKGDKlCmCx9PT0+Hn58cPRiiI9evXY9CgQQgLC+Mfe/z4MUaMGIH69evnmZf4xYsXGD58OGrVqvXdOgnyeGFYUJJ9vuXLl6NChQqIi4vDu3fvUKdOHXAcJ/idvnz5Ai8vL3Tv3l2mYID4e0QiEb5+/YrffvuN7+8eO3YMNjY26NSpkyBIYmlpibZt2/7qKhYJyXWPiYmBtrY2OI7j92Px82lpaWjevDnMzc1x584dqZuBsp5fYmJi0KxZMyxcuFCqvsfVq1fRsWNHXL9+nX9M3tqXJUuWwMbGhv973bp1aNq0KSZNmsSPsv706ROcnZ0xduzYklpMuRIWFgYNDQ2sWrUKZ8+ehbq6Otq1ayfI6StOj7B582b+sdWrV6Ny5cpycbNZcr+/f/8+zM3NcfHiRdy5cwdBQUGoVKkSP7PqzZs3uHHjBtavX4+LFy/KlAbl9evXCAsLQ/Xq1dGzZ0/07NkT2dnZfPvz9u1bNGjQAD169Mjz/T+biZzXLKwePXrA29tb6rVfvnzJsyDsz47Jf/75B/b29lLre/XqVTx9+hR37txBgwYN+GN/xowZ4DiOLwKZe/lKkvj3+vjxIyZMmAAbGxuMHz+e/w2+fv0Kb29vdO/enY+H+Pn58aOIJT/jR7Zu3QqO4xAREcHHc44fPw41NTVB/QvxZ4lzQBsZGQnO5UWRRuLu3bvgOI7as19QagK2kjvQhw8fEBcXJ9jhgf/dYZszZ06euWzkJZeJZAPy119/4dChQ+jdu7fg4ExLS0OPHj1ga2uL5cuX53lXVlYrV66ElZUVvnz5Ivgt+vXrhxo1amDTpk0FCtpKftaff/7Jj2wS52DM3finp6fj7du36NatG8zMzAQ5XeRJQkICf0F58OBBVK5cGYMGDeKfP3LkCIKDg9GlSxeMGTNGpvxlhJDySbKdkxyd1b59exgZGWHbtm0QiUR48+YNFixYAH19fbi4uOC3334rcIBrypQpqFu3Lo4ePYrXr1/D398fVatWFQQh/vnnH9SpU4cfJQHkTNdVVlaWi2AtkPN7mZmZYcOGDbh8+TL69u0LY2NjmJiYQFFRkZ/mLak8t8eHDh2Cvr4+Ll++DAC4ePEiFBUVUalSJfj4+AiCtitWrODPYS9evICXl9dPL3LLUh7OkiaeEh4cHIwTJ07g7NmzcHd3/6Wq0K9evYK/vz9q1Kgh6LsAQHx8PEaOHImGDRsKAsJv377FypUr0bx5c9y9ezfPz5XnC0NZ5Z6eHBERgR07dvCPnTt3DrVr18bvv/+OAwcOYN++fWjTpg2aNWsmU4o1ye8R5xHu1auXIPerOGjbuXNnwUhbefidcpNcJnEg/tGjRzA0NIS1tbUglyyQE6yoV68eevbsyb9v3bp1BT6/9OnTBxzHCVIefP78GT4+PvDx8ZHL3wzI+T3OnDmDOnXqwNPTk398/vz5/EyXdu3awcbGBsbGxtQ+ImdUvqGhIX9z4+rVq6hcuTLq1auHli1bCm5w/Pnnn/xv9u7dO/Tr108ugrWS++PXr1/x4MEDqRmZo0ePhqKi4nfzyv+sLyPZDr169QqTJ0+Gmpoa7Ozs+MfFM0V37tyJunXr4vnz5zL1kU6dOoW3b98CyLkZPH78eADAH3/8AS0tLdy+fVuwHO/evUPbtm1x9OjRfH9H7nZ1z549UqOmxSkkxeuzYcMG+Pr6Yvbs2XLZ58sraCs50nblypXgOA4+Pj5o1qyZ4NiXJTYyceJEVKpUCeHh4XzdIPENDj8/P8Frt23bhv79+yMwMLBYfrPHjx/L5bYpLUpNwFZs4sSJsLGxgaqqKpo3by5VhXTRokWoWLEiJk2aVGgjRguT5IE3YsQIqKmpoWbNmuA4Dn379hU8//HjRwQGBqJJkyaFcsG8bNky1KhRgx9yL27orl27hgoVKqBWrVr8ia0gnZ3ExEQkJibCy8sLVapUwfz58/nn8ip88uXLF9StW1eQ4LwkSa7ztm3boKamhhMnTvwwaAsI1406V4SQ75FsY7Zs2YKAgADBSCDJoK24nf706ZPgfbK2MXfu3IGrqys/EuXAgQNQU1ODp6cnFBQUBCkWnj59KuhQTZ48ucQKdOR1Dnr79i3atWsHKysrKCgoICgoCIcPH0ZycjJatWolKDBT3olEIvz111/8CJSjR49CTU0NW7duxd27d1GlShX06tVLME0Z+N9Fofii7EefL1ba83DKA5FIhP3796Nhw4bQ1NSEsbGxzFWh87qwu3r1Krp27YoaNWrg0KFDgufi4+PRp08f+Pn5Cd6bnJwsNXUxN3m+MMwvyXW+du0aOI4Dx3GIioriH//27RvOnTsHExMT6OjowMrKCp06dSrwzbPRo0ejXr16qFKlClRUVKRygh8/fhz29vZo3bq1YMq3PAUgJZdl8eLFGDFiBD9AIzY2Fg0bNoSbmxuSkpIA/O93/vz5M/97iWf45VU7Iz/fnZycDD8/P6ipqWHKlCmYMGECWrduLXN9j6J2/vx5HDt2DAAwePBgzJ07FyKRCJcuXYKmpibc3Nz41x47dgyLFi1CYGAg/vjjD5oh8v9u3LjBp7w4duwYatasic2bN+PNmzdQUVFB27ZtpfYj8X6We2ZqSZs6dSo8PDzQoEEDtG7dWiofb0hICKpWrSpog/Ijr339xYsXmDRpEjiO43Ojiu3evRsGBgb8MZofaWlp0NLSgq2tLfr164fq1asLRrNaWlrCyMgIp0+fxsuXL/H8+XN4eXmhZcuW+W4nu3fvjm3btvH9hcTERHAch4CAAMFAvKlTp0JHRwdPnz6FSCRC+/btBfUK5Ok8I5ZX0HbcuHH88R0ZGYm+ffti1KhRMg8Ak0xbFBoaCiUlJaxdu5YvZC++SdSuXTs8ffqUH7gxZ84c/n35+S7x98iabiL3qGx5aJtLG7kP2OYOomloaGDp0qUICgpC1apVMXbsWKkKpNOmTYO9vb3cjdiU9PjxY3h4eODmzZv8SIcWLVpg0qRJguVOTU3FH3/8IVPjI/mbSf47LS0Npqam8PHxEVw83bt3D2PHjkW/fv1Qu3btfDfgO3fu5JP8jxw5Ej4+PgByRqb6+PigZcuWgjuFeVX5tLW1lfnEVBQkf6cdO3Zgw4YN4DgOzZs3FxSWEFcJDgoK4htCQgj5mdzV2rt06YLatWujR48efN4t4H/pEbZu3SoYjQYUbBbCs2fPsGzZMmRnZ+P06dPQ0NDA8uXLAeQE1FRUVKQ68yWd91Xyt4qLi8PTp0/5AOLLly9x4cIFXLlyRfAeGxsbLF26tFiXU57k1YFOSUnBixcvkJKSAnt7ez5l1Pv376GnpweO4xASEpLn5+RXWcnDKS/ev3+P+Ph4xMXFyZQ2QPKYyf07X79+Hd26dYOJiYkgLzaQc0GcV87B7ymuC8Oidvr0aX5E/qBBg9CnTx9ERUWhZs2a6N+/P/868fGQkZGBly9f4v379/xjslY3v379OvT09HDq1ClERUXBxcUFjo6OUunDDhw4gAEDBsj9Re3YsWOhrq6OzZs3C27UxMbGokGDBmjTpg0fkJL8HQorFUpGRgbGjh2L1q1bw9vbWxDoKOkgp0gkwrt372BjYwNfX1906tQJSkpKglHrFy9elAra5lbS61Hc8trnP336hDdv3iA9PR2tW7fGtGnT+LRSlpaWqFixIkaNGiV4j7xc/+fO1Vy7dm1MmDABv//+OziOw9KlS6X6ef369YOzs3OBviM2NpZPFfnt2zd8+fIF48aNg4KCAubPn48nT54gISEBHh4ecHFxkbmNSU9PR7Vq1VCtWjU+1YF4H/38+TNcXFzQuHFjqKqqwtzcHFZWVjId7x4eHlBTU8P+/fv5c82lS5dQu3ZtdO7cmc/5eurUKTg7O6N+/fowMTFB06ZN5bqovFjuoK21tTXGjx/PL7tk3zu/x77k+q5YsQKrV69GhQoVoKqqioiICH5w3pUrV/hto62tLfPsnc2bN6Nt27Y4e/as1Ijn/C5f7kGWJP/kPmArdu7cOQwZMgSbNm3iH1u6dCm0tLQQGhoqlfhfnpJN5xYVFQU7Ozt06tSJD5ympKRgzJgxsLa2lgraisk6wiIiIgK9e/fGrFmz+IDA/v37YWFhAScnJ9y5cweXL1+Gp6cnunXrhrdv36JWrVr5GvH633//ISwsDBzHwdvbG8rKyoKOSHx8PLy8vNCqVStBMRPJ5Tt06BA4jkNsbOxPv6+4hIaGolatWoiMjMT06dPRokULNGjQQBC0FS+3ZBVOQgjJj5EjR0JfXx/Dhg1DQEAAqlWrhh49eggKCwUEBKBOnTqC/Gw/86O71v/++y8AIDAwEAMHDuTPJX369IGxsTEcHBzk5lwpuRxTp06FoaEh9PT0oKmpKQgEAjkXCE+ePIGnpyfMzc3L3cWtmOQN2JcvX+LTp0+CgmwJCQlo2rQpHxj68OEDRo4ciXv37skcNClreTjlXX4uqHMHBbp164bAwEAsWbKEf/zy5cvo3r07TExM8pyemp/vKa4Lw6L28eNHtGnTBs7OzvD19UWNGjXw8OFDiEQirFu3DoqKioKcv3ktu6zt5bp169C7d29MnDiRf+zcuXPw8/ODq6trnjUfAPkYJZqXo0ePQltbW5DKDfjf7yIuRNa8eXOZLu4LQjzCW0ye9rUHDx5AW1sbFSpU4EeJSrp48SK0tLTg5eVVAksnXyRvBj1+/BivX7/m+y5AznnLzMyMT+X05csXDBgwAJcuXZKLm0A/cvv2bQQFBQlmLIWFhUFBQQErV64s0M15cWFKsdDQUBgaGkJDQwOWlpYYNGgQkpKSkJycjAkTJkBRURHVq1fH8OHDBbM3ftbGSD7//PlzqKioQFNTE05OTnj58qXUa86dO4ft27fj+PHj+U59JPl+8YyQffv28TcCL1++DFVVVXTq1Ik/3k+fPo2lS5di9uzZpSolYe6grZ2dHQYPHvzLbf2UKVOgpqaGnTt3Yt26dejVqxcUFRUFs2AyMjKwdetW7N27l/+t8vObffnyBTY2NmjUqBGaNm2Krl27YubMmfjvv/9++DmS+2d4eDgcHR1/qVBneVYqAra3bt1C48aNoaKiwo8MEhMHbcPCwgR3eAH5DNZ+/foVM2bMgL6+PkxMTATPpaSkYOzYsbCzs8Pw4cNl/mzJ9Z02bRqqV6+O3377DXXr1oW7uzs/ZeTUqVOwt7dH1apVoa2tDWtra2RlZeHDhw/Q19fnp+/kR7NmzcBxHKZPnw4g54AVH7Tx8fHw9vZGmzZt+JG4kj5+/IgnT57IvJ5F5enTp2jQoAF27tzJP5aVlQUnJyc0bNgQf//9N39hfPHiRbnqFBJC5J94yvDVq1f5x6KiomBiYoJu3brhzp07/OO5c7TL4uLFizh58qTgJlpaWhosLCz4QERWVhY6dOiAy5cvy80NTskO6+TJk1G3bl0cPHiQHxGipqbG55cUiURYtmwZ3N3d4eTkVC4LWIWHhwtmxISFhcHIyAgGBgawt7fnRyG/evUKqqqq6N+/P/bs2QNPT0/Y2dnJNFIQKHt5OMuacePGQUNDA6NGjUJwcDC0tbURHBzMP3/58mUEBgZCXV1daoS6LIrywrC4JCcnw8DAABzHYfbs2fzjX758wdq1a/nUaoXhzZs3+O2336Cqqoq+ffsKnjt37hzat28PNzc3qfQI8mzlypWwsLAQpJ7L3Z48ePAA7du3l/nYz+95KHelelneWxxEIhH++ecfODg4wMLCAv7+/nkG5i9dugQFBQWMHDmyBJay5E2dOpUP/AE5fR9tbW00atQITZo0wa5du5CZmYkPHz7A0NAQ7du3x9KlS+Hu7o4WLVrw21ye2hdJ58+fh5KSEmrUqIFt27YJngsLC+PbTsmbrED+g7YAsGDBAtSpU4e/Udq9e3fUrl2bv6Hy5s0b/PHHH+A4Dhs3buTfL8t17Jw5c3Dz5k1kZmbi/fv3aNKkCezt7ZGYmCh4Xe7jPT/bRfI9X758gZ2dHfT19bFv3z4+kC8O2nbs2JG/OSjr98gLyaDt0KFD0b9//19qu1JTU9G8eXOpWWYhISGoVKkSIiMj80xzlN/fTCQSYcaMGZg9ezbi4+OxYcMGNGzYED4+PggJCclzZrbkNl29ejWqVasmN/UwSqNSEbAFgE2bNqFJkyZwd3eXyrm2fPlyKCgoYPXq1SW0dLJJTU3FsmXLULduXcHUKyAnaDtw4MBfOnhv376NwMBAftTLgwcP4OfnBxcXF0GH8Pr164iPj+cPqgkTJqBp06aCE2duuROnDxkyhE/+Lw7KZmdn8xfP8fHxsLW1xdChQwu0LsUpPj4eGhoaOH/+PID/jVr6+PEjtLW1YWlpidOnT1POWkJIgZw7dw4aGhqCvF8AsGbNGlSoUAE9e/YU5LQFft6hmjx5sqB42PDhw1GvXj3UqFEDRkZG8PDw4D9j9OjRqFy5MoYMGQJLS0u5KfoobnPFbty4AUdHR75g1YEDB6CqqgpnZ2dUqlSJv6n26tUr7Nq1q1wWsDpw4ACaNGmCgQMH4vPnz9i1axdq1qyJLVu2YOnSpfj9999RqVIl7Nq1C0BOkUw1NTUYGxvD0dGRP0cXZLuXhTycZc3mzZuhp6fH3wzasWMHlJSUUK1aNUGhp7Nnz8qcZktSUV8YFpeUlBR4e3vDyckJbdq0EVSWz8jIwLp161ClShVBwDu/8jqmrl+/jsDAQKioqPDHpNj58+fh6OiIoKAg2VekGEiujzh4smDBApiamvIBW8mbfrt27ZK6TvvZsX/q1Cns2bNH5mnN8hSgBb6/njdv3oSjoyN8fX2lRrhnZ2fj/v37cneMFIfLly/DyMgI7u7uSE5OxsmTJ6Guro79+/djz549GDVqFCpUqIAFCxYAyPkdTU1NYW1tLRglKm/7QW4LFy6EsrIyBg4cKBXgnDx5MjiOy/cNm4kTJwrSWH369Alt27bFqlWrAOQUM1dRUeFjIpmZmcjKysKrV68QGRmZr2NMMnVOVlYWXr9+jcaNGwuO62fPnqFJkyZwcnLCs2fPkJmZiS5dumDGjBk//fzvGT58ONq0aQN3d3eoq6ujdu3agqDtlStXULt2bbi5uUmNSi5psq6vuK1IT0/P8+aTLN/74cMH6Orq8nEYyVlXLi4uqF+/PpYsWSI1G0EW9+7dg7KysmBQ38KFC8FxHLS1tTF+/Hi+z557tnf16tXlovhfaSb3AVvJnTcqKgrNmzfHwIEDER0dLXid5EWbPJOsmLp48WKYmppKFbH69OlTgUc8bdq0CU5OTrC1tRXc8bh37x78/PzQqlUrbN26VfCemzdvYvDgwVBVVRWM8MpNclvs27cPly5d4hsF8Qkn90ja169fIyUlpdRcqBkYGAiqpGdlZeHLly/w8PBAnTp10KRJEz6Xorx3EAgh8uXixYuoXbs2n/tLfLGRlZUFPT09mJiYYNiwYT8t+CT29u1b2NjYoHXr1tixYwdfTfnixYuIjo7G7t27YWxsjObNm/Nt8MSJE+Hj44M+ffrIxajUmTNnolmzZoKRJzExMfx07lOnTvF5d0UiEZycnFC7dm2pc01pOP8XJpFIhAULFqBly5YYNGgQhg0bhoiICP75//77D6NHj0alSpX4i6x3797h5cuXMuVGFX+XWFnLw1lWLF26FNOmTQOQk2tfVVUVixcvxvLly1GhQoU8A4+yHjPFdWFYnN68eQNvb2+4urryOW2BnONn3rx5cHFxkamvJ7m/p6amCooePXz4EIGBgTA0NJS6eL17967cHyvTpk3j09JdvXoVHMdh8eLFgtd8+vQJfn5+iIyMzPfn7ty5ExzHwcLCAgcPHsz3TUTJ59evX48zZ87k+zuLguT2i4mJwcWLF5GcnMwfIxcuXICjoyM6dOjAFwBs1aqVYOZoeTuPATnX787OznB3d8f48eP54KzYokWLwHEcP3o0JSUFqampMs8QKQmS23P27NnQ1NTEjBkzBLNSgJyb9vlZj5SUFLi4uMDJyUnQB3JxccG9e/dw/PhxKCsr832BzMxMREZGSt0U/9F37d+/HxzHCfbL1NRU6Ojo4MGDB4LXJiQkQF9fH1paWmjevDkMDAwKXANh06ZNqFGjBm7fvo33798jOTkZ/v7+UFVVxb59+/hRtWfPnoWHh4dctZc/Kqr1o3ZMcjvkd32+97qAgACYmZnx596srCxkZ2ejV69eaNSoEZycnGQ6lx0/flxQhwjIifVI3gA2MTGBv78/5s+fjw4dOoDjOEG++lWrVkFVVZVG1hYCuQ/YAsKdc82aNTA3N8fAgQP5qqSS5OFkl99ORmpqKh+0zWsEakECgidOnIClpSVUVVWlqmbev38f/v7+MDU15QMGQE7KiTlz5uT5e+a1LOPGjYOmpiY2bdrE5xdKT0/HpEmToKCggIiICPz777/w8/ND9+7d+ffJU+Oam3i/2b59O3R1dTF27FjBc4GBgXjw4AEMDAzQu3fvklpMQkgp17VrV9SrV0+Qu/vNmzfo2bMnZsyYAVVVVfz9998//Rxxm/zkyRO0bdsWvr6+GDRokOBckp2djZs3b8LQ0FBwY1ByOllJX+zExcWhbdu2aN26teBm4vv37wEAXbp0wdChQ5GdnY3s7Gx07doVurq6cHJyKqlFLnGSeWTFQaVatWph3bp1/PMikQgfP36Eo6MjRo8eLbWdC3I+Lmt5OEurvPqG2dnZePLkCZKSkmBmZoa5c+cCyAkS1qlTBxzHYfLkyTJ9T3FdGJa0p0+fwsfHh0/f9e3bN7Ru3RqjR4+WafCE5GtmzJgBW1tbNG3aFK1bt8a1a9cAANHR0ejVqxeMjIywb98+qc+Q52PF3d0dY8aM4f+eN28enzri3LlzuHLlCtzd3WFmZpbv88rDhw9haWmJcePGwdXVFdbW1oIChd/73SUfj4yMBMdxgvygxU1yu4WGhsLIyAjVqlVDq1atMH36dD4X54ULF+Dm5gZjY2M+P3tJF/ksKZLbcOfOnXB3d4eysjI/QvO///7jX9O+fXsEBAQgMzPzu4W15ZXkMk6fPh1aWlqYMWMG3rx5I/XaHx034t8iKSkJHTt2RKtWrbBmzRoAOb+PgYEBatSowfcDgJyikq6uroJZWD+TkZGB+fPnQ0FBgR/Jm56eDl1dXURHR/P9C/Ex+vXrV0yfPh0LFy78paJ/CxYs4Gf/SO4bbdu2haamJvbv3y9V7Fvetv+CBQvg7++PwMBAwUj6vNoxycf++usvqYGIeZFc3zt37uD+/ft8jvAbN26gRYsW8PHx4Uckf/v2DQEBAbh7965M57KLFy+C4zhYWloKZp/s3r0bpqamePz4MVq0aAEHBwd+Rk1ycrKg3s/evXtRvXp1qRklpGBKRcAWEO6ka9euhaWlJTp37oyEhIQSXCpp4rtPP2tEJIO2S5YsQd26dTF//nyZvut733HhwgXY2dmhbdu2Uhf+t27dyjM3Yn47DLNnz4aGhgYuX74saJDF6yPOkWNsbAwjI6NS1xFJTk7GokWLoKmpCVdXV4waNQp2dnYwMjKCSCRCYGAg2rdvX9KLSQgpZcTtdXJyMry8vKCmpoYFCxYgMjISbm5ufKVoQ0NDjBgxQqbPFOcLr169Otzd3aVeFxYWBnt7e6nOrrwEVcQBk9yj3FJTU2FqasrnmMzKyoK/vz9u3LghN8teUiQDGuJzlr29vVRV9nbt2glmjRRUWczDWRpJ9t3ev38vNZL1woUL0NXVxbNnzwDkjPTr1q2boABMfhTXhaG8ePr0Kfz9/WFoaAgdHR2YmJjwIyNlXY8pU6agVq1aWLlyJdavXw8HBwc0atSIv3C9c+cO+vbti1q1auHcuXOFvi6FIa/ri549e8LHx4f/OysrCxs3bkTdunWhoaEBY2NjtG7dWqaZGzExMRg5ciTi4uKQkZEBFxcX2NjYfDdoKw4WiYmn28pLuzN9+nTUrVsXx48fx8ePHxEQEAAtLS2MHDmSTx9x9+5dbNq0CfPnz/+lAFdpllfe2R07dqB58+Zo3LgxXr16JXh+wIABpfraS/J4mjFjBrS1tTFu3DhBUbWfkfytLl++DGdnZ1hZWWHv3r14+PAhrK2t0axZMwA5QdSUlBR4eXnB0dFR5sFsX758wbx58/gC22lpaTA0NMxXzKUgMzeAnGNHU1NTsAxAzkhPjuNQsWJFqZHCJU1yu06bNg21a9dG3759+ZsP4hkJgLAdy92GcRyHixcv5vt7Q0JCoKOjg8qVK6Njx478iP39+/fD3Nwc9erVg7+/P8zMzKCvr8+3L/kNcItHWTs5OcHPzw9RUVH8cz4+PvxzkjNIJIlEIuzdu1eqUDApuFITsAWEO9rSpUvRu3dvubq7snz5cnAcx++g+Q3afvjwATt27ChwZ/rvv//Grl27cPDgQb7zfObMGbRs2RLt27cXVGuWJGuj+unTJ7i5uWHhwoUAcqpFnjhxAt27d8fYsWP5abzXrl3Dvn37Sm1ewY8fP+LChQvw9fWFn58fAgMD+Y57hw4dMHjwYKnqnIQQkl9ZWVkYOXIkWrRoASMjI3h7e/OdU2traz4X2ffkFRB59uwZ2rVrh/r16/OjLsQ2btwIIyMjPpgnjySDtpLpEQYOHAgVFRWMGTMG1tbWgry78nT+Lw6511dypO3SpUthbm6Onj178sVLsrKyYGtrS3k4y4B9+/bxQQwgJyjo6OgIAwMDrFu3jq+8HB0djVq1amHixImIj4+Hp6cnOnbsWODCPEV9YShPXr9+jUOHDmHt2rX5DqSJZwIAOev85s0bNGvWTHDjCQA6deoEbW1tfjtduXIFs2bNkotZgT9y/fp1Pg91ZGQkvL29pbZtQkICoqOj8eDBA5nTrfz333+CkYZpaWl80Hb//v3875NXvkpxsLYkp9tKtpPR0dGwsrLiR9b9/fffqFatGnx8fGBgYIAxY8ZI3TQF5GNmaHHKvf+Ir1uBnFQ6VlZWsLe35/eLrKwsODg4IDAwsDgXs0B+dF0oud5jx45F+/btC3QdOWrUKPj5+cHa2hoqKiowMDBAeHg4tm/fDi0tLejr66Nly5Zo2bIlzM3N830DJfd2EYlEmD17NjiOw5AhQ9C0aVMYGRnB39+fv0HbunVrrFy5Uqbl/9654e3bt9DW1hZMuQdyRnuOGTMGEydOlKt4guS2e/ToEebMmcPXDnrz5g0mTJggVeQtd+wgIiIiXykDJH+zv/76C/r6+jh16hT27t0LDw8PODs7832y169fY+LEiRg2bBhCQkL430zWdqZHjx5wdnaGv78/XF1dsWHDBgA5AfSmTZvywfPSeK4vjeQmYJvfRiuvvCDysrM8fPgQvXv3Ru3atfmRrfkN2n7v758JCQlBw4YN0bBhQzRq1AiNGjXi89WdOnUKDg4OCAgI+O5UxR/JvexpaWlwdXVFcHAwoqKi0KFDB7i6uvJ3+Xr27CnIZwbIX0ekoEHWr1+/YvTo0VBXVxdMZSaEkIJKTk4WXIiGhYVBU1MT8fHx332PZLuclJSE9PR0pKWlAcgZaevj4wNHR0csWbIEX79+xYsXL9CqVSt4eXnJ/U0myaCteBrW169fERQUBHd3d3Tv3l0u8u6WhNwVd/v3749evXoJgvOLFi2Cvr4+dHV10blzZ/z2228wNDSUeaZLWc7DWRpt3boVlSpVwrx58/Dp0yesW7cO6urqWL58OXr27AktLS2MHj2abzdmzZqFmjVrQltbG1ZWVjIV5imJC0N59bP16NevH4YNG8YHYQHg5cuX0NLS4guzSKaf0dfXx8iRI2X+npJy5MgRqKqqQklJCZaWllBXV4eSkhLWr1+PAwcOICUlBV+/fpWq2F7QNkC8n378+JEP2h46dAiJiYnw8/PDihUr+NcuWrQIampqJVrIRvJ4evjwIVJTU7Ft2zakpqbi3LlzqFOnDt8+u7q6om7duujdu3eeFe7Li9wDrzp37synjRCfZ/bv3w9TU1PUrFkTTk5O6NmzJ4yNjeWywFhSUhKeP3/O98F+Jq8Yhizrs3HjRqipqeHWrVv4999/8erVK7i5ucHZ2Rnr16/Hy5cvMWvWLEybNg1r167N98Cp3O3+jh078OjRIwDA4sWLoaSkBF1dXaxcuRJTpkzBxIkTMWHCBEyZMkWmIKrk92zYsAHBwcEIDg7m8/Fu3LgRxsbGCAgIwJMnT3Dnzh14enpi4MCB/PtKOmg7ZcoUwd9HjhzhC2/dvXuXfzw5OZkP2or7s5JtfX5vOEmOwv7rr78wZMgQzJs3j3/s4cOHCAgIgJOTk2CwgyRZfjPxDZQtW7agf//+uHr1Kvz9/eHo6IgdO3ZAJBLB1NRUsE1I0SvRgG1Bq4KW9MH6IwkJCRg2bBjU1NRw6dIlAD/uvEg+9+rVK5k6OuvXr0fNmjVx/fp1vH79Gg8fPoS3tzc0NDT4aQunT5+Gvr4+xo8fX8A1ymlUxTlKFixYACsrK6ioqGDSpEn8EP6goCC5ze36/PlzPHr0SKb0GeJ8iQDwzz//YPz48dDT08Pt27eLajEJIaWcrJWtxW1MbGws+vbtizp16vywjZH8/OnTp8POzg7GxsZwdHTk7+yLc9oqKSnBwMAA/v7+8PDw4C925D2gJg7auri4CAoeiEeNAvLdByhqY8aMgbq6Orp3746OHTuC4zh0796dD/wvW7YMBgYG0NfXx/bt22We6VLW83CWVmFhYdDW1sby5csxYsQIQY2C5cuXw8DAACNHjuSL2Tx9+hTnz5+XacRjcV8YlnYzZ86ElpYWJk6ciOfPn/OPGxkZCeo3iAcytGvXLt/pbkpCXuevFy9e4P79+9i3bx8mTpwIjuPQokULNGzYENra2lBWVsaiRYsKbRnE7dXHjx/RqlUrWFlZQUdHB02bNuX3LXFu7twFlIuT5G81cuRIuLm5ITExkU9R0rdvXwQFBfHLPGzYMFhaWmLkyJHUPiKnFkrt2rUxfPhwBAcHQ1lZGT4+PvyAo/3798PZ2Rmqqqo4duyYzCO3i8OWLVvg4OAAdXV1eHp68rMPfib3Oshyw2by5Mmwt7cXpAZ5+fIlrKys0KRJkzyDf7J8/vjx41GtWjU0adIEFStWxMqVK/Hy5UusWrUKCgoKgin+P1qnnxkzZgzq16+PQYMGYfTo0eA4DrNnz0ZGRgZ27doFExMTqKiooGHDhrC0tJSb9IpXr16Fg4ODYH3/+ecfDBkyBJUqVeJvIIm3TXJyMsLCwsBxnCCn7fLly1GrVq2fBmvPnz8PFxcXnDlzBunp6TAxMUHlypUxbNgwwevE5+bWrVsLis/m1+nTp6XyHL9+/RqamppYv3493rx5A39/fzg4OODo0aM4fPgwatWqxV93kKJXYgHbwqgKGhUVVeJVQQHhxcmmTZv4Oyo1a9bE2bNnpV4jJrkuy5cvR/v27QXTq35mwoQJ6Nq1q+CxtLQ0ODk5wcHBgW/g7ty5U+A7+MnJyVBXV4eFhQV/wfzs2TM+P5qYu7u7VAMiDzZv3oxmzZqhUaNGUFJS4hOoy7KfATkBlcTExCJbTkJI6VTQG4+Sr0tNTcXhw4d/OLJW0pQpU1CzZk1s2LABCxcuxG+//YZKlSrxnb8nT56gQ4cO0NLSwqZNm+TyYudHnj59yhciy11tXJ5G1xS13Ot65coV1K9fX5Dr7OLFi1BRUcGAAQP490yZMkUQGChIgKAs5OEsCySP2XHjxqFBgwZQV1eXSkmxYsUKGBgYYPTo0VKzgPLT/yuuC8OyQPK4XLFiBRo0aICwsDC+/d65cyd0dHQEBboAwMbGRubCb8VFso148eIFoqOjpaqdA4CjoyPWrFmDtLQ0XL16FZs3by7084p4f42PjwfHcbCzs+OvZ8TflVdqgZLw/PlzwQ1TMV9fX3Tu3Jn/u3Pnzti6davczQwtDrlHxt69excNGzYU5LeMjo5G48aN4e/vzz+2YcOGXz6PFZWoqCgoKytj5cqV2LdvH2xsbAQ3aYCfX/dv2LABcXFx+fo+8ftmz54NS0tL/saA+LcVp98wNjbmb+bJUihRJBLh2bNncHBwwOXLl5GcnIz58+eD4zjMmTMHr1+/xsKFC6GoqIhp06bluT759ffff6NRo0b8oLY9e/ZAUVER4eHhgtdduHABt27dkqv0ipIpDSTzZj969Ai9evVCtWrV+NkVYu/fv0dERAS//E+fPoWioiL+/PPPn35fbGwsXFxc4O3tjbi4OMTHx8PBwQFmZmZSM6ejo6Ph4uIicyzm9OnT4DgOHMfBw8MD4eHhfD2m7du3w9fXF58+feLP/W3atEH//v35YsCkeJRIwLasVAXNbcyYMdDS0sLSpUsxbtw42NraQk1Njc8hm9dUCCBneqOysnK+Dl5JgwYNgpGREf+3+PfbuHEjDAwM+JEWuZ//kbx++5iYGBgZGcHa2povOgHkBBkuX74MLy8vmJiYyEVjKmnr1q1QVlbGxo0bcePGDSxatAgKCgq4cePGD9+XuzMuWXWdEELECuvGo/jGXl5yt6vv37+HlZWVIC/Wf//9h5CQEFSqVIkfoRIXF4fRo0fL5cVOfjx9+hS2trblNifq0KFDcebMGcF2O3HiBBo1asTf2BXvb0ePHkXlypUF+eplCQyU9TycpVVe227mzJmoVKkSgoKC+LoBYqtWrYKqqip/Y1oWxXFhWFZIbpfExET8/vvvqF+/PiZMmIB3794hIyMDixYtgoaGBhwdHdG/f384ODjA0NBQ7vrJgPB8NHnyZJiZmaFevXqwsrLCggUL+JHX//33H4yNjTFr1iypzyjs9Xr//j0sLCxgbGwst4W55syZA2dnZ7Rt25a/NsrOzsa3b98wadIk2NjYoG3btnBwcICRkVG5zL0+YsQIREZGCtJA3Lx5E5qamoiJiQHwv6Dj3bt3oaiomGdVeXk6x5w/fx5aWlqCWQabNm3CkCFDEBsbK8jJ/L3rfnEMI7+jcsX++ecfVKxYEVOnThU8fuTIEbRr1w6hoaH53r8kX5ecnIy4uDipouRLliwBx3GYO3cu3rx5gz/++AMODg6/dOM8KioKrVq1ApATrFVWVsbq1asB5MQV8hqIJ0/bH8gZFMFxHDp27Mg/FhcXh759+/KjwvMi3tcl89H/TFxcHNzd3dGmTRvExMQgLi4O9vb28PX1xfHjxwWvffbsmczty+PHj+Hk5IRWrVrBxcUFQUFBqFWrFpYsWYJFixahVatW/A2phw8fwsXFBRMnTuS/R962TVlVIgHbslYVFMg5SAwMDATTA+/evYuuXbtCTU2N39klp9oD/1uXH+Vh+l4VyZMnT8LY2BiLFy8WdGSOHj0KQ0NDQV6tghL/7jExMTAwMICdnR2fZ+jkyZNwdXVFu3bt5C6vYGxsLOzs7KTu2Dk4OPB3B/M64eTez2rUqJFn54EQUr4Vx43Hzp07o0ePHoKiHAkJCVBRURGMohCJREhLS4ODgwNCQ0OlLmxL6wXi69evS+2y/yptbW0YGBjg8uXL/G9w69YtKCgo4OTJkwD+t10TExPRqFEjqel1+bmoKut5OEsryf0+PDxckL9zypQp0NLSwrx585CUlCR43549ewq8LYr6wrCsGT58OJo1a4auXbvCzs4OFSpUwLhx45CcnIysrCxcvnwZHTt2RPfu3TF8+HC5z/E7c+ZM1K1bF4cPH8Z///0HV1dXNG7cGPfu3eO39dChQ/nR/EUpOTkZvXv35tNJyEOwNvf+vn//flSvXh1169bFkydPBM+lpKRg6tSp6NGjB/r27Sv3276ouLi4wNTUFFu3buXPI3FxcahcuTKf0kIc5P769StMTU1lLmJVnLKzs7F//34sXLhQMIDJzc0NOjo6qFGjBlq2bCk10KcwYxhRUVFQVFRESEgIrl+/jvj4eHh7ewtSH8rSNoeGhsLKygo1atSAqamp1AyNJUuWoGLFiggLC0NycnKBcu9KOnjwIDp06IANGzZAWVlZMFPjr7/+Qr9+/WQKaJYEkUiEv/76C+rq6vjtt9/4xx89eoR+/fqhVq1agrRFku8rCPG52d3dHY8ePUJMTAwcHBzg6+uLEydOSL1e1nPzo0eP4O/vD19fX5w8eRLHjh2Dv78/vLy8wHEc2rdvz7ddT58+LbUDQUqzEgnYlvaqoHl5+PAhKleuLHXhffXqVWhqakJdXV2qw5ufdRFPU5Occig+4FNSUtC/f3+4uLhg6tSpSE1NxdOnT+Hl5SVTgZnjx48LfutFixbB1dVV6vuio6Oho6OD1q1b8yeqO3fuyOV029u3b8Pa2hr37t0TPN6hQwfB1FFJuZOB16hRQ+72M0KIfCiOG487d+6EkpISgoODBUFbT09PdO7cmW+HxZ/r4eGBwYMHF+ZqyoXy1CmUXFdra2vo6+vj0qVLyMrKwn///YeuXbtKTcFNSUmBoaFhgc5XZS0PZ1kTEhLCT7mXDKqHhYWhQYMGmDt3rlTQFih4YKioLwzLiqNHj/LFf8S/9dy5c1G9enWMHTtWaoabmDz1k8VEIhFSUlLg7OzMF8c5ceIEVFRU+JFv4uUOCgpCmzZtCvxdBdlf5CV/pVhMTAyfkuHkyZOoWrUqevfuzU9TF69j7msMedz2RUVyO3fs2BEmJibYsmULf605atQoNGzYEEeOHOFfl5GRAWNjY6xbt67Yl1cWHz9+FKTIa9u2LRo2bIjz58/j9u3bmDdvHkxMTPiRonkN0vrVa8vdu3ejTp060NLSgpaWFszNzfNdlE1yebZv34569eph2bJlGDFiBKpWrYqQkBCpmi8zZsyAvb29TMHa7x3rly5dgq6uLipWrIiFCxfyj3/+/BleXl7o27dvqUh9JRKJ+POAZNA2Li4OAQEB8PDwKNTvy31ujo2NhZOTE+zs7HD9+vVf/vzY2Fh4enrC3d0dMTEx+PbtGx4+fIi+ffvyxdRyX9OQ4lOiRceA0lcVFMi5uyC+eJk/fz4+f/6M7OxseHp6Ijg4mC/QJebt7Q1tbW14enryj61fvx7VqlX7aaMdGxsLZ2dn+Pj4CPLWiTuISUlJCA4OhrGxMRQVFWFiYgILC4t8F5jZunUrOI5DREQE0tPTAeQEcNXU1AS5hMSfI54eYWRkJAjyyuOBK1mtUby9Bg8ejFGjRgle9+7dO8Hfq1evlsubAoQQ+VFcNx4PHTqEypUrIygoiB+hsnz5ctja2mLy5Ml8IDczMxNOTk5ymyOR5I9IJBIE21q0aAE9PT1cvnwZAHD27Fn4+fnByMgIy5Ytw9atW+Hu7o7mzZvLFKQri3k4y5rNmzdDXV0dN2/e5B+T3MZhYWHQ0dFBWFgYP/OpMBT1hWFZcPDgQejq6uLly5eC/u+MGTOgoKCAyZMn81XWS4OUlBSYm5vj/fv3OH78OJSVlfkZahkZGVi9ejXi4uKQmJiY73YmJiYGR48exZgxY7Bq1So+Xc/PyOP1hJh4CveOHTv4AO2RI0dQpUoVDBo0SDAbQbKNLQ0BqMKU+zzWvn17PmiblZWFJ0+eoHfv3lBTU0NYWBgWLlwId3d3NGvWrNSNQt69e7egrsvjx4+hpKQkleZwyZIlhRrDePXqFa5fv44zZ84UKM/r2bNnMWTIEEF6rZUrV0JLSwvjxo2TCtrKEqyVfM2aNWswa9YsQXFC8eyycePG4cCBAzh16hTatGkDU1NTmetBlCSRSIRjx45BTU0Nv//+O//4ixcviqQdE5+bPTw88OjRIzx48ACDBw8utO+SPPefP39e8Jw8t8vlQYkHbIHSUxUUyBlR2qhRI+zbtw/BwcHgOI7vlM2YMQPNmjXDsmXLkJaWBiDnIr59+/Y4cOCAoPHZs2dPvvPvxsXFwdPTEx4eHoKgrTgom5mZiU+fPmHevHm4ffu2zA33xIkTUalSJYSHh/MdkLNnz0JdXR1+fn6C127btg39+/dHYGCg3J5Uc6+3ZOGEQYMGoVevXvzjHTp0EOR7W7NmDSpWrFjiNwUIIaVHYd94zN0xOnDgACpXrsxPsxOJRAgNDYWFhQVMTU0xcOBA2NrawsjIqFyN4ilrJPsIknllW7RoAV1dXVy7dg0AcP36dYwePRpqamqwsbGBr6+vzGmJyloezrJowoQJ6NmzJ4D/bdfcbcPQoUPRoUOHQr+4LeoLw9Lu0KFDqF69Oh4/fgwAfN85MTERNWvWROXKlaUKJso7W1tbuLi4oHr16oKK4QkJCXBychKcs362H2zfvh22trYwNjaGlpYWVFVVoaSkhKioKH4ARV4k9+OzZ88WSmq3gvreMeXn54fGjRtj165dgqCtkpIShgwZwj9WXkn+bpLbr3379jAyMsK2bdsgEonw5s0bLFiwAPr6+nBxccFvv/0md+n1ZCFe70ePHvHFu8QSExNhaWkpyHtb2GT5zd68eQNdXV0oKytjyZIlgudWrFgBLS0thIaGSqX6kPU8ExYWBjU1NbRs2RL16tWDjY0Nf1Nj8eLFaNmyJapWrYqWLVsWqB8jD8RB29q1a8Pd3V3wXFEFbb28vGBhYSE4vgozaOvp6QlPT0+pYoqk5MhFwBaQ/6qgEydO5O829+zZE7Vq1YKysjJ/ASUWFBSEZs2aoXXr1ggJCYGtrS2sra359fuVaWrioK3kASQSifDq1St4eXkJpsLm53skp9iGhoZCSUkJa9eu5X/nM2fOoE6dOmjXrh2ePn2K169fw9/fH3PmzJHpe4pDfiu19+vXDz169ACQM/JZS0tLEGyZNm2aXOVGJoSUDkVx4zEhIYFvnw4ePIjKlStj0KBB/PNHjhxBcHAwunTpgjFjxpTbPHllgWRne+XKlXy6DTFx0Pbq1av8Y//++y8+ffrEn+8KEkgta3k4S6u8LrZ69uwJR0dH/m/xdv769Sufx1jy8aII2hblhWFp16ZNG+jr6wtmUTx9+hSDBg3C6tWrS80xIt6eBw8eROPGjdG6dWv+ufT0dHh7e8PV1TXf67N69WqoqKggMjKSLyx18eJFBAYGQlFREatWrQIgvb9K/r1q1SpwHIdbt2790roVlYCAAGhrawuCtn/99Rc4jsP8+fNLeOlKjmTbsGXLFgQEBAhG5UsGbcXXoJ8+fRK8r7TdEJTcbzMyMuDr6ws3Nzepdco9m7Ok3bt3D/r6+mjTpg3u378veG7VqlVQUFCQqgPzM7nXuXv37rh58yYyMjJw8+ZNGBkZwczMjI8zJCUlIT4+Hu/evfulfkxh+u2332QOrItEIuzfvx+enp7Fcn6Mjo7GyJEji+y74uLi4OPjA0tLS6nUkqRkyE3AFpDfqqApKSlwcXGBnZ0dDh8+jBUrVqBWrVp8kQ9xKgExcbVINzc39OnTJ9/pCX4mr5G2b9++hZOTE3R1dWXK85R7OuTq1atRoUIFqKqqIiIigr8DduXKFTRu3BiqqqrQ1tYWTFeQF/mp1C5+bMSIERg6dCg6deoEPT09qbt55f3OOCGk4H71xqPkOWLbtm1QU1PDiRMnfhi0BYRtnby1z+TnJLd7bGws/Pz8oK6ujrCwMMFUS8n0CHnNJJFVWcrDWVZERkbi7NmzAHJG4xsYGOD06dOCUYlJSUlwcHAQVBgvqumjRX1hWBqJf+u7d+/C2toaDRs2xI4dO7Bnzx54eHjA29ubf21pCdoCOYW+Zs+ejbp168Le3h7+/v5wcHCAqalpvke+RUZGokqVKvzAB8n98t27dxgwYAAUFBQEow9zvy4iIgJqamolVvB34sSJWL58Of/38uXLcebMGaljoEOHDqhbty527drFn9fzapvLC8nf58qVK+jSpQtq166NHj164Pbt2/xz4vQIW7dulUoZVRqmweclPT0dR44cgZeXF5o1a1ZqRorevXsX5ubm6N+/v1TKElkLWEpu/5iYGFy7dg1+fn58miUgJ0hsbGwMc3NzqdhJ7s8oKd27d0fVqlUFReTzQ3LZi3O7F9VvFh0djVGjRsnFNiFyFrCVx6qg4pNHUlISOnbsCG9vb4waNQpPnz5F7969YWBggE2bNuV5ES7ZGBXWuoiDtl5eXjh48CDatGkDQ0NDqaBAfk2ZMgVqamrYuXMn1q1bh169ekFRUVGQHiEjIwNbt27F3r17f3mkcGHLb6V28f+DgoLAcRwsLS0L/JsRQsj3FPTGo2SnaMeOHdiwYQM4jkPz5s1x6tQp/jMOHjyIKlWqICgoqERnnZDCN2LECJiamiIwMBBOTk6oUKECJkyYIJiWaG1tjRo1auDBgwe//H1lLQ9naSYu/KSiooIdO3YAAL58+QIzMzNYWVlh9+7dePPmDR4/fgwfHx+0bNmy2PthdOEmJBKJ8PTpU3Tr1g3a2tr81O78Fv+RR2lpabh8+TICAwMxfPhwzJ8/P9/nsdjYWHAch/79+wPIu/hWdHQ09PT0+JluuZ8v6cLS4gE6Tk5OfPErMzMzaGlp4dKlS1LHQPPmzWFmZoaNGzcKZi2W5+uKkSNHQl9fH8OGDUNAQACqVauGHj164MaNG/xrAgICUKdOHali3KXVmzdvEBwcjMDAQLkacJYft2/fhoWFBfr374+HDx9KPS/reWbs2LFQV1eHsbExlJWVBakcAeD+/fswNTWFlpaWIOezPJCMFVSpUgX79+/P1/vK+rmxrK9faVAsAdvSXBVUsqG6dOkSHB0dYWtry1e27NGjBwwMDATTO4KCggQjNYtimpq3tzc4jvulYG1qaiqaN2+OpUuXCh4PCQlBpUqVEBkZKVVADZCfYC2Qv0rtklatWgUDA4NSd0IlhJQOv3rjMTQ0FLVq1UJkZCSmT5+OFi1aoEGDBoKg7aFDh8BxnKCIAyndjhw5wo92FfeZ5s2bB1VVVYwfPx5Pnz7lX9unT59COQ+XxTycpUleAS1XV1fB6L7Pnz/Dzc0NJiYmqFy5MszNzWFtbV1qRnCVdvntv7948QJv3rzht6k89i1/5VokP/vZ58+fMW3aNFSuXBnr16//7nf+/vvvaNmypdRzq1atQs2aNUssWJt7gI6zszM/Urh169Zo1KgRLl68KBgQ8ttvv0FVVRUdO3YskWWWN+L6J5Kpe6KiomBiYoJu3brhzp07/OPjx48vFe1XfmMYHz58kJtp/bK6ffs2rKys0LFjR0FfIz8kf5+DBw+iadOm2L17N3bs2AELCwuYmJhI5cK9desWunfvLlfbX3JZEhMT4ePjg7p16wpmsuRFsh3btWsXNm3aVGTLSMqvQg/YlsWqoAAwatQo+Pn5wdraGtWrV0fjxo35BPw9e/ZE06ZNERQUBHd3d6iqqhZ5Yx0TE4OgoKACBx5FIhE+fPgAXV1dvmMlOeXOxcUF9evXx5IlS+Q6TUB+K7WLi8ABKLUnVEJIySmOG49Pnz5FgwYNsHPnTv6xrKwsODk5oWHDhvj777/5dvrixYvUhpUh+/btg66uLhITEwX72syZM1GhQgVMmjSJD6yKFcbFTlnJw1maxcbG8v/u1asXAgICBBeBmZmZuHPnDrZt24azZ88WqCI4yZ+kpCQ8f/5c0Gf8kbyC7vJ0PfP8+XM8evRIquL7j0gW6s3Ozv7p+ly4cAELFy7E4sWLcezYMSxbtgwVKlRAVFRUnq/38/NDnz59BN939+5dcBwnOPcVN8m27vLly3B2dkaLFi1w+PBhADnXRY0aNcL58+f52S29e/dGdHS0XG3zknTu3DloaGhI5URds2YNKlSogJ49ewpy2gLyddOpoDEMyXUojSPrAeDatWvo3bt3gfflDRs2YPr06YI6N2/fvoW5uTmaNWsmFbQVk6ftDwBjxoyBjY0NvL29Ubt2bSgrK383PYLktg4PD0e1atXw999/F9OSkvKkUAO2ZaEqaF42btzIj3z5999/8erVK7Rp0waWlpb8QTx+/Hh06NABAQEBxT7yQdbptpICAgJgZmbGB2WzsrKQnZ2NXr16oVGjRnBycio1J5+fVWoXjyQWiUSlZp0IIcWvpG48xsfHQ0NDA+fPnwfwv5toHz9+hLa2NiwtLXH69GnKWVsG7d+/HyoqKlKjXd++fYtatWqhQYMGmD17NjIzMwslOFBW83CWNhEREahVqxb09PRga2uL1q1bw9XVFSdOnMC7d+/w8ePHPN9H26TwbdmyBQ4ODlBXV4enp+dPR1aJ5e5Pysu22bx5M5o1a4ZGjRpBSUkJy5YtA/DzgJIs/eM1a9ZAXV0dzZs3h4qKCvT09LB+/XosXLgQHMfxo83EbVZCQgJcXV3zHLkvL+lXJAfoqKioQEdHh58a3aZNG+jo6MDd3R12dnYwNDTktzcFbXNuJNeuXZsviig5A1RPTw8mJiYYNmwY3r59W5KLmafCiGGcO3dO7mIYshCvS0H2ZT09PXAch169egkeT0pKQosWLdC8eXO5Oca/Z8uWLVBWVsb169eRmpqKhIQE9OnTB0pKSlLpESR/o4iICKiqqpZY3m1S9hVawLYsVwWdPHky7O3tkZ2dzS9vYmIirK2toaOjw0+Zkdcql5LLdefOHdy/fx8pKSkAgBs3bqBFixbw8fHhUzp8+/YNAQEBuHv3bpFVHy4q+anUTggh31PSNx4NDAwEHd6srCx8+fIFHh4eqFOnDpo0acJf7JSWdpnkj5ubm9Ro14SEBAwZMgShoaGoUqWK1MilX1UW83DKs9wXwk+ePEF0dDS2bNmCSZMmwdPTExzHwdbWFtWrV4ehoSFcXV1pmmURi4qKgrKyMlauXIl9+/bBxsYG3bt3F7wmryCG5PGxYcMGxMXFFfmy5sfWrVuhrKyMjRs34saNG1i0aBEUFBQEeUTzkvuabODAgd997Zo1a1CpUiXs2LEDGRkZOHPmDJycnODg4IDHjx8jNDQUHMdhw4YNAHJ+Px8fH7i6ugqC2vIU6PzeAJ0WLVrg4MGDAIA5c+ZgwIABGDJkCH9dIU/rUNK6du2KevXqCWYOvHnzBj179sSMGTOgqqoqd6MQy3IMQ1aynvMlX+/m5gYNDQ2cO3dOcIwnJSVBS0sLPXv2LLTlLAqLFi2Cs7Oz4LHMzEx06dIFampq+Ouvv6Tes3r16hLNu03Kh0IJ2JaFqqB5ES/f7NmzYWlpyY94EV/I/P3336hWrRqMjIz4E7nk++RNSEgIdHR0ULlyZXTs2JEfPbB//36Ym5ujXr168Pf3h5mZGfT19UttR+RHldrlZeQDIUT+lGSnXdw2bd++Hbq6uhg7dqzgucDAQDx48AAGBgbo3bt3gdaPyDfJ0a67du3C3r174eHhAV9fXwCAlpYWZsyYIfPnlqU8nKWZZF8qKioKY8aMQXBwMI4ePco/fuHCBaipqeHmzZs4evQooqKiMGLECNoWRej8+fPQ0tLCtm3b+Mc2bdqEIUOGIDY2VpB2S3IbSh5XkZGR4Dgu36Nyi1JsbCzs7OwQHh4ueNzBwQHTpk0DkHebkPuarEaNGt+9Jjtz5gw4jpP6vLlz56JevXp4//49vn79ikmTJkFBQQGbNm1Cx44dYWBgINf98R8N0GnUqBGfCk8SHZs5xMdGcnIyvLy8oKamhgULFiAyMhJubm5wc3MDABgaGmLEiBEluagCZTWGUZwkjwErKyvo6+tLFen78OGDXB7zkhYvXowaNWrwA9hy143gOA5nz57lXx8REYGqVavm2S4QUph+OWBbFqqC/sw///yDihUrYurUqYLHjxw5gnbt2iE0NFQug5qSy/TXX39BX18fp06d4i8CnZ2d+ZPL69evMXHiRAwbNgwhISF8IyXvjev3FLRSOyGkfJKXTntycjIWLVoETU1NuLq6YtSoUbCzs4ORkRFEIhECAwPRvn37An8+kV8ikQhPnjxB165doaWlBV1dXTg7O+Pr16/49u0bmjVrhq1bt/70c8paHs6yZsyYMahbty5GjhyJTp06oXHjxggODoZIJMLbt29hYGCAmzdvSr2vtPbH5Fl2djb279+PhQsX8jPPgJyRYjo6OqhRowZatmyJoUOHCt6X1zWM+NxR0m7fvg1ra2vcu3dP8HiHDh0wYMAAAD9O4yAO1v7omiwuLg6Ojo7w8/PDuXPn+Mfnzp0LHR0dfhZIeno6Jk+eDI7j0KRJkwIXSS5q+R2gY2xsnO/K8eVZVlYWRo4ciRYtWsDIyAje3t748uULAMDa2pq/+V3SykMMo7hIHtOWlpYwMDDA5cuXpfoS8nAe+17/5u3bt2jevDkCAwMF54Nr164hKCgIS5Ys4dczISEB7u7uFKwlxeKXA7alvSpofkVFRUFRUREhISG4fv064uPj4e3tjfHjx/OvkacLnH///Zf/919//YUhQ4Zg3rx5/GMPHz5EQEAAnJycBKMKJMlbh0oWv1qpnRBSfshbp/3jx4+4cOECfH194efnh8DAQL4t69ChAwYPHky5uEup/G6zhIQEvHv3jn/9xIkToaOjg2fPnv3wfWUtD2dZc/ToUejo6ODatWsAgJ07d6JKlSrYsmUL/xozMzPMmjWL/5uO86L18eNHJCYm8n+3bdsWDRs2xPnz53H79m3MmzcPJiYmOHPmDADp3IXyGKy5e/cu/2/xuWPw4MEYNWqU4HXv3r0T/C3L9N64uDh4enrC3d0dcXFxOHXqFCpXriwVwEhJScH27dtLxeCJ0jpAR14lJycLUvyEhYVBU1MT8fHxJbhU/1NeYhjFRfLYtrGxQY0aNfDgwYMSXCJpksfv+vXrERwcjKFDh2LdunX8Y/b29mjfvj0ePnyI27dvw9vbG7///rvUZ7x+/bp4F56UWwUO2JaVqqCy2L17N+rUqQMtLS1oaWnB3NxcLvO8nT9/Hi4uLjhz5gzS09NhYmKCypUrY9iwYYLXiYO2rVu3RkRERAktrWyKo1I7IaR8Kc5Oe0HPFV+/fsXo0aOhrq4uyA1H5FtBR7uK/3/v3j0MGDAAtWrVwu3bt3/43rKWh7MsWrduHZycnAAAu3btgoqKCj91PS0tDRcuXICzszOmTJlSgktZvu3evVtwY+Tx48dQUlLCn3/+KXjdkiVLoKamJlcjrHIHQ0UiEX/MDxo0iM+PLhKJ0KFDB74QGZCTk7ZixYoyrU9cXBy8vLxgYWEBRUVF/sbDt2/f8jzXyXOwVqy0DdApTvntv+QuXhUbG4u+ffuiTp06Pz2PFYfyGMMoDPnZ/pLHeN++feX25u+YMWOgoaGBUaNGYfDgwVBTU0NISAiys7MRFRUFZ2dnVKhQAY0bN0aLFi0EsQR5ivmQ8qFAAduyWBU0v169eoXr16/jzJkzfCMkbx2Q2NhYuLi4wNvbG3FxcYiPj4eDgwPMzMykEmZHR0fDxcVFKpgrD0qqUjshpHwork778+fP8ejRIyQkJOR72bKzs/m27J9//sH48eOhp6cnFxc7JH8KY7Tr27dvsXbt2p/2lcpaHs6yauPGjejWrRv++usvKCsrC/KM7t27F/PmzcOhQ4fkrl9ZHomPjUePHsHBwUGQDicxMRGWlpbfnaFWnE6dOoU9e/bw+8z3ggn9+vXjZ4h4e3tDS0uLD0J8/PgR06ZNK1Bah7i4OLRq1QomJia4evUq/3hpDmqUlgE6xSG/+1dukq9LTU3F4cOH5WJkbXmOYRREQfqvuc9f8jZw6tSpU2jcuDGuXLkCANixYweqVq2K1atXC153+fJl3L9/X27jPaT8kDlgWxargv4Keb1zFBcXB3d3d7Rp0wYxMTGIi4uDvb09fH19cfz4ccFrnz17Jnfbo6QrtRNCyrbi6rRv3rwZzZo1Q6NGjaCkpMSPaPrZRU/u52NjYwXTdol8K4zRrhs3bsTTp09/+l1lMQ9nWRUTE4NKlSqB4zjBjaGMjAy4u7vzIyAB+e1flnWSx0VGRgZ8fX3h5uYmOF6zsrKk0gmUhJ07d4LjOFhYWODgwYP8PiO5DuLHRowYgaFDh6JTp07Q09OTKv4lzttaEI8fP4anpyc8PT1x8eLFAn+OPCkNA3SKWn72r7xIPh8VFSUo1FSSKIYhm8Lqv5a03GnOoqKiYGdnBwDYs2cPVFRU+JnGaWlpOHHihNRn0PmYlCSZArZltSpoWSUO2rq7u+PRo0eIiYmBg4MDfH1982yM5OUEVJKV2gkhZV9xddq3bt0KZWVlbNy4ETdu3MCiRYugoKCAGzdu/PB9km3ZihUrpAJtRL6VxGjXspiHs6zatWsXlJSUMHbsWJw5cwanT59GmzZtYGpqWu4CQvIqPT0dR44cgZeXF5o1ayaX1zAPHz6EpaUlxo0bB1dXV1hbW+PAgQNSQTXx/4OCgsBxHCwtLYuk+FdcXBx8fHxgaWkpVfCsLJCnbV8c8rt/5ZbXeezgwYPFssw/QjEM2RRG/3XVqlUYOHBgUS/qD0lus+joaADAoUOH0KVLF2zfvh3KysqCtJDHjh1DUFAQDZAgckWmgG1ZqwpaHuQO2sbGxsLJyQl2dna4fv16SS+eFHmp1E4IKZuKq9MeGxsLOzs7wZRnAHBwcJD6bkm527IaNWpQW1aKyMto19Kch7Os+/btG7Zt2wZNTU1oamqiRYsW8PX1LZdBAXn15s0bBAcHIzAwUG6LZcXExGDkyJGIi4tDRkYGXFxcYGNjIwiqSVq1ahUMDAyKdH2io6MxatQouRkAQgouP/uX5HkrOztbrmdtUAwj/8pK/3Xnzp1YsWIFAGDkyJGwt7fHly9fcO/ePaiqqoLjOP55IGeWgaenJ3r16iV3o4RJ+SZzSoSyWBW0rBMHbT08PPDo0SM8ePAAgwcPlrsOlbxVaieElD3F1Wm/ffs2rK2tpUYadejQAQMGDAAg3eGVvMgWd3apLSt95Gm0a2nJw1kevXv3DnFxcXj+/Dm/naivXPTy2/f98OGDXG+X//77TzBaPy0tjQ+q7d+/nz+fSBY8LM71kbdrDCKb/O5fnz59knqvvF6LUQwjf8pK/3XGjBngOA7u7u6oXr26YH0OHz4MjuMwcuRI7N+/HydPnoSbm5tgpgsFbYm8KFDRsbJYFbSsk9xmknld5alDVZyV2gkh5Vdxddrv3r3L/1uce3vw4MEYNWqU4HW5cyGuXr1aLi92SMGUxGjX0pSHk+SQp/5YWVHQ4rWSwYfScNEuWTxMHFQ7dOgQEhMT4efnh6VLlwLIWZfSsD5Evvxs/5Icpbho0SK5nrVBMYz8Ka3919DQUNy5c4f/u1mzZlBQUMDEiRMBCEeC//nnnzA0NETdunVha2sLPz8/mulC5FKBArZA2awKWtZFR0dj5MiRcndRUFyV2gkhRKwoO+25XysSifh2d9CgQXxhIZFIhA4dOvCFHICc/LoVK1aU24sdUnDFPdq1NOThJKSoFEbx2nPnzpWa4rXi4/rjx49o1aoVrKysoKOjg6ZNm5bboBMpPPnZvz5+/AhHR0ds3bq1JBf1pyiG8X2luf+alpaGihUrwsHBAffv3wcA9O/fH4MGDUKFChWwcuVK/rXidXr//j0SEhLw6tUruZ5RQcq3AgdsgbJZFbS8kJegbXFVaieEkNwKs9N+6tQp7Nmz56dTqfr168endPH29oaWlpZg9Mq0adPkJucbKRwlNdq1NOThJKQolNfiteKgWnx8PDiOg52dHd2oIYXmR/uX+Nzy+fPnEls+WVAM43/KQv9V3J969+4dGjZsCFtbW8HMppkzZ0oFbYGc9A95fQ4h8uSXArZA2a8KSopOcVVqJ4SQ7ymMTvvOnTvBcRwsLCxw8ODBPAtyiB8bMWIEhg4dik6dOkFPT0/qYjojI+NXVofIqcIe7VpW8nASUtjKe/Ha9+/fw8LCAsbGxnSjhhS6srR/UQyj7PRfRSIRvxzv3r2DpqYmWrZsiQcPHvCvmTVrFipWrIhFixbhyZMn8PPzg6+vL/9+QuTVLwdsAaoKSmRXXJXaCSHkZ36l0/7w4UNYWlpi3LhxcHV1hbW1dZ5VlMX/DwoKAsdxsLS0LJfVh8urXxntWl7ycBLyq6h4LZCcnIzevXvzaR/o/EIKU1nbv8pzDKMs9l8/fPgAAEhKSoKmpibs7e0FQVvxDF5jY2PBzXNC5BkHAKwQiUQiVqFChcL8SFIGPX78mPXt25fVrFmTjRo1ijk5OTHGGJs3bx6LiIhgV65cYXXr1mWfP39m8+bNY9OnT2e6urosOjqaKSoqsm/fvrGKFSuW8FoQQsqKmJgYtnbtWjZ//nyZzmGxsbEsMjKSDR48mGlpaTFvb2/25csXFhoaynx8fJiCgoLg9eHh4Wzp0qXsn3/+YRUrVqS2rAzIb78nJSWFqaqqMo7j8r3d//zzT7Z06VL26dMnlpaWxtLT01lmZiZbtWoV69q1K6tUqVKe7wPAOI5jjDF2/vx5pqOjwxo0aCDbihFSymRkZLAFCxawWbNmsfDwcNa7d2/BsSDWpUsX9uLFC3bx4kXBc+Hh4SwsLIxFRkaygICA4l78HyrI9VVWVhZTVFQsoiUiZQntX+UvhlHW+q+rV69mcXFxLCgoiDVq1Ii9e/eOWVhYsEaNGrGIiAhmYmLCGGPs5s2bLC0tjbm4uDAFBQW5Ww9Cciv0gC0h+fX48WMWHBzMRCIRW7FiBXv58iXz9vZm27ZtY/7+/vzrUlNT2bFjx1jHjh3l8gRBCClbZOm0Z2VlseTkZKahocEYY+zjx4/Mz8+PffnyhU2YMIG1bduWKSgosI8fP7Lq1aszxv4XTKO2rPSJjY1lCQkJ7PTp00xHR4c5OTkxY2Pjn74vOzubv/jJK4CUl8jISBYSEsIWLlzIHB0dWdOmTdmlS5fYmjVr2LZt29jSpUvZ4MGDpT5P8u/w8HA2dOhQdvPmTWZhYVHAtSZEvl28eJFdv36dVahQgRkaGrK4uDg2YsQItm7dOtarVy+p17dv357VqlWLrVu3jjGWc8zcv3+fmZubsx07drBOnToV8xoIFbSdKW8BJ1IwtH8Rxspe/3XChAls9+7drFu3bqxXr16CoK2Ojg4LDw9nxsbGgv6SZN+MELlVMgN7CclRlJXaCSGkOEkWX3BxcYGNjQ0OHTqExMRE+Pn5YenSpQByppfRFPXSpzirzpf3PJyE5FdZK15bGO3M2bNn89XOkPKH9i+Sl9LWf/1eCouZM2eiadOmmDRpEl90LCkpCdra2jAwMMCTJ0+KcSkJKRwUsCUlrjArtRNCSEkS5/76+PEjWrVqBSsrK+jo6KBp06Z0w6kUK86q85SHk5D8KWvFa4uznSHlD+1f5EdKY//11q1bfN5asenTp/NBW/GNhdevX6N9+/ZU/4aUShSwJXKhMCq1E0KIPBB3COPj48FxHOzs7KhYYilW3KNdP3/+jGnTpqFy5cpYv3691GeJ/f7772jZsqXUc6tWrULNmjUpWEvKtLJWvJZG1ZOiRPsXyY/S1H89evQoVFVVsWLFCqSmpgqemzhxIqpWrYopU6bg8ePHgufkbT0I+RkK2BK58SuV2gkhRJ68f/8eFhYWMDY25kcmyOsIBfJ9xTna9cKFC1i4cCEWL16MY8eOYdmyZahQoQKioqLyfL2fnx/69Okj+M67d++C4zjs3LlT5nUlpDSJi4uDo6Mj/Pz8cO7cOf7xuXPnQkdHB2/fvgUApKenY/LkyeA4Dk2aNJHL6uY0qp4UJdq/iCxKU/+1f//+0NfXx8qVKwVB27S0NNSvXx+1a9fGmjVrANDMXVJ6UcCWyJXo6GiMGjVKbqanEUJIQSQnJ6N37958Tjh57eySHyuu0a5lLQ8nIcUhLi4Onp6ecHd3R1xcHE6dOoXKlStjz549gtelpKRg+/btcht8oFH1pCjR/kVkIY/91x/FBQYMGABdXV2sWrUKaWlpAHLODcOGDcPy5ctpRC0p9TgAKOnCZ4TkhaqREkLkTUHapaysLKaoqFhES0SKQnFWnV+7di0bOnQo27x5M/P19WXXrl1jU6ZMYSKRiEVFRbGoqCg2e/ZsFhUVxQIDA5lIJGLt2rVjGRkZ7OTJk3yFYzpnkvLo8ePHbPjw4SwpKYk9ePCARUVFsW7durHs7GxWoUIFQUVwxphcVTcvznaGlD+0fxFJpbH/ipzBhfxyHzp0iMXHx7N69eoxExMTZmJiwhhjbODAgez8+fPMw8OD2dvbsw0bNjBlZWW2Y8cOxhhj2dnZfF+JkNJGPnoshOSBLjwJISUpNjaWJSQksNOnTzMdHR3m5OTEjI2Nf/q+3J1iCtaWLmvXrmWhoaFMU1OTPXnyhGloaLAJEyaw+fPnsz59+jAFBQXWo0cPfjs/f/6cffz4kfn4+PCfwXEcMzMzY7GxsUxfX/+733X27Fk2YMAANnXqVNa5c2cGgLm4uDAfHx+2ZMkSpqqqyiZPnswUFBRY3759WYUKFdjBgwdZfHw8e/DgAVNQUOAvROicScojPT09tnTpUjZo0CBmYGDAmjRpwhhjTEFBgeU1JkVegrXF2c6Q8of2r/KtrPRfOY7jb7qNGzeObd68menr67P3798zHR0d1rdvX9ahQwe2evVqNnXqVHb8+HF28OBB1rhxY7Z//37GWE7Ql4K1pFQrqaG9hBBCiLzavn07bG1tYWxsDC0tLaiqqkJJSQlRUVH8NLG8SE4lPHv2LF+hlpQOxV11vizl4SSkJJWm4rXF3c6Q8oX2r/KtLPRfR4wYgUuXLvF/L168GA0aNMCVK1cAAAsXLkTlypXRsmVL/Pnnn/zr3rx5gxcvXvD7LvWRSFlAAVtCCCFEwurVq6GiooLIyEjExMQAAC5evIjAwEAoKipi1apVAKRzwEn+vWrVKnAch1u3bhXfgpNfUlJV58tKHk5CSlppKF5bUu0MKR9o/yrfykL/1cvLC+bm5vzfnz59Qv/+/bF8+XIAwP79+1GjRg2MGTMGjo6OMDc3x759+6Q+h244kLKCAraEEELI/4uMjESVKlWwd+9eAMJO7Lt37zBgwAAoKCjg8uXLgvflrqaspqaGXbt2Fc9Ck0JRkqNd4+Li4OXlBQsLCygqKmLLli0Aci6c8yoOQ8FaQvIm78VraVQ9KUq0f5VfZaH/+vLlS9jY2ODw4cMAgJMnT+LTp0+IiYlBYmIi/vnnH+jo6GDx4sUAgI0bN6JatWpo2rQpTpw4USLLTEhRo4AtIYQQAiA2NhYcx6F///4A/nd3XrIzGx0dDT09PfTo0YN/LHdnt3r16lRNuZQqydGucXFxaNWqFUxMTHD16lX+8bwCtoSQn5PnoC2NqidFhfav8qes9F+Tk5Oho6ODbt26oW/fvlBVVcW///7Lr8+qVavg6OiIT58+AchJ/+Dl5YU5c+bIbXtPyK/igDwy8hNCCCHlTEZGBluwYAGbNWsWCw8PZ71792YApKqMd+nShb148YJdvHhR8Fx4eDgLCwtjkZGRLCAgoLgXnxSSkqw6Hx8fz4KCghhjjIWFhTF7e/tC+VxCiHwpyXaGlH20f5UvZaH/Ki54lpiYyHR0dJiSkhLbt28fa926Nf+aVatWseXLl7PVq1ezli1bsoCAAGZtbc1CQ0MZx3F8EVZCyhIqKUwIIaRcu3jxIlu0aBGLjIxkNjY2bP78+axfv35sw4YNUp1dxhj78uULa9q0Kf8cAHbv3j02dOhQFhERQcHaUk5cdV5VVVWq6nxeCvMit0mTJmzZsmVMQUGBjRgxgt2/f7/QPpsQIj9Ksp0hZR/tX+VDWeq/VqiQE5a6ceMGy87OZt++fWNbtmxhSUlJ/GvMzc1ZnTp1WI8ePZiBgQF78uQJGzduHOM4jgGgYC0pk2iELSGEkHJr7dq1LDQ0lGlqarInT54wDQ0NNmHCBJaSksJCQkLYxo0bWY8ePfg7/8+fP2e9e/dmXbp0Yf379xd8VlxcHNPX1y+hNSGFrSRHu8bExLC1a9ey+fPn8xcxhJCyh0bVk6JE+1fZVVb6r+LlE3v16hVTUVFhCQkJzM7OjnXo0IEtWrSI1alThzHG2LVr19izZ8/Yhw8f2IABA1jFihVphDgp0yhgSwghpFxau3YtGzp0KNu8eTPz9fVl165dY1OmTGEikYhFRUWxqKgoNnv2bBYVFcUCAwOZSCRi7dq1YxkZGezkyZP8nfzcnU1Sdjx+/JiNHDmSJSUlsXXr1jFTU9NiXwbavwgp2+ShnSFlF+1fZU9Z6b9Kfn9sbCxLS0tjurq6TElJiVWrVo1dvHiReXp6svbt27OFCxeyunXrSn0GpUEgZR3diiCEEFLunD17lg0YMIBNnTqVde7cmQFgLi4uzMfHhy1ZsoSpqqqyyZMnMwUFBda3b19WoUIFdvDgQRYfH88ePHjAFBQU+E4iBdPKLj09PTZ//ny2du1aZmJiUiLLQPsXIWWbPLQzpOyi/atsKQv9V/F4QfH3T5w4ke3bt4+lpKSwBg0aMAsLCzZhwgTm4ODATp48yTw8PJiCggKbO3cu09DQEHwWBWtJWUdXAYQQQsodTU1N5uDgwG7fvs3Onz8vyPVVpUoVlp2dzSpXrszGjRvHJk6cyAIDA9ndu3fZgwcPmKKiIvv27Rt1EssJQ0NDtnDhQlahQgUmEolKenEIIWUQtTOkKNH+VXaUhf6r5DIvXLiQrV27lq1YsYK9efOGGRgYsL1797LExETGGGN2dnbs+PHjbPPmzSwyMrKkFpmQEkMpEQghhJRLjx8/ZsHBwUwkErEVK1awly9fMm9vb7Zt2zbm7+/Pvy41NZUdO3aMdezYkXJlEUIIIYSQElNa+69hYWGsbt26fF7l9PR01qVLF+bt7c0GDx7Mjh49yn777Te2YMECNmDAAJaZmcn+++8/pqKiwv755x/WtGlT6n+TcocCtoQQQsqtx48fs+HDh7OkpCT24MEDFhUVxbp168ays7NZhQoVpKrslnRnlxBCCCGElG+lrf+amprKOnTowEQiEevVqxfr3bs3Y4wxV1dXtnTpUvb27VsWEBDAFixYwAYOHMj+++8/tmnTJqavr88cHBz49AklvR6EFDdKiUAIIaTc0tPTY0uXLmWqqqrMwMCANWnShDH2/ZxY1EkkhBBCCCElqTT1XwEwVVVVtmPHDlanTh22ZcsWtnbtWsYYY6qqqqxz586sc+fObOnSpWzgwIGMMcbev3/Ptm3bxuLj4wW5dqkfTsobGmFLCCGk3IuPj+enaIWFhTF7e/sSXiJCCCGEEEK+rzT0X8VFzhhj7MqVK2zChAksIyODTZgwgRkYGLDevXuzL1++sPv377PMzEz25csX1rVrV5aens7OnDlT4jl3CSlJFLAlhBBCWM70spEjR7KkpCS2bt06ZmpqWtKLRAghhBBCyHeVlv7r6NGj2ZMnT9ibN29YTEwMq1+/PhsxYgRTVVVlY8aMYVWrVmW1a9dmjDH25csXdu3aNaaoqCgI+BJS3lDAlhBCCPl/MTExbO3atWz+/PmCKViEEEIIIYTII3nvv27atImNGDGC/f3330xbW5tlZmaywMBAlpWVxQIDA1mbNm3Y5s2bWVZWFtPU1GS9evViCgoKlLOWlHsUsCWEEELyIBKJ5LLTSwghhBBCSF7ksf86ZcoUdurUKXb+/HnGcRzjOI4lJiYyf39/lpKSwubMmcMCAgIE76GRtYRQ0TFCCCEkT/LW2SWEEEIIIeRH5Kn/Kh4bqKSkxDIzM1lmZibjOI5lZWUxLS0tNnv2bPbmzRs2ZcoUduDAAcF7KFhLCAVsCSGEEEIIIYQQQkgh4jiOMcaYr68vu3v3Lps3bx5jjDFFRUXGGGOZmZmsdevWzM/Pj/n6+greQwhhjBKCEEIIIYQQQgghhJBCZ2xszNasWcMGDBjA0tPTWefOnVnNmjXZypUrmampKZs5cyZjTD7TORBSkiiHLSGEEEIIIYQQQggpMnv27GFDhgxhlSpVYowxpq6uzq5du8YUFRUZABpdS0guFLAlhBBCCCGEEEIIIUXq9evX7NWrV+zz58/M0dGRKSgosG/fvrGKFWnyNyG5UcCWEEIIIYQQQgghhBSr7OxsKjBGyHdQwJYQQgghhBBCCCGEEELkBGV0JoQQQgghhBBCCCGEEDlBAVtCCCGEEEIIIYQQQgiRExSwJYQQQgghhBBCCCGEEDlBAVtCCCGEEEIIIYQQQgiRExSwJYQQQgghhBBCCCGEEDlBAVtCCCGEEEIIIYQQQgiRExSwJYQQQgghhBBCCCGEEDlBAVtCCCGEEEIIIYQQQgiRExSwJYQQQgghhDG2YcMGxnFcnv+NHz++0L/v8uXLbOrUqSw1NbXQP5sQQgghhJReFUt6AQghhBBCCJEnf/zxB9PR0RE8ZmJiUujfc/nyZTZt2jTWq1cvpqqqWuifTwghhBBCSicK2BJCCCGEECLBy8uLWVpalvRiFNjnz59ZtWrVSnoxCCGEEEJIAVFKBEIIIYQQQvLp6NGjzNHRkVWrVo2pqKgwHx8f9vDhQ8Fr7t+/z3r16sUaN27MqlSpwjQ0NFifPn1YcnIy/5qpU6eyMWPGMMYY09HR4VMvJCQksISEBMZxHNuwYYPU93Mcx6ZOnSr4HI7jWHR0NOvatStTU1NjDg4O/PNbtmxhLVq0YEpKSqxmzZrs999/Zy9fvizcH4UQQgghhBQqGmFLCCGEEEKIhLS0NPbvv/8KHqtduzbbvHkzCwwMZB4eHmzu3LksIyODhYeHMwcHB3bnzh3WqFEjxhhjJ0+eZE+fPmW9e/dmGhoa7OHDhywyMpI9fPiQXb16lXEcx/z9/VlcXBzbvn07W7x4MatduzZjjDF1dXX2/v17mZe5U6dOTE9Pj82aNYsBYIwxNnPmTDZp0iTWuXNn1q9fP/b+/Xu2fPly5uTkxO7cuUNpGAghhBBC5BQFbAkhhBBCCJHg5uYm9dinT59YcHAw69evH4uMjOQfDwwMZAYGBmzWrFn840OGDGGjR48WvN/W1pZ16dKFXbx4kTk6OjJTU1NmYWHBtm/fztq3b88HexljBQrYmpmZsW3btvF/P3/+nE2ZMoXNmDGDhYaG8o/7+/szc3NztmrVKsHjhBBCCCFEflDAlhBCCCGEEAkrV65k+vr6gsdOnjzJUlNTWZcuXQSjbxUUFJiNjQ07c+YM/5iSkhL/769fv7L09HRma2vLGGPs9u3bzNHRsdCXedCgQYK/9+7dy0QiEevcubNgeTU0NJienh47c+YMBWwJIYQQQuQUBWwJIYQQQgiRYG1tLVV0bN68eYwxxlq1apXne6pXr87/+8OHD2zatGnszz//ZO/evRO8Li0trZCXNoeOjo7g78ePHzMATE9PL8/XKyoqFslyEEIIIYSQX0cBW0IIIYQQQn5CJBIxxhjbvHkz09DQkHq+YsX/das7d+7MLl++zMaMGcOaN2/OlJWVmUgkYp6envzn/AjHcXk+np2d/d33SI7qFS8vx3Hs6NGjTEFBQer1ysrKP10OQgghhBBSMihgSwghhBBCyE/o6uoyxhirU6dOnjluxVJSUtipU6fYtGnT2OTJk/nHHz9+LPXa7wVm1dTUGGOMpaamCh5//vy5TMsLgOno6EildyCEEEIIIfKtQkkvACGEEEIIIfLOw8ODVa9enc2aNYtlZWVJPS8uFCYezQpA8PySJUuk3lOtWjXGmHRgtnr16qx27drs/PnzgsdXrVqV7+X19/dnCgoKbNq0aVLLAoAlJyfn+7MIIYQQQkjxohG2hBBCCCGE/ET16tVZeHg469GjB7OwsGC///47U1dXZy9evGBHjhxh9vb2bMWKFax69erMycmJzZs3j2VlZTFNTU124sQJ9uzZM6nPbNGiBWOMsYkTJ7Lff/+dKSoqMl9fX1atWjXWr18/NmfOHNavXz9maWnJzp8/z+Li4vK9vLq6umzGjBlswoQJLCEhgbVv356pqKiwZ8+esX379rEBAwawkJCQQvt9CCGEEEJI4aGALSGEEEIIIfnQtWtXVr9+fTZnzhw2f/58lpmZyTQ1NZmjoyPr3bs3/7pt27axoKAgtnLlSgaAubu7s6NHj7L69esLPs/KyopNnz6dRUREsGPHjjGRSMSePXvGqlWrxiZPnszev3/Pdu/ezXbu3Mm8vLzY0aNHWZ06dfK9vOPHj2f6+vps8eLFbNq0aYwxxho0aMDc3d1Zu3btCudHIYQQQgghhY5D7jlShBBCCCGEEEIIIYQQQkoE5bAlhBBCCCGEEEIIIYQQOUEBW0IIIYQQQgghhBBCCJETFLAlhBBCCCGEEEIIIYQQOUEBW0IIIYQQQgghhBBCCJETFLAlhBBCCCGEEEIIIYQQOUEBW0IIIYQQQgghhBBCCJETFLAlhBBCCCGEEEIIIYQQOUEBW0IIIYQQQgghhBBCCJETFLAlhBBCCCGEEEIIIYQQOUEBW0IIIYQQQgghhBBCCJETFLAlhBBCCCGEEEIIIYQQOUEBW0IIIYQQQgghhBBCCJETFLAlhBBCCCGEEEIIIYQQOfF/rV91SOwKfJkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the top 50 features\n",
    "top_native_features = native_ft_importance.head(50)\n",
    "\n",
    "# Set a larger figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Create the bar plot for top 50 features\n",
    "top_native_features.plot(\n",
    "    kind=\"bar\", x=\"Features\", y=\"importance\", legend=False, figsize=(14, 6)\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Top 50 Native Feature Importance\", fontsize=14)\n",
    "plt.ylabel(\"Feature Importance\", fontsize=12)\n",
    "plt.xlabel(\"Feature\", fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
    "\n",
    "# Adjust layout to prevent label overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{MODEL_PATH}/native_feature_importance.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/tabular_model.py:2020: UserWarning: KernelShap is computationally expensive and will take some time. For faster results, try usingsome other methods like GradientShap, IntegratedGradients etc.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/captum/attr/_core/lime.py:1109: UserWarning: You are providing multiple inputs for Lime / Kernel SHAP attributions. This trains a separate interpretable model for each example, which can be time consuming. It is recommended to compute attributions for one example at a time.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Explain a single instance using the GradientShap method and baseline as 10000 samples from the training data\n",
    "kernelSHAP = tabular_model.explain(train, method=\"KernelShap\", baselines=\"b|1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = kernelSHAP.abs().median().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Industry_subgroup                0.014694\n",
       "coupon rate                      0.007859\n",
       "domicile_country                 0.007547\n",
       "Industry_group                   0.007073\n",
       "event_type_subcategory_sum       0.005407\n",
       "                                   ...   \n",
       "PD_12_domicile_sector            0.001047\n",
       "PD_49_pd                         0.001044\n",
       "PD_15_pd                         0.001034\n",
       "PD_3_pd                          0.001033\n",
       "shares_out_outstanding_shares    0.000998\n",
       "Length: 164, dtype: float32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = feature_importance.reset_index()\n",
    "feature_importance_df.columns = [\"Feature\", \"Importance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the top 50 features\n",
    "top_features = feature_importance_df.head(50)\n",
    "\n",
    "# Set a larger figure size\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Create the bar plot for top 50 features\n",
    "top_features.plot(\n",
    "    kind=\"bar\", x=\"Feature\", y=\"Importance\", legend=False, figsize=(14, 6)\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Top 50 Global Feature Importance (SHAP)\", fontsize=14)\n",
    "plt.ylabel(\"Mean |SHAP Value|\", fontsize=12)\n",
    "plt.xlabel(\"Feature\", fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
    "\n",
    "# Adjust layout to prevent label overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the fig\n",
    "plt.savefig(f\"{MODEL_PATH}/training_shap.png\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:58:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">301</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m13:58:18\u001b[0m,\u001b[1;36m301\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:58:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">303</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m13:58:18\u001b[0m,\u001b[1;36m303\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:58:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">309</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m13:58:18\u001b[0m,\u001b[1;36m309\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:58:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">365</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m13:58:18\u001b[0m,\u001b[1;36m365\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:58:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">443</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m13:58:18\u001b[0m,\u001b[1;36m443\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:58:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">460</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m13:58:18\u001b[0m,\u001b[1;36m460\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:58:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">518</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m13:58:18\u001b[0m,\u001b[1;36m518\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    240 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    240 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d8f53c7afc45a8939093193b899343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">057</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:03:59\u001b[0m,\u001b[1;36m057\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">061</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:03:59\u001b[0m,\u001b[1;36m061\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">261</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:03:59\u001b[0m,\u001b[1;36m261\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">282</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:03:59\u001b[0m,\u001b[1;36m282\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">292</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:03:59\u001b[0m,\u001b[1;36m292\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">303</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:03:59\u001b[0m,\u001b[1;36m303\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">390</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:03:59\u001b[0m,\u001b[1;36m390\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">515</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:03:59\u001b[0m,\u001b[1;36m515\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">545</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:03:59\u001b[0m,\u001b[1;36m545\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">617</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:03:59\u001b[0m,\u001b[1;36m617\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    241 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    241 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b365458a57452292014ba2799b9192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:10:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">981</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:10:01\u001b[0m,\u001b[1;36m981\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:10:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">983</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:10:01\u001b[0m,\u001b[1;36m983\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:10:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">173</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:10:02\u001b[0m,\u001b[1;36m173\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:10:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">203</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:10:02\u001b[0m,\u001b[1;36m203\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:10:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">268</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:10:02\u001b[0m,\u001b[1;36m268\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:10:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">294</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:10:02\u001b[0m,\u001b[1;36m294\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:10:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">420</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:10:02\u001b[0m,\u001b[1;36m420\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:10:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">550</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:10:02\u001b[0m,\u001b[1;36m550\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:10:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">578</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:10:02\u001b[0m,\u001b[1;36m578\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:10:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">661</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:10:02\u001b[0m,\u001b[1;36m661\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    241 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    241 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826f500886c44818a0d14cb15ad4d80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:15:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">831</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:15:48\u001b[0m,\u001b[1;36m831\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:15:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">833</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:15:48\u001b[0m,\u001b[1;36m833\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:15:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">004</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:15:49\u001b[0m,\u001b[1;36m004\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:15:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">023</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:15:49\u001b[0m,\u001b[1;36m023\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:15:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">027</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:15:49\u001b[0m,\u001b[1;36m027\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:15:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">035</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:15:49\u001b[0m,\u001b[1;36m035\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:15:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">131</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:15:49\u001b[0m,\u001b[1;36m131\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:15:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">287</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:15:49\u001b[0m,\u001b[1;36m287\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:15:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">317</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:15:49\u001b[0m,\u001b[1;36m317\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:15:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">351</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:15:49\u001b[0m,\u001b[1;36m351\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    244 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.5 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    244 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2f3563473b4dc78ae65783ed90b25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:22:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">226</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:22:08\u001b[0m,\u001b[1;36m226\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:22:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">232</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:22:08\u001b[0m,\u001b[1;36m232\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:22:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">651</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:22:08\u001b[0m,\u001b[1;36m651\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:22:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">675</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:22:08\u001b[0m,\u001b[1;36m675\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:22:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">680</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:22:08\u001b[0m,\u001b[1;36m680\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:22:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">690</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:22:08\u001b[0m,\u001b[1;36m690\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:22:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">798</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:22:08\u001b[0m,\u001b[1;36m798\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:22:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">991</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:22:08\u001b[0m,\u001b[1;36m991\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:22:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">104</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:22:09\u001b[0m,\u001b[1;36m104\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:22:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:22:09\u001b[0m,\u001b[1;36m240\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    245 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.5 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    245 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5482d0ac5a304da692f0389afc75b7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:28:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:28:14\u001b[0m,\u001b[1;36m110\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:28:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:28:14\u001b[0m,\u001b[1;36m112\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:28:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">320</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:28:14\u001b[0m,\u001b[1;36m320\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:28:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">395</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:28:14\u001b[0m,\u001b[1;36m395\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:28:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">401</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:28:14\u001b[0m,\u001b[1;36m401\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:28:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">411</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:28:14\u001b[0m,\u001b[1;36m411\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:28:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:28:14\u001b[0m,\u001b[1;36m502\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:28:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:28:14\u001b[0m,\u001b[1;36m652\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:28:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">686</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:28:14\u001b[0m,\u001b[1;36m686\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:28:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">758</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:28:14\u001b[0m,\u001b[1;36m758\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    240 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    240 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9287171995474e06973dbcf0d8263d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">505</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:34:06\u001b[0m,\u001b[1;36m505\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">507</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:34:06\u001b[0m,\u001b[1;36m507\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">657</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:34:06\u001b[0m,\u001b[1;36m657\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">674</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:34:06\u001b[0m,\u001b[1;36m674\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:34:06\u001b[0m,\u001b[1;36m678\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">685</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:34:06\u001b[0m,\u001b[1;36m685\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">784</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:34:06\u001b[0m,\u001b[1;36m784\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">928</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:34:06\u001b[0m,\u001b[1;36m928\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">955</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:34:06\u001b[0m,\u001b[1;36m955\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">031</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:34:07\u001b[0m,\u001b[1;36m031\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    240 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    240 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da421e4dc524f6aa5c1b9ccf93e9051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:40:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">084</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:40:00\u001b[0m,\u001b[1;36m084\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:40:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">086</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:40:00\u001b[0m,\u001b[1;36m086\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:40:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">394</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:40:00\u001b[0m,\u001b[1;36m394\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:40:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">511</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:40:00\u001b[0m,\u001b[1;36m511\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:40:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">543</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:40:00\u001b[0m,\u001b[1;36m543\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:40:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">551</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:40:00\u001b[0m,\u001b[1;36m551\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:40:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">646</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:40:00\u001b[0m,\u001b[1;36m646\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:40:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">781</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:40:00\u001b[0m,\u001b[1;36m781\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:40:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">810</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:40:00\u001b[0m,\u001b[1;36m810\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:40:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">932</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:40:00\u001b[0m,\u001b[1;36m932\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    242 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    242 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90621bb252f48f58f51576e51a36fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:45:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">168</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:45:23\u001b[0m,\u001b[1;36m168\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:45:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">169</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:45:23\u001b[0m,\u001b[1;36m169\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:45:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">328</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:45:23\u001b[0m,\u001b[1;36m328\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:45:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">345</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:45:23\u001b[0m,\u001b[1;36m345\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:45:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">348</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:45:23\u001b[0m,\u001b[1;36m348\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:45:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">356</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:45:23\u001b[0m,\u001b[1;36m356\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:45:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">426</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:45:23\u001b[0m,\u001b[1;36m426\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:45:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">558</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:45:23\u001b[0m,\u001b[1;36m558\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:45:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">585</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:45:23\u001b[0m,\u001b[1;36m585\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:45:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:45:23\u001b[0m,\u001b[1;36m663\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6daf72441cf046db8e86d3dfbddcb827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">863</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:53:39\u001b[0m,\u001b[1;36m863\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">865</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:53:39\u001b[0m,\u001b[1;36m865\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">042</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:53:40\u001b[0m,\u001b[1;36m042\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">061</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:53:40\u001b[0m,\u001b[1;36m061\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">066</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:53:40\u001b[0m,\u001b[1;36m066\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">076</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:53:40\u001b[0m,\u001b[1;36m076\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">180</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:53:40\u001b[0m,\u001b[1;36m180\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">320</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:53:40\u001b[0m,\u001b[1;36m320\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">347</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:53:40\u001b[0m,\u001b[1;36m347\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">418</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:53:40\u001b[0m,\u001b[1;36m418\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    245 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.5 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    245 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50609325c54a4dcb98168578f755f4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">249</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:59:13\u001b[0m,\u001b[1;36m249\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">252</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:59:13\u001b[0m,\u001b[1;36m252\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">493</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:59:13\u001b[0m,\u001b[1;36m493\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">523</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:59:13\u001b[0m,\u001b[1;36m523\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">527</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:59:13\u001b[0m,\u001b[1;36m527\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">541</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:59:13\u001b[0m,\u001b[1;36m541\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">650</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:59:13\u001b[0m,\u001b[1;36m650\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">794</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:59:13\u001b[0m,\u001b[1;36m794\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">818</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:59:13\u001b[0m,\u001b[1;36m818\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:13</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">895</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m14:59:13\u001b[0m,\u001b[1;36m895\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    240 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    240 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839d6d9537d947f18c6382995af80be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:06:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">356</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:06:43\u001b[0m,\u001b[1;36m356\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:06:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">358</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:06:43\u001b[0m,\u001b[1;36m358\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:06:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">554</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:06:43\u001b[0m,\u001b[1;36m554\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:06:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">582</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:06:43\u001b[0m,\u001b[1;36m582\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:06:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">592</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:06:43\u001b[0m,\u001b[1;36m592\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:06:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">626</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:06:43\u001b[0m,\u001b[1;36m626\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:06:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">741</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:06:43\u001b[0m,\u001b[1;36m741\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:06:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">878</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:06:43\u001b[0m,\u001b[1;36m878\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:06:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">912</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:06:43\u001b[0m,\u001b[1;36m912\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:06:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">951</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:06:43\u001b[0m,\u001b[1;36m951\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    240 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    240 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16fe8752bc24206b0d3753df4681df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">480</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:12:48\u001b[0m,\u001b[1;36m480\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">482</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:12:48\u001b[0m,\u001b[1;36m482\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">654</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:12:48\u001b[0m,\u001b[1;36m654\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">673</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:12:48\u001b[0m,\u001b[1;36m673\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">676</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:12:48\u001b[0m,\u001b[1;36m676\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">686</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:12:48\u001b[0m,\u001b[1;36m686\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">778</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:12:48\u001b[0m,\u001b[1;36m778\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">914</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:12:48\u001b[0m,\u001b[1;36m914\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">946</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:12:48\u001b[0m,\u001b[1;36m946\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">996</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:12:48\u001b[0m,\u001b[1;36m996\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    241 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    241 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a22400e8bc4db89bbdd69cabc269f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:19:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">938</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:19:14\u001b[0m,\u001b[1;36m938\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:19:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">940</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:19:14\u001b[0m,\u001b[1;36m940\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:19:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">111</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:19:15\u001b[0m,\u001b[1;36m111\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:19:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">135</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:19:15\u001b[0m,\u001b[1;36m135\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:19:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">145</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:19:15\u001b[0m,\u001b[1;36m145\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:19:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">159</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:19:15\u001b[0m,\u001b[1;36m159\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:19:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">294</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:19:15\u001b[0m,\u001b[1;36m294\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:19:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">422</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:19:15\u001b[0m,\u001b[1;36m422\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:19:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">444</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:19:15\u001b[0m,\u001b[1;36m444\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:19:15</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">514</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:19:15\u001b[0m,\u001b[1;36m514\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    244 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.5 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.7 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    244 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccfabae2dd54287bc0ee136bb107946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">567</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:26:33\u001b[0m,\u001b[1;36m567\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:26:33\u001b[0m,\u001b[1;36m576\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">903</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:26:33\u001b[0m,\u001b[1;36m903\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">932</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:26:33\u001b[0m,\u001b[1;36m932\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">940</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:26:33\u001b[0m,\u001b[1;36m940\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">954</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:26:33\u001b[0m,\u001b[1;36m954\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">067</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:26:34\u001b[0m,\u001b[1;36m067\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">328</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:26:34\u001b[0m,\u001b[1;36m328\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">388</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:26:34\u001b[0m,\u001b[1;36m388\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">557</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:26:34\u001b[0m,\u001b[1;36m557\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf049a17eab41c186058b02807f54fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:34:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">167</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:34:57\u001b[0m,\u001b[1;36m167\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:34:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">190</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:34:57\u001b[0m,\u001b[1;36m190\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:34:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">020</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:34:59\u001b[0m,\u001b[1;36m020\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:34:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">166</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:34:59\u001b[0m,\u001b[1;36m166\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:34:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">192</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:34:59\u001b[0m,\u001b[1;36m192\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:34:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">292</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:34:59\u001b[0m,\u001b[1;36m292\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:34:59</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">551</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:34:59\u001b[0m,\u001b[1;36m551\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:35:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:35:00\u001b[0m,\u001b[1;36m127\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:35:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">318</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:35:00\u001b[0m,\u001b[1;36m318\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:35:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:35:00\u001b[0m,\u001b[1;36m600\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    239 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    239 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42072e8c77884d799db36b7933427873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:55:05</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">617</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:55:05\u001b[0m,\u001b[1;36m617\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:55:05</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">620</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:55:05\u001b[0m,\u001b[1;36m620\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:55:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">084</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:55:06\u001b[0m,\u001b[1;36m084\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:55:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">109</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:55:06\u001b[0m,\u001b[1;36m109\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:55:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">115</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:55:06\u001b[0m,\u001b[1;36m115\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:55:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:55:06\u001b[0m,\u001b[1;36m127\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:55:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">264</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:55:06\u001b[0m,\u001b[1;36m264\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:55:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">430</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:55:06\u001b[0m,\u001b[1;36m430\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:55:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">472</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:55:06\u001b[0m,\u001b[1;36m472\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:55:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">591</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m15:55:06\u001b[0m,\u001b[1;36m591\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    239 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    239 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce7fd782f5e48d4bf2974fd92a4c479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:02:27</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">928</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:02:27\u001b[0m,\u001b[1;36m928\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:02:27</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">930</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:02:27\u001b[0m,\u001b[1;36m930\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:02:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">058</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:02:28\u001b[0m,\u001b[1;36m058\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:02:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">078</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:02:28\u001b[0m,\u001b[1;36m078\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:02:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">082</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:02:28\u001b[0m,\u001b[1;36m082\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:02:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">091</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:02:28\u001b[0m,\u001b[1;36m091\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:02:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">167</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:02:28\u001b[0m,\u001b[1;36m167\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:02:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">308</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:02:28\u001b[0m,\u001b[1;36m308\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:02:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:02:28\u001b[0m,\u001b[1;36m340\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:02:28</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">411</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:02:28\u001b[0m,\u001b[1;36m411\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    242 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    242 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb7727056e9464190eeec47854f51b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:11:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">379</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:11:25\u001b[0m,\u001b[1;36m379\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:11:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">387</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:11:25\u001b[0m,\u001b[1;36m387\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:11:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">826</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:11:25\u001b[0m,\u001b[1;36m826\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:11:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">927</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:11:25\u001b[0m,\u001b[1;36m927\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:11:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">932</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:11:25\u001b[0m,\u001b[1;36m932\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:11:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">954</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:11:25\u001b[0m,\u001b[1;36m954\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:11:26</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">061</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:11:26\u001b[0m,\u001b[1;36m061\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:11:26</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">432</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:11:26\u001b[0m,\u001b[1;36m432\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:11:26</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">489</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:11:26\u001b[0m,\u001b[1;36m489\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:11:26</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">593</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:11:26\u001b[0m,\u001b[1;36m593\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45f425327ff4813b882b0dc94f0af22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:24:31</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">738</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:24:31\u001b[0m,\u001b[1;36m738\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:24:31</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">739</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:24:31\u001b[0m,\u001b[1;36m739\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:24:31</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">813</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:24:31\u001b[0m,\u001b[1;36m813\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:24:31</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">825</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:24:31\u001b[0m,\u001b[1;36m825\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:24:31</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">828</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:24:31\u001b[0m,\u001b[1;36m828\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:24:31</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">834</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:24:31\u001b[0m,\u001b[1;36m834\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:24:31</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:24:31\u001b[0m,\u001b[1;36m880\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:24:31</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">992</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:24:31\u001b[0m,\u001b[1;36m992\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:24:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">013</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:24:32\u001b[0m,\u001b[1;36m013\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:24:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">077</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:24:32\u001b[0m,\u001b[1;36m077\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646f95f0deb04809b9c96c9e1f09866f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:28:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:28:33\u001b[0m,\u001b[1;36m100\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:28:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:28:33\u001b[0m,\u001b[1;36m102\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:28:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">180</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:28:33\u001b[0m,\u001b[1;36m180\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:28:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">195</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:28:33\u001b[0m,\u001b[1;36m195\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:28:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:28:33\u001b[0m,\u001b[1;36m198\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:28:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">205</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:28:33\u001b[0m,\u001b[1;36m205\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:28:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">247</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:28:33\u001b[0m,\u001b[1;36m247\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:28:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">320</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:28:33\u001b[0m,\u001b[1;36m320\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:28:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">344</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:28:33\u001b[0m,\u001b[1;36m344\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:28:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">364</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:28:33\u001b[0m,\u001b[1;36m364\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    240 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    240 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221f5bc708984cc98672ef977b814d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:32:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">650</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:32:33\u001b[0m,\u001b[1;36m650\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:32:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">651</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:32:33\u001b[0m,\u001b[1;36m651\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:32:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">718</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:32:33\u001b[0m,\u001b[1;36m718\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m1\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:32:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">729</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:32:33\u001b[0m,\u001b[1;36m729\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:32:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">731</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:32:33\u001b[0m,\u001b[1;36m731\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:32:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">738</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:32:33\u001b[0m,\u001b[1;36m738\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:32:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">780</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:32:33\u001b[0m,\u001b[1;36m780\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:32:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">853</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:32:33\u001b[0m,\u001b[1;36m853\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:32:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">871</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:32:33\u001b[0m,\u001b[1;36m871\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:32:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">953</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:32:33\u001b[0m,\u001b[1;36m953\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    240 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    240 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b545bc7ecd4874beefa285f117513f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:36:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">487</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:36:34\u001b[0m,\u001b[1;36m487\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:36:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">488</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:36:34\u001b[0m,\u001b[1;36m488\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:36:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">572</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:36:34\u001b[0m,\u001b[1;36m572\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:36:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">584</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:36:34\u001b[0m,\u001b[1;36m584\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:36:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">587</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:36:34\u001b[0m,\u001b[1;36m587\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:36:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">594</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:36:34\u001b[0m,\u001b[1;36m594\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:36:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">692</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:36:34\u001b[0m,\u001b[1;36m692\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:36:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">763</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:36:34\u001b[0m,\u001b[1;36m763\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:36:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">779</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:36:34\u001b[0m,\u001b[1;36m779\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:36:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">806</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:36:34\u001b[0m,\u001b[1;36m806\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    241 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    241 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e988c18f704027be760e9193e281ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:40:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">779</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:40:35\u001b[0m,\u001b[1;36m779\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:40:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">781</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:40:35\u001b[0m,\u001b[1;36m781\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:40:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">861</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:40:35\u001b[0m,\u001b[1;36m861\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m3\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:40:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">873</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:40:35\u001b[0m,\u001b[1;36m873\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:40:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">875</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:40:35\u001b[0m,\u001b[1;36m875\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:40:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">881</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:40:35\u001b[0m,\u001b[1;36m881\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:40:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">923</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:40:35\u001b[0m,\u001b[1;36m923\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:40:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">994</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:40:35\u001b[0m,\u001b[1;36m994\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:40:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">009</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:40:36\u001b[0m,\u001b[1;36m009\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:40:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">061</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:40:36\u001b[0m,\u001b[1;36m061\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    242 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    242 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb05110e4e2d445784cc96cd0c5f9c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:44:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">679</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:44:35\u001b[0m,\u001b[1;36m679\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:44:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">680</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:44:35\u001b[0m,\u001b[1;36m680\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:44:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">761</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:44:35\u001b[0m,\u001b[1;36m761\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m4\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:44:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">773</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2386</span><span style=\"font-weight: bold\">}</span> - INFO - Running Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:44:35\u001b[0m,\u001b[1;36m773\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2386\u001b[0m\u001b[1m}\u001b[0m - INFO - Running Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:44:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">775</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:44:35\u001b[0m,\u001b[1;36m775\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:44:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">781</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:44:35\u001b[0m,\u001b[1;36m781\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:44:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">820</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:44:35\u001b[0m,\u001b[1;36m820\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:44:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">891</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:44:35\u001b[0m,\u001b[1;36m891\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:44:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">906</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:44:35\u001b[0m,\u001b[1;36m906\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:44:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">928</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:44:35\u001b[0m,\u001b[1;36m928\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/hoanguyen/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Recovery rate forecasting/Code/final/src/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │    243 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  2.4 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │  2.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │    243 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss          │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 40                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 40                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff936cf53914c5eb77da105f39b47e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/trainer/connector\n",
       "s/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py\n",
       ":298: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:48:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">726</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:48:36\u001b[0m,\u001b[1;36m726\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:48:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">727</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:48:36\u001b[0m,\u001b[1;36m727\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:48:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">799</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2411</span><span style=\"font-weight: bold\">}</span> - INFO - Fold <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> prediction done                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m16:48:36\u001b[0m,\u001b[1;36m799\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m2411\u001b[0m\u001b[1m}\u001b[0m - INFO - Fold \u001b[1;36m5\u001b[0m/\u001b[1;36m5\u001b[0m prediction done                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "EPOCHS = 100\n",
    "val_mae = []\n",
    "val_mape = []\n",
    "val_rmse = []\n",
    "val_rsqr = []\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    experiment_config=experiment_config,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_epochs=EPOCHS,\n",
    "    early_stopping=None\n",
    ")\n",
    "\n",
    "model = None\n",
    "datamodule = None\n",
    "\n",
    "for index, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "        # Create training and validation datasets for the current fold\n",
    "        train_fold, val_fold = df.iloc[train_idx], df.iloc[val_idx]\n",
    "            \n",
    "        # Train the model\n",
    "        bagged_pred_df = tabular_model.bagging_predict(\n",
    "            cv=5, train=train_fold, test=val_fold, aggregate=\"mean\"\n",
    "        )\n",
    "\n",
    "        # Validation of the model.\n",
    "        mae, mape, rmse, rsqr = calculate_metric(bagged_pred_df.to_numpy().squeeze(), val_fold[target_col].to_numpy())\n",
    "        val_mae.append(mae)\n",
    "        val_mape.append(mape)\n",
    "        val_rmse.append(rmse)\n",
    "        val_rsqr.append(rsqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2587083486523426,\n",
       " 0.2467718990858054,\n",
       " 0.25178891753890464,\n",
       " 0.2453077783298973,\n",
       " 0.25632908717781844]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test average mean absolute error: 0.20103623262968476\n",
      "Test average mean absolute percentage error: 5252.416188960119\n",
      "Test average root mean squared error: 0.25178120615695365\n",
      "Test average R2: 0.42099126750949445\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test average mean absolute error: {statistics.mean(val_mae)}\")\n",
    "print(f\"Test average mean absolute percentage error: {statistics.mean(val_mape)}\")\n",
    "print(f\"Test average root mean squared error: {statistics.mean(val_rmse)}\")\n",
    "print(f\"Test average R2: {statistics.mean(val_rsqr)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
